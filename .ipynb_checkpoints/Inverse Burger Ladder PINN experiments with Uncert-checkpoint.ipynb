{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef5dfe8-a792-446a-a597-38ac590abc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from pysr import pysr, best, best_callable\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "from utils import *\n",
    "import pcgrad\n",
    "from ladder import LadderNetwork\n",
    "\n",
    "# AdamGC (Gradient centrailization) optimizer\n",
    "# Please also try learning finder. (Doesn't have to be included in the paper)\n",
    "from optimizers import Lookahead, AdamGC, SGDGC  # Not have to report Lookahead and GC\n",
    "\n",
    "print(\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e50676-a65c-4d6f-b7b5-60994293b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e35985-72fb-4721-9386-223aaf9803e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples: 2000\n"
     ]
    }
   ],
   "source": [
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:, None]\n",
    "x = data['x'].flatten()[:, None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print('The number of training samples:', str(N))\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx, :]\n",
    "\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4f5488-e8e4-44e6-a215-bbf673047a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model, uncert_mode=0):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        print('Init using xavier')\n",
    "        self.model.apply(self.xavier_init)\n",
    "        self.uncert = 0\n",
    "        self.log_vars = None\n",
    "        \n",
    "        if uncert_mode>0:\n",
    "            print(\"Createing an Uncert network\")\n",
    "            self.uncert = uncert_mode\n",
    "            self.log_vars = nn.Parameter(torch.zeros((uncert_mode)))\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "    def forward(self, data, inference=True):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def loss(self, data, y_input, include_unsup=False):\n",
    "        uf, unsup_loss = self.forward(data)\n",
    "        mse_loss = F.mse_loss(uf, y_input)\n",
    "        if not include_unsup:\n",
    "            return mse_loss\n",
    "        \n",
    "        if self.uncert:\n",
    "            mse_loss = mse_loss.unsqueeze(0)\n",
    "            unsup_loss = unsup_loss.unsqueeze(0)\n",
    "            losses = torch.cat([mse_loss, unsup_loss])\n",
    "            weights = torch.exp(-self.log_vars)\n",
    "            return torch.dot(weights, losses)\n",
    "        \n",
    "        return mse_loss + unsup_loss\n",
    "    \n",
    "    def get_gradients_dict(self, x, t):\n",
    "        self.eval()\n",
    "        \n",
    "        uf, _ = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        return {'uf':uf, 'u_x':u_x, 'u_xx':u_xx, 'u_tt':u_tt, 'u_xt':u_xt, 'u_tx':u_tx}, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df16fac6-ca81-49fb-b2bb-a3a58b87f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LadderNetwork(\n",
       "  (encoder): Encoder(\n",
       "    (stacked_layers): Sequential(\n",
       "      (layer_0): LinearLayer(\n",
       "        (linear): Linear(in_features=2, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_1): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_2): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_3): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_4): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (stacked_layers): Sequential(\n",
       "      (layer_0): DecoderLayer(\n",
       "        (V): Linear(in_features=1, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_1): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_2): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_3): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_4): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_decoder): DecoderLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in, hidden_nodes, d_out = 2, 50, 1\n",
    "bias = True, True\n",
    "n_layers = 4\n",
    "activation_function = torch.tanh\n",
    "noise_std = 0.01\n",
    "uncert_mode = 2\n",
    "\n",
    "model = LadderNetwork(d_in=d_in, hidden_dims=hidden_nodes, n_layers=n_layers,\n",
    "                      d_out=d_out, bias=bias, activation_function=activation_function, \n",
    "                      noise_std=noise_std)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05587d16-e383-44ca-a70b-5c331ecd84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate finding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42441d21d41e462aa3b72fc95768aa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 3.70E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init using xavier\n",
      "Createing an Uncert network\n"
     ]
    }
   ],
   "source": [
    "print('Learning rate finding')\n",
    "bs = 4000\n",
    "bs = N if bs>N else bs\n",
    "criterion = LadderUncertLoss(n_task=2)\n",
    "tmp_optimizer = SGDGC(model.parameters(), lr=1e-7, use_gc=True, nesterov=True, momentum=0.9)\n",
    "trainloader = get_dataloader(X_u_train, u_train, bs=4000)\n",
    "lr_finder = LRFinder(model, optimizer=tmp_optimizer, criterion=criterion, device=\"cpu\")\n",
    "lr_finder.range_test(trainloader, val_loader=None, end_lr=100, num_iter=300)\n",
    "_, suggested_lr = lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "\n",
    "lr_finder.reset()\n",
    "network = Network(model=model, uncert_mode=uncert_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed52cdc-944f-4151-8b55-b283437ac94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pcgrad_closure():\n",
    "#     n_obj = 2 # There are two tasks\n",
    "#     losses = network.loss(X_u_train, u_train, include_unsup=True)\n",
    "#     updated_grads = []\n",
    "    \n",
    "#     for i in range(n_obj):\n",
    "#         optimizer1.zero_grad()\n",
    "#         losses[i].backward(retain_graph=True)\n",
    "\n",
    "#         g_task = []\n",
    "#         for param in network.parameters():\n",
    "#             if param.grad is not None:\n",
    "#                 g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "#             else:\n",
    "#                 g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "#         # appending the gradients from each task\n",
    "#         updated_grads.append(g_task)\n",
    "\n",
    "#     updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "#     for idx, param in enumerate(network.parameters()): \n",
    "#         param.grad = (updated_grads[0][idx]+updated_grads[1][idx]).requires_grad_(True)\n",
    "        \n",
    "#     return sum(losses)\n",
    "\n",
    "def uncert_closure():\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer1.zero_grad()\n",
    "    l = network.loss(X_u_train, u_train, include_unsup=True)\n",
    "    if l.requires_grad:\n",
    "        l.backward()\n",
    "    return l\n",
    "\n",
    "def closure():\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad()\n",
    "    l = network.loss(X_u_train, u_train, include_unsup=False)\n",
    "    if l.requires_grad:\n",
    "        l.backward()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbf6d4-48d7-4ae0-8a98-d460f579f020",
   "metadata": {},
   "source": [
    "### Copy weights from network.model.encoder and build a new feedforward model!\n",
    "### Change a model architecture? (ResNet, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb084ec-3f9c-4563-8fb8-36b46382a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using the lookahead option\n",
      "1st Phase optimization using SGDGC/AdamGC with PCGrad gradient modification\n",
      "Epoch 0:  0.8087694048881531\n",
      "Epoch 10:  0.32052838802337646\n",
      "Epoch 20:  0.16696465015411377\n",
      "Epoch 30:  0.10699272155761719\n",
      "Epoch 40:  0.08011902868747711\n",
      "Epoch 50:  0.06551286578178406\n",
      "Epoch 60:  0.05629907548427582\n",
      "Epoch 70:  0.0498032420873642\n",
      "Epoch 80:  0.044864408671855927\n",
      "Epoch 90:  0.04093877971172333\n",
      "Epoch 100:  0.037690505385398865\n",
      "Epoch 110:  0.03495460003614426\n",
      "Epoch 120:  0.03262503445148468\n",
      "Epoch 130:  0.030591662973165512\n",
      "Epoch 140:  0.028817277401685715\n",
      "Epoch 150:  0.027242396026849747\n",
      "Epoch 160:  0.025835689157247543\n",
      "Epoch 170:  0.02457307279109955\n",
      "Epoch 180:  0.023427508771419525\n",
      "Epoch 190:  0.022392548620700836\n",
      "Epoch 200:  0.021447323262691498\n",
      "Epoch 210:  0.02057936228811741\n",
      "Epoch 220:  0.01978171616792679\n",
      "Epoch 230:  0.019041571766138077\n",
      "Epoch 240:  0.018357515335083008\n",
      "Epoch 250:  0.017730016261339188\n",
      "Epoch 260:  0.01713201031088829\n",
      "Epoch 270:  0.016582142561674118\n",
      "Epoch 280:  0.01606716401875019\n",
      "Epoch 290:  0.015574922785162926\n",
      "Epoch 300:  0.015117477625608444\n",
      "Epoch 310:  0.014693954959511757\n",
      "Epoch 320:  0.014286018908023834\n",
      "Epoch 330:  0.013905348256230354\n",
      "Epoch 340:  0.013542814180254936\n",
      "Epoch 350:  0.013197576627135277\n",
      "Epoch 360:  0.012869685888290405\n",
      "Epoch 370:  0.01255861483514309\n",
      "Epoch 380:  0.01226755604147911\n",
      "Epoch 390:  0.011983005329966545\n",
      "Epoch 400:  0.011710943654179573\n",
      "Epoch 410:  0.011451121419668198\n",
      "Epoch 420:  0.011206426657736301\n",
      "Epoch 430:  0.010971428826451302\n",
      "Epoch 440:  0.010747413150966167\n",
      "Epoch 450:  0.010526292957365513\n",
      "Epoch 460:  0.010324669070541859\n",
      "Epoch 470:  0.010124031454324722\n",
      "Epoch 480:  0.00993035826832056\n",
      "Epoch 490:  0.009745188057422638\n",
      "Epoch 500:  0.009569233283400536\n",
      "Epoch 510:  0.009397606365382671\n",
      "Epoch 520:  0.009231999516487122\n",
      "Epoch 530:  0.009073549881577492\n",
      "Epoch 540:  0.008915621787309647\n",
      "Epoch 550:  0.008766284212470055\n",
      "Epoch 560:  0.008623490110039711\n",
      "Epoch 570:  0.00848410464823246\n",
      "Epoch 580:  0.008348232135176659\n",
      "Epoch 590:  0.008220843970775604\n",
      "Epoch 600:  0.00809051189571619\n",
      "Epoch 610:  0.007967811077833176\n",
      "Epoch 620:  0.007850157096982002\n",
      "Epoch 630:  0.007733083330094814\n",
      "Epoch 640:  0.007619486190378666\n",
      "Epoch 650:  0.007517523597925901\n",
      "Epoch 660:  0.007405977230519056\n",
      "Epoch 670:  0.0073044090531766415\n",
      "Epoch 680:  0.0072042872197926044\n",
      "Epoch 690:  0.007107563316822052\n",
      "Epoch 700:  0.0070151686668396\n",
      "Epoch 710:  0.006919892504811287\n",
      "Epoch 720:  0.006830766797065735\n",
      "Epoch 730:  0.006742104887962341\n",
      "Epoch 740:  0.0066564492881298065\n",
      "Epoch 750:  0.006573633756488562\n",
      "Epoch 760:  0.0064940862357616425\n",
      "Epoch 770:  0.006415212992578745\n",
      "Epoch 780:  0.006337177939713001\n",
      "Epoch 790:  0.006263704039156437\n",
      "Epoch 800:  0.006188644096255302\n",
      "Epoch 810:  0.006118375808000565\n",
      "Epoch 820:  0.006049097049981356\n",
      "Epoch 830:  0.005977004766464233\n",
      "Epoch 840:  0.005912670865654945\n",
      "Epoch 850:  0.0058465683832764626\n",
      "Epoch 860:  0.005781394429504871\n",
      "Epoch 870:  0.005717439576983452\n",
      "Epoch 880:  0.005658144596964121\n",
      "Epoch 890:  0.005600143689662218\n",
      "Epoch 900:  0.005537539720535278\n",
      "Epoch 910:  0.005480298772454262\n",
      "Epoch 920:  0.005423344671726227\n",
      "Epoch 930:  0.005369858350604773\n",
      "Epoch 940:  0.005315021611750126\n",
      "Epoch 950:  0.005261346697807312\n",
      "Epoch 960:  0.005213446915149689\n",
      "Epoch 970:  0.005159766413271427\n",
      "Epoch 980:  0.005108766257762909\n",
      "Epoch 990:  0.005059943534433842\n",
      "Epoch 999:  0.005018787458539009\n",
      "2nd Phase optimization using LBFGS\n",
      "Epoch 0:  0.036149993538856506\n",
      "Epoch 10:  9.07348221517168e-05\n",
      "Epoch 20:  1.700961365713738e-05\n",
      "Epoch 30:  5.237722689344082e-06\n",
      "Epoch 40:  2.147707618860295e-06\n",
      "Epoch 50:  2.127292646036949e-06\n",
      "Epoch 60:  2.127292646036949e-06\n",
      "Epoch 70:  2.127292646036949e-06\n",
      "Epoch 80:  2.127292646036949e-06\n",
      "Epoch 90:  2.127292646036949e-06\n",
      "Epoch 100:  2.127292646036949e-06\n",
      "Epoch 110:  2.127292646036949e-06\n",
      "Epoch 120:  2.127292646036949e-06\n",
      "Epoch 130:  2.127292646036949e-06\n",
      "Epoch 140:  2.127292646036949e-06\n",
      "Epoch 150:  2.127292646036949e-06\n",
      "Epoch 160:  2.127292646036949e-06\n",
      "Epoch 170:  2.127292646036949e-06\n",
      "Epoch 180:  2.127292646036949e-06\n",
      "Epoch 190:  2.127292646036949e-06\n",
      "Epoch 200:  2.127292646036949e-06\n",
      "Epoch 210:  2.127292646036949e-06\n",
      "Epoch 220:  2.127292646036949e-06\n",
      "Epoch 230:  2.127292646036949e-06\n",
      "Epoch 240:  2.127292646036949e-06\n",
      "Epoch 250:  2.127292646036949e-06\n",
      "Epoch 260:  2.127292646036949e-06\n",
      "Epoch 270:  2.127292646036949e-06\n",
      "Epoch 280:  2.127292646036949e-06\n",
      "Epoch 290:  2.127292646036949e-06\n",
      "Epoch 299:  2.127292646036949e-06\n"
     ]
    }
   ],
   "source": [
    "lookahead = False \n",
    "\n",
    "# optimizer1 = torch.optim.Adam(network.parameters(), lr=5e-3, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "# optimizer1 = torch.optim.SGD(network.parameters(), lr=5e-3)\n",
    "optimizer1 = SGDGC(network.parameters(), lr=suggested_lr, use_gc=True, nesterov=True, momentum=0.9)\n",
    "if lookahead:\n",
    "    print(\"Using the lookahead option\")\n",
    "    optimizer1 = Lookahead(optimizer1)\n",
    "else:\n",
    "    print(\"Not using the lookahead option\")\n",
    "    \n",
    "epochs1 = 1000 # How long this should be ??? (500 and 1000 seem to be a good number.)\n",
    "network.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using SGDGC/AdamGC with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(uncert_closure)\n",
    "    l = uncert_closure()\n",
    "    \n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "\n",
    "if not bias[0]:\n",
    "    print('Adding encoder biases.')\n",
    "    # Loading weights to a new encoder model with biases\n",
    "    # The bias for decoder could be whatever you want, it doesn't matter.\n",
    "    model = LadderNetwork(d_in=d_in, hidden_dims=hidden_nodes, n_layers=n_layers,\n",
    "                          d_out=d_out, bias=(True, False), activation_function=activation_function, \n",
    "                          noise_std=noise_std)\n",
    "\n",
    "    # Reinit the biases as 0.01\n",
    "    model.load_state_dict(network.model.state_dict(), strict=False)\n",
    "\n",
    "    # delete the old one and create the new network\n",
    "    del network\n",
    "    network = Network(model=model, uncert_mode=uncert_mode)\n",
    "\n",
    "# 2nd Phase optimizer\n",
    "optimizer2 = torch.optim.LBFGS(network.parameters(), lr=5e-3, max_iter=80, max_eval=100, history_size=120, line_search_fn='strong_wolfe')\n",
    "epochs2 = 300\n",
    "curr_loss = None\n",
    "\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    \n",
    "    # To early stop from the loop\n",
    "    if l.item() != curr_loss: curr_loss = l.item()\n",
    "    else: break\n",
    "\n",
    "    if (i % 10) == 0 or i == epochs2-1:\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793113b0-1d5e-40ce-8c2f-eac8849809f4",
   "metadata": {},
   "source": [
    "### Evaluate the MSE loss comparing btw with & without the sparsity (Average the results from 5 evaluations?)\n",
    "### The better one would benefit the Symbolic regression process to recover PDE relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f3b87c-4bdb-420f-a06a-3af679215353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.836991360614775e-06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncert seems to also have large generalization gap with LBFGS[lr=5e-2,1e-1,] \n",
    "# but not for 5e-3. The generalization gap is smaller (quite small actually). \n",
    "# So, the learning rate does matter here.\n",
    "((network(X_star)[0].detach() - u_star)**2).mean().item()\n",
    "\n",
    "### Notes on the results ###\n",
    "# PCGrad, BEST-full: 5.905130819883198e-07\n",
    "# Uncert BEST-2000: 2.730447477006237e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d137c-cc28-40df-bec2-965039b94fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aeced3-aad9-434e-85ed-f7eb0442cb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adeed16-b489-46ea-9094-39c3e88f6588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6301161-029e-4c32-9fc0-13fd3bda248b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8326215-7302-4b43-97ed-0b74d6dd3a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394a548-79be-4e2b-a8d5-5014f19bc41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6b5b7-5ec1-4ea7-bfd1-be63b27ea133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a8411a8-268b-4828-8a17-baa2613b8932",
   "metadata": {},
   "source": [
    "### Precise pde parameters recovery using the PINN technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555db227-afe4-4111-b938-fac890a5b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_1_init, lambda_2_init = network.get_theta(X_u_train[:, 0:1], X_u_train[:, 1:2])\n",
    "# network.set_lambdas(lambda_1_init, lambda_2_init)\n",
    "\n",
    "lambda_1_init = 0.6860763\n",
    "lambda_2_init = np.log(0.0020577204)\n",
    "\n",
    "### Choosing btw reset model weights or pretraining ###\n",
    "network = Network(model=model, lambda_1_init=lambda_1_init, lambda_2_init=lambda_2_init)\n",
    "optimizer = torch.optim.LBFGS(network.parameters(), lr=5e-2, max_iter=50, max_eval=50, line_search_fn='strong_wolfe')\n",
    "\n",
    "network.train(); best_train_loss = 1e6\n",
    "for i in range(epochs):\n",
    "    ### Add the closure function to calculate the gradient. For LBFGS.\n",
    "    def closure():\n",
    "        if torch.is_grad_enabled():\n",
    "            optimizer.zero_grad()\n",
    "        l = network.loss(X_u_train[:, 0:1], X_u_train[:, 1:2], u_train, is_pde_parameters_update=True)\n",
    "        if l.requires_grad:\n",
    "            l.backward()\n",
    "        return l\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    # calculate the loss again for monitoring\n",
    "    l = closure()\n",
    "\n",
    "    if i > 400 and float(l.item()) < best_train_loss:\n",
    "        torch.save(network.state_dict(), 'nn_with_physical_reg_from_symreg.pth')\n",
    "        best_train_loss = float(l.item())\n",
    "\n",
    "    if (i % 100) == 0:\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486df7a-545a-479e-a6a2-17f4e4f08a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the best weights ###\n",
    "network.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4396c38-e6db-4a06-ad56-2671e9e50b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979fe15-f6b2-48a0-9cf2-40de0425d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "\n",
    "error_lambda_1 = np.abs(network.lambda_1.detach().item() - 1.0)*100\n",
    "error_lambda_2 = np.abs(torch.exp(network.lambda_2).detach().item() - nu) / nu * 100\n",
    "\n",
    "error_lambda_1, error_lambda_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1a11b-4464-40ad-8fdd-0ef159cd21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0, network.lambda_1.detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80847f13-575d-4412-8d5e-01f8b3bd7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu, torch.exp(network.lambda_2).detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1646ad-717f-4832-be8f-ec8d3fbd5c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee919dd1-d31a-49ce-aacb-16b9ec4738c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9cc5c3-3778-49f7-b7f4-e702a7c531a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cee62-4fe5-4085-a98b-52fa4af504c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33c03a-e06b-4d1f-9aca-b34091cc5faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a750b88-7b16-415a-8da7-3752fad4849f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5241108-6e99-4e82-a944-bbc5e9edb255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a2efde-648e-42e8-adae-3e827e426e3b",
   "metadata": {},
   "source": [
    "### Symbolic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604816e6-3182-465c-be34-b56b95025166",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_dict, target = network.get_gradients_dict(X_u_train[:, 0:1], X_u_train[:, 1:2])\n",
    "index2features = grads_dict.keys()\n",
    "print(index2features)\n",
    "\n",
    "G = torch.cat(list(grads_dict.values()), dim=1).detach().numpy()\n",
    "target = torch.squeeze(target).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da011546-0de5-4d0d-befe-1be0c9405ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "equations = pysr(G, target, niterations=20, binary_operators=[\"plus\", \"sub\", \"mult\"], unary_operators=[], batching=True, procs=4, populations=10, npop=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99d0ba-1fdd-4d89-b8e6-b5396e40a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the one with best score => might be overfitting (the lowest loss)\n",
    "print(best(equations))\n",
    "# fn = best_callable(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63e5cd-e0e1-4af2-b994-bdf396484638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = equations.drop(labels='lambda_format', axis=1)\n",
    "df.to_pickle('./saved_path_inverse_burger/equations_from_pysr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1a67f-ef7c-43e7-a0ea-628ee193ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The one config that I used, and it was giving a good approx symbolic representation of the data. ###\n",
    "\n",
    "# (1)\n",
    "# est_gp = SymbolicRegressor(population_size=50000, generations=20, function_set=('add', 'sub', 'mul'),\n",
    "#                            p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "#                            p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "#                            verbose=1, low_memory=True, n_jobs=2)\n",
    "\n",
    "# (2)\n",
    "# est_gp = SymbolicRegressor(population_size=60000, generations=20, function_set=('add', 'sub', 'mul'),\n",
    "#                            p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "#                            p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "#                            verbose=1, low_memory=True, n_jobs=-1)\n",
    "\n",
    "# const_range=(-1. float(G.shape[1])) ?\n",
    "\n",
    "### Current experiment ###\n",
    "est_gp = SymbolicRegressor(population_size=60000, generations=25, function_set=('add', 'sub', 'mul'),\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                           p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "                           verbose=1, low_memory=True, n_jobs=-1)\n",
    "\n",
    "est_gp.fit(G, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9290ce-61ff-4ea3-9cbf-7a01733e9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_exp\n",
    "program = est_gp._program\n",
    "print(build_exp(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6d9f-c8d4-4c3d-8fe1-626a72c67691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import pickle_save\n",
    "# pickle_save(est_gp, './data/gp_symreg_with_noisy_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dfcc4-741e-4e69-938d-8d668dafb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exreacted equation (for further fine-tuning)\n",
    "# u_t + 0.6860763*uf*u_x - 0.0020577204*u_xx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
