{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01588b0a-2e22-4fc7-b853-2bdb0e7a02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from pysr import pysr, best, best_callable\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "from utils import *\n",
    "import pcgrad\n",
    "from ladder import LadderNetwork\n",
    "\n",
    "# AdamGC (Gradient centrailization) optimizer\n",
    "# Please also try learning finder. (Doesn't have to be included in the paper)\n",
    "from optimizers import Lookahead, AdamGC, SGDGC  # Not have to report Lookahead and GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f334226-14bc-4ba8-9f54-b313cfefdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1405080-bfff-4155-afdf-b5fe632bae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples: 2000\n"
     ]
    }
   ],
   "source": [
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:, None]\n",
    "x = data['x'].flatten()[:, None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print('The number of training samples:', str(N))\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx, :]\n",
    "\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0888bd-10cc-442b-9e97-9601fccc06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = model\n",
    "        print('Init using xavier')\n",
    "        self.model.apply(self.xavier_init)\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def loss(self, data, y_input, include_unsup=False):\n",
    "        total_loss = []\n",
    "        \n",
    "        uf, unsup_loss = self.forward(data)\n",
    "        \n",
    "        total_loss.append(F.mse_loss(uf, y_input))\n",
    "        if include_unsup: # or if unsup_loss: ?, lets chk\n",
    "            total_loss.append(unsup_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def get_gradients_dict(self, x, t):\n",
    "        self.eval()\n",
    "        \n",
    "        uf, _ = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        return {'uf':uf, 'u_x':u_x, 'u_xx':u_xx, 'u_tt':u_tt, 'u_xt':u_xt, 'u_tx':u_tx}, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f597beb8-deff-480c-8ec6-616bbe89f6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LadderNetwork(\n",
       "  (encoder): Encoder(\n",
       "    (stacked_layers): Sequential(\n",
       "      (layer_0): LinearLayer(\n",
       "        (linear): Linear(in_features=2, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_1): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_2): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_3): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_4): LinearLayer(\n",
       "        (linear): Linear(in_features=50, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (stacked_layers): Sequential(\n",
       "      (layer_0): DecoderLayer(\n",
       "        (V): Linear(in_features=1, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_1): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_2): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_3): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=50, bias=True)\n",
       "      )\n",
       "      (layer_4): DecoderLayer(\n",
       "        (V): Linear(in_features=50, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_decoder): DecoderLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in, hidden_nodes, d_out = 2, 50, 1\n",
    "bias = True, True\n",
    "n_layers = 4\n",
    "activation_function = torch.tanh\n",
    "noise_std = 0.01\n",
    "\n",
    "model = LadderNetwork(d_in=d_in, hidden_dims=hidden_nodes, n_layers=n_layers,\n",
    "                      d_out=d_out, bias=bias, activation_function=activation_function, \n",
    "                      noise_std=noise_std)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96666527-e474-4cb8-b116-5b4fbc57b240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate finding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0227ccd2b7e442a8133da1289ff1026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 3.70E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxqUlEQVR4nO3daXgUZfb38e/pTkiAQAgQEcIWMSg7SAwCiqgDIqgs4wKKihuiguPoOKMzLog6+vxdxtFBBRVRFBBxVFQUHUWUTQiLsgmERQighJ0AWfs8L7rBJnQwga5U0jmfi77SdVdV97npJL9U3bWIqmKMMcYU5XG7AGOMMeWTBYQxxpiQLCCMMcaEZAFhjDEmJAsIY4wxIVlAGGOMCSnK7QLCpW7dutq0aVO3yzDGmApl0aJFO1Q1MdS8iAmIpk2bkp6e7nYZxhhToYjIz8XNs11MxhhjQnI0IESkl4isFpEMEbk/xPwmIvKViPwoIt+ISMOgeTeIyNrA4wYn6zTGGHMsxwJCRLzAaOASoCUwSERaFlnsGeAtVW0LjAKeDKxbG3gE6ASkAY+ISIJTtRpjjDmWk2MQaUCGqq4HEJHJQF9gZdAyLYF7As9nAh8Gnl8MfKmquwLrfgn0AiY5WK8xlU5+fj6ZmZnk5OS4XYpxWGxsLA0bNiQ6OrrE6zgZEEnA5qDpTPxbBMF+AAYA/wb6AzVEpE4x6yYVfQMRGQoMBWjcuHHYCjemssjMzKRGjRo0bdoUEXG7HOMQVWXnzp1kZmaSnJxc4vXcHqT+C3C+iCwBzge2AIUlXVlVx6pqqqqmJiaGPErLGHMcOTk51KlTx8IhwokIderUKfWWopNbEFuARkHTDQNtR6jqVvxbEIhIHPBHVd0jIluA7kXW/caJInMLCpm1OgsRQQCPBwQh8A8RwSP+Nglqk6LzBQgs4wm8lgSvV+S5RwSPCNFewesRojwevJ7Q0/bDa5xk31+Vw4l8zk4GxEIgRUSS8QfDQOCa4AVEpC6wS1V9wAPAuMCsGcA/gwamewbmh93+nAKGTljkxEuHjUc4EhhRXiHKI3g9niNhEhPlISbKS2z00V9joj3EHv4a7SUm6revcTFRxMVGERcTRY3YKOJioo9Mx8VE4fXYLw0Tgip8/z1s2wb160OnTof/Ogqr559/nqFDh1KtWrWwv3ZJ7dmzh4kTJ3LHHXeUyfsdPperbt26dOnShblz557Q64wfP56ePXvSoEGDk67JsYBQ1QIRGY7/l70XGKeqK0RkFJCuqtPwbyU8KSIKfAvcGVh3l4g8hj9kAEYdHrAOt/iq0Xwy4lxUQVFUwaeK4v9ZAMWn/uca1H7U8yPL+Ns4/BpKYBn/fPitzadKoc//KDj8tdB35Hl+oVLoK8F0oZJb6CM3v5DcAh85+YXsPFBATtD04a85+b4S/79Uq+KlRmwUCdWqULt6FRKqV6FO9SrHTNerGUv9+Fiqx0TMOZemONOnw223wZ49/k1tnw9q1YIxY6B377C+1fPPP8/gwYNdD4iXXnrppAKioKCAqKjS/2ycaDiAPyBat25dvgMCQFWnA9OLtD0c9HwqMLWYdcfx2xaFY6K9HlonxTv9NuWCqpJX6CMnz8eBvAKycwvYn+P/mp1TQHZuPtm5hUee7z2Uz+6D+ew6kMeqrfvYdTCPPQfzQ752jZgoTo2P9T9qxtIwoRpN61ajSZ3qNK1TjVrVqpRxb01YTZ8OV1wBhw4d3Z6d7W+fOvWEQuLAgQNcddVVZGZmUlhYyEMPPcSvv/7K1q1bueCCC6hbty4zZ87kiy++4JFHHiE3N5dmzZrxxhtvEBcXx6JFi7jnnnvIzs6mbt26jB8/nvr169O9e3fatWvHrFmzKCgoYNy4caSlpXHgwAFGjBjB8uXLyc/PZ+TIkfTt25cVK1Zw4403kpeXh8/n4/333+ehhx5i3bp1tG/fnh49evD0008fVftjjz3G22+/TWJiIo0aNaJjx4785S9/oXv37rRv357Zs2czaNAgmjdvzuOPP05eXh516tThnXfeoV69euzcuZNBgwaxZcsWOnfuTPDdPePi4sjOzgbg6aefZsqUKeTm5tK/f38effRRNm7cyCWXXMK5557L3LlzSUpK4qOPPuLTTz8lPT2da6+9lqpVqzJv3jyqVq1a+s/7MFWNiEfHjh3VOC+/oFCz9ufoml/26ZyMLP1gcaa+NDNDH/louQ59a6Fe/p/ZmvbEl9rkb58c9Wg7coZe9uJ3etekxTp65lr9+qdfddueQ+rz+dzuUqW2cuXK31/I51NNStIjG9KhHg0b+pcrpalTp+ott9xyZHrPnj2qqtqkSRPNyspSVdWsrCw977zzNDs7W1VVn3rqKX300Uc1Ly9PO3furNu3b1dV1cmTJ+uNN96oqqrnn3/+kdedNWuWtmrVSlVVH3jgAZ0wYYKqqu7evVtTUlI0Oztbhw8frm+//baqqubm5urBgwd1w4YNR9YrasGCBdquXTs9dOiQ7tu3T08//XR9+umnj7z37bfffmTZXbt2Hfk+f/XVV/Wee+5RVdURI0boo48+qqqqn3zyiQJH+ly9enVVVZ0xY4beeuut6vP5tLCwUPv06aOzZs3SDRs2qNfr1SVLlqiq6pVXXnmkX+eff74uXLgwZN2hPm/8e3RC/l61/QKmVKK8HurGxVA3LoaUejWKXS4nv5DNuw6ycedBft55gJ93HmTjzgOkb9zNR0u3HlkuoVo0Z55akxb1a9KuUTxnNU6gYUJVGzgtT77/HvbuPf4ye/bAggX+MYlSaNOmDffeey9/+9vfuPTSSznvvPOOWWb+/PmsXLmSrl27ApCXl0fnzp1ZvXo1y5cvp0ePHgAUFhZSv379I+sNGjQIgG7durFv3z727NnDF198wbRp03jmmWcA/1FcmzZtonPnzjzxxBNkZmYyYMAAUlJSjlv3nDlz6Nu3L7GxscTGxnLZZZcdNf/qq68+8jwzM5Orr76abdu2kZeXd+Qw02+//Zb//ve/APTp04eEhGPPBf7iiy/44osv6NChAwDZ2dmsXbuWxo0bk5ycTPv27QHo2LEjGzduPG7NJ8ICwjgiNtpLSr0aIUNk76F8Vv+yn1Xb9vHTL/tYuW0/Exf8zLg5/jGSU2rE0LFJAh2bJNClWV1a1K9hgeGmbdv8Yw7H4/HA1q3HXyaE5s2bs3jxYqZPn86DDz7IRRddxMMPP3zUMqpKjx49mDTp6PNkly1bRqtWrZg3b17I1y76PSMiqCrvv/8+Z5xxxlHzWrRoQadOnfj000/p3bs3Y8aM4bTTTit1fw6rXr36kecjRozgnnvu4fLLL+ebb75h5MiRJX4dVeWBBx7gtttuO6p948aNxMTEHJn2er0cKrr7LwzcPg/CVELxVaNJS67NDV2a8uSAtnx0Z1eWj7yYT+86l8f6tqJLszos27KXxz9dRe8XvuPsJ77iz+8u5YMlmWTtz3W7/Mqnfn3/gPTx+HxwAoOiW7dupVq1agwePJj77ruPxYsXA1CjRg32798PwDnnnMOcOXPIyMgA/OMWa9as4YwzziArK+tIQOTn57NixYojr/3uu+8CMHv2bOLj44mPj+fiiy/mxRdfPLK/f8mSJQCsX7+e0047jbvuuou+ffvy448/HlVDUV27duXjjz8mJyeH7OxsPvnkk2L7uHfvXpKS/Of5vvnmm0fau3XrxsSJEwH47LPP2L179zHrXnzxxYwbN+7IeMSWLVvYvn37cf9Pj1d3adkWhCkXorweWjWIp1WDeK7r3BSAX/bmMDtjB9+tzeLbNVl8sMR/Gk3HJglc0vpULmlTn6RaJzEAZ0qmUyeIj/cPSBenVi1ISyv1Sy9btoz77rsPj8dDdHQ0L7/8MgBDhw6lV69eNGjQgJkzZzJ+/HgGDRpEbq7/D4THH3+c5s2bM3XqVO666y727t1LQUEBd999N61atQL8l5bo0KED+fn5jBvnP97loYce4u6776Zt27b4fD6Sk5P55JNPmDJlChMmTCA6OppTTz2Vv//979SuXZuuXbvSunVrLrnkkqMGqc8++2wuv/xy2rZtS7169WjTpg3x8aEPdhk5ciRXXnklCQkJXHjhhWzYsAGARx55hEGDBtGqVSu6dOkS8moQPXv2ZNWqVXTu3BnwD16//fbbeL3eYv9PhwwZwrBhw8IySC2Hk7SiS01NVbsfROTy+ZSV2/bxzertTF/2Cyu37QOgfaNa9GlTn34dkkisEfM7r2KKWrVqFS1atPj9BYs7igmgatUTPorJKd27d+eZZ54hNTXVsffIzs4mLi6OgwcP0q1bN8aOHctZZ53l2PuFQ6jPW0QWqWrI/yjbgjAVgscjtE6Kp3VSPMMvTGHjjgN8tvwXPlu+jSemr+L/ff4TF7U4hYFpjemWkmgn+oVb797+ECij8yAqgqFDh7Jy5UpycnK44YYbyn04nAjbgjAV3rqsbKYs3MzURZnsPJBH/fhYrj67EYPPaULdONuqOJ4Sb0Ecpuo/WmnrVv+YQ1qaI2dSG2eUdgvCAsJEjLwCH1+t+pVJCzfz3dosor0eBnRI4pbzkjn9lOIPya3MSh0QpkKzXUym0qoS5eGSNvW5pE191mVl8/rsDby/KJPJCzfTp0197roohTNOtaAoSlXtMOJK4EQ2BuwwVxORmiXG8c/+bZh7/4UMv+B0Zq3Jote/v+XOiYtZl3Wco3EqmdjYWHbu3HlCvzxMxaGB+0HExsaWaj3bxWQqhd0H8nht9nrGz9lIboGPazs15q6LUqhTycco7I5ylUdxd5SzMQhjAnZk5/KvL9cwacEmqleJ4q6LUhjStSnRXtuYNpXT8QLCfipMpVI3LoYn+rdhxt3d6Ng0gSemr+KyF2ez6Odjz2I1prKzgDCVUkq9Grwx5GxeGdyRvYfy+ePLc/n7B8vYnxP6cubGVEYWEKbSEhF6tT6V/91zPrecm8zkBZvo9fx3zM3Y4XZpxpQLFhCm0qseE8WDl7bkvWFdqBLl4ZrXvueRj5aTk1/odmnGuMoCwpiAjk0SmH7XedzYtSlvzvuZvv+Zw9pfw3NVTGMqIgsIY4JUreLlkcta8eZNaezIzuWy/8xmysLNdp6AqZQcDQgR6SUiq0UkQ0TuDzG/sYjMFJElIvKjiPQOtDcVkUMisjTweMXJOo0p6vzmiXz2p/M4q3ECf33/R+6b+qPtcjKVjmMBISJeYDRwCdASGCQiLYss9iAwRVU7AAOBl4LmrVPV9oHHMKfqNKY4p9SMZcLNnbjrohSmLsrkqjHz2Lon/HftMqa8cnILIg3IUNX1qpoHTAb6FllGgZqB5/FA6e9ZaIyDvB7hnh7NGXtdR9ZnHeCyF2ezYMMut8sypkw4GRBJwOag6cxAW7CRwGARyQSmAyOC5iUHdj3NEpFj72RuTBnq2epUPryzK/HVohn82vd8tHSL2yUZ4zi3B6kHAeNVtSHQG5ggIh5gG9A4sOvpHmCiiNQsurKIDBWRdBFJz8rKKtPCTeVz+ilxfHB7V9o3rsWfJi9l9MwMG7w2Ec3JgNgCNAqabhhoC3YzMAVAVecBsUBdVc1V1Z2B9kXAOqB50TdQ1bGqmqqqqYmJiQ50wZijxVeLZsLNafRt34CnZ6zm7x8so6DQ53ZZxjjCyYBYCKSISLKIVME/CD2tyDKbgIsARKQF/oDIEpHEwCA3InIakAKsd7BWY0osJsrLv65qz50XNGPSgs3c/GY62bkFbpdlTNg5FhCqWgAMB2YAq/AfrbRCREaJyOWBxe4FbhWRH4BJwBD1b7N3A34UkaXAVGCYqtrIoCk3PB7hvovP5J/92zA7YwfXvvY9ew7muV2WMWFll/s25iR9ufJX7nxnMaclVmfCzZ1IrFG57zFhKha73LcxDurRsh6vD0nl550HudrOlTARxALCmDA4LyWRt25OI2t/Lle+Mo+fdx5wuyRjTpoFhDFhcnbT2ky89RwO5hVw5SvzyNhuF/ozFZsFhDFh1KZhPO/e1hmfwqBXv2ddVrbbJRlzwiwgjAmz5vVqMOnWTvh8yjWvzmfjDtvdZComCwhjHJBSrwYTbz2H/EJl0Kvz2bTzoNslGVNqFhDGOOSMU2vw9s2dOJRfyKBX57N5l4WEqVgsIIxxUMsGNXn75k7sz8nnmtfms8UOgTUViAWEMQ5rnRTP27d0Ys/BfK55dT7b9lpImIrBAsKYMtC2YS3euimNndl5XPPq92zfl+N2Scb8LgsIY8pIh8YJvHnT2fy6L4drX/uendm5bpdkzHFZQBhThjo2qc3rN5zNpl0HGfz6ArvAnynXLCCMKWOdm9Xh1etTWbc9mxvGLWBfTr7bJRkTkgWEMS7o1jyRl649ixVb93HTGws5YPeTMOWQBYQxLvlDy3r8e2AHFm/azS1vppOTX+h2ScYcxQLCGBf1aVufZ69qx/wNOxk6YRG5BRYSpvywgDDGZf07NOSpAW34dk0WwycuId/ucW3KCQsIY8qBq89uzKi+rfhy5a/c/e5SCiwkTDkQ5XYBxhi/6zs3JSe/kH9O/4kYr4dnrmyHxyNul2UqMUe3IESkl4isFpEMEbk/xPzGIjJTRJaIyI8i0jto3gOB9VaLyMVO1mlMeTG0WzPu6dGc/y7Zwj8+XEak3DPeVEyObUGIiBcYDfQAMoGFIjJNVVcGLfYgMEVVXxaRlsB0oGng+UCgFdAA+J+INFdVG8EzEW/EhaeTW1DI6JnriIny8shlLRGxLQlT9pzcxZQGZKjqegARmQz0BYIDQoGagefxwNbA877AZFXNBTaISEbg9eY5WK8x5YKI8JeeZ5CT7+P12RuIifZwf68zLSRMmXMyIJKAzUHTmUCnIsuMBL4QkRFAdeAPQevOL7JukjNlGlP+iAgP9mlBbkEhY2atJ8br4c89mltImDLl9iD1IGC8qj4rIp2BCSLSuqQri8hQYChA48aNHSrRGHeICKMub01egY8Xvs4g36f89eIzLCRMmXEyILYAjYKmGwbagt0M9AJQ1XkiEgvULeG6qOpYYCxAamqqjeaZiOPxCE8NaEuU18PL36wjN9/HQ5e2sJAwZcLJo5gWAikikiwiVfAPOk8rsswm4CIAEWkBxAJZgeUGikiMiCQDKcACB2s1ptzyeIQn+rXmxq5NGTdnAw99tByfz/4eMs5zbAtCVQtEZDgwA/AC41R1hYiMAtJVdRpwL/CqiPwZ/4D1EPUf17dCRKbgH9AuAO60I5hMZSYiPHxpS2KivLwyax15BT6eHNAWr50nYRwkkXKcdWpqqqanp7tdhjGOUlX+/dVanv/fWi5r14Bnr2xHlSi7III5cSKySFVTQ81ze5DaGFMKIsLdf2hO1WgvT372E3sO5vHK4I5Uj7EfZRN+9qeHMRXQbec34/+uaMvcdTu55rXv2XXA7kxnws8CwpgK6qrURrwyuCM/bdvHFa/MZcueQ26XZCKMBYQxFViPlvWYcHMnsvbn8seX5rL6l/1ul2QiiAWEMRVcWnJtptzWGZ8qV7w8l9lrd7hdkokQFhDGRIAW9WvywZ1daVCrKkPeWMCUhZt/fyVjfocFhDERIqlWVd67vTOdm9Xhr+//yNMzfrIT6sxJsYAwJoLUjI1m3JCzGXh2I0bPXMef3l1KTr6dY2pOjB08bUyEifZ6eHJAGxrXqcb/fb6aX/YeYsx1qdSuXsXt0kwFY1sQxkQgEeGO7qfz4qAO/JC5lwEvzSFje7bbZZkKxgLCmAh2WbsGTLq1E/tzCuj/0hy+XZPldkmmArGAMCbCdWxSmw/v7EpSrarcOH4h4+dssHtdmxKxgDCmEmhUuxpTb+/CBWecwsiPV/KPD5eTX+hzuyxTzllAGFNJxMVEMfa6jgw7vxkTv9/E9a8vYLddw8kchwWEMZWIxyPcf8mZPHtlOxb9vJt+L80hY7tdnsOEZgFhTCX0x44NmTS0EwdyC+g/ei6zbPDahGABYUwldXjwumHtatz4xgLGzbbBa3M0CwhjKrGGCdWYOqwzf2hRj1GfrOTvH9jgtfmNBYQxlVz1mCheGdyRO7o3Y9KCTVz3ut2AyPhZQBhj8HiEv/Y6k+evbs/iTXu47MXZLN+y1+2yjMscDQgR6SUiq0UkQ0TuDzH/XyKyNPBYIyJ7guYVBs2b5mSdxhi/fh2SmDqsM6rKH1+ey/uLMt0uybhInBqUEhEvsAboAWQCC4FBqrqymOVHAB1U9abAdLaqxpX0/VJTUzU9Pf3kCzfGsDM7lzsnLmb++l1c37kJD/ZpSZUo2+EQiURkkaqmhprn5CeeBmSo6npVzQMmA32Ps/wgYJKD9RhjSqhOXAxv39yJW85N5q15P3Pta/PZvj/H7bJMGXMyIJKA4NtaZQbajiEiTYBk4Oug5lgRSReR+SLSr5j1hgaWSc/KsuO4jQmnKK+HBy9tyb8HtmfZlr1c+sJsFv282+2yTBkqL9uMA4Gpqhp8Z5Mmgc2ea4DnRaRZ0ZVUdayqpqpqamJiYlnVakyl0rd9Eh/c0ZXYaC8Dx86zi/1VIk4GxBagUdB0w0BbKAMpsntJVbcEvq4HvgE6hL9EY0xJtKhfk4+Hn0u3lERGfrySEZOWcCC3wO2yjMOcDIiFQIqIJItIFfwhcMzRSCJyJpAAzAtqSxCRmMDzukBXIOTgtjGmbMRXi+bV61O57+IzmL5sG5f/ZzZrf7XrOEUyxwJCVQuA4cAMYBUwRVVXiMgoEbk8aNGBwGQ9epu1BZAuIj8AM4Gnijv6yRhTdjwe4c4LTuftWzqx91A+fUfP4aOlxe0YMBWdY4e5ljU7zNWYsvXL3hyGT1xM+s+7ub5zE/7RpwUxUV63yzKl5NZhrsaYCHZqfCyThp5z5FDYq8bMZ8ueQ26XZcLIAsIYc8KiA4fCvjL4LNZtz+bSF76zS4dHEAsIY8xJ69W6PtOGd6VezViGvLGAf325hkJfZOy+rsxKFBAiUl1EPIHnzUXkchGJdrY0Y0xFclpiHB/c0ZX+HZL491drGfLGArsqbAVX0i2Ib/Gf2ZwEfAFcB4x3qihjTMVUtYqXZ69sx5MD2vD9hl1c+sJ3LNlkZ19XVCUNCFHVg8AA4CVVvRJo5VxZxpiKSkQYlNaY94d1weMRrhozj7fmbbSzryugEgeEiHQGrgU+DbTZ8WzGmGK1aRjPJyPO5byURB7+aAV/mrzUzr6uYEoaEHcDDwAfBE52Ow3/CWzGGFOsWtWq8Frg7OtPftxKv9Fz2LTzoNtlmRIq9YlygcHqOFXd50xJJ8ZOlDOmfJuTsYM7Jy5GgDHXpZKWXNvtkgxhOFFORCaKSE0RqQ4sB1aKyH3hLNIYE9m6nl6XD+/oSkL1Klz72nzeS9/8+ysZV5V0F1PLwBZDP+Az/PduuM6poowxkalp3ep8cHtXOiXX4b6pP/Lk9FV2vkQ5VtKAiA6c99APmKaq+YB9qsaYUouvFs0bN57Ndec0Ycy367ltwiIbvC6nShoQY4CNQHXg28Ad4MrVGIQxpuKI9np4rF9rHr28FV//9CtXvDKPrXYdp3KnRAGhqi+oapKq9la/n4ELHK7NGBPhbujSlDduTCNz10H6vzSHlVvt787ypKSD1PEi8tzh+z+LyLP4tyaMMeaknN88kfdu74xH/CfVzV67w+2STEBJdzGNA/YDVwUe+4A3nCrKGFO5nHlqTf57RxcaJlRlyBsLeH9RptslGUoeEM1U9RFVXR94PAqc5mRhxpjKpX58VaYM60yn02pz73s/8OJXa+3yHC4raUAcEpFzD0+ISFfARpSMMWFVMzaaN4ak0b9DEs9+uYa/f7CMgkKf22VVWlElXG4Y8JaIxAemdwM3OFOSMaYyqxLl4bmr2tGgViyjZ67jl705vHRtR6pWscu/lbWSHsX0g6q2A9oCbVW1A3Dh760nIr1EZLWIZIjI/SHm/0tElgYea0RkT9C8G0RkbeBhYWRMJSIi3HfxmTzerzXfrMli8Ovfs/dgvttlVTqlvhbTkRVFNqlq4+PM9wJrgB5AJrAQGKSqK4tZfgTQQVVvEpHaQDqQiv+EvEVAR1Ut9sLydi0mYyLT9GXbuHvyUpLrVuetm9OoVzPW7ZIiyklfi6m41/2d+WlARmBQOw+YDPQ9zvKDgEmB5xcDX6rqrkAofAn0OolajTEVVO829Rk35Gw27z7IFa/MZeOOA26XVGmcTED83qZHEhB8Na7MQNsxAmdmJwNfl2ZdERl6+NyMrCy7UboxkerclLpMvPUcsnMKuOKVeazYutftkiqF4waEiOwXkX0hHvuBBmGsYyAwVVULS7OSqo5V1VRVTU1MTAxjOcaY8qZ9o1q8N6wz0V5h4Jj5fL9+p9slRbzjBoSq1lDVmiEeNVT1946A2gI0CppuGGgLZSC/7V4q7brGmEri9FNqMPX2LiTWjOH6cQv438pf3S4pop3MLqbfsxBIEZFkEamCPwSmFV1IRM4EEoB5Qc0zgJ4ikiAiCUDPQJsxppJLqlWVqcO6cOapNbjt7UV21rWDHAsIVS0AhuP/xb4KmBK4XekoEbk8aNGBwGQNOpxKVXcBj+EPmYXAqECbMcZQu3oV3rn1HM4JnHU9Yf7PbpcUkU74MNfyxg5zNabyyckvZPjExfxv1XYe7NOCW86zKwCVllOHuRpjjKtio728dG1HLml9Ko9/uorRMzPcLimiWEAYYyq0KlEeXhzUgb7tG/D0jNU89+Uau8hfmJT0WkzGGFNuRXk9PHdVe2KiPLzw1VpyCwq5v9eZiPze+bzmeCwgjDERwesRnhrQlipRHsbMWk9uvo9HLmtpIXESLCCMMRHD4xEe69uamCgvr8/eQIHPx2N9W1tInCALCGNMRBERHuzTgiivMGbWeqI8HtuSOEEWEMaYiCMi3N/rTAoLlddmb8Dr8YeGhUTpWEAYYyKSiPCPPi0o8Cmvz95AlEe4/xIbuC4NCwhjTMQSER65rCUFPh9jvl1PlFf4S88zLCRKyALCGBPRRIRRl7em0AejZ64jyuPhzz2au11WhWABYYyJeB6P8ES/1hT6fPz7q7VEeYQRF6W4XVa5ZwFhjKkUPB7hyQFtKfApz365hrjYKG7smux2WeWaBYQxptLweoT/+2NbsnMKePTjlSRUq0K/DiFvdGmwazEZYyqZKK+HFwZ1oPNpdfjLez/w9U9206HiWEAYYyqd2GgvY6/vSIv6Nbn97cUs3Gi3mwnFAsIYUynViI1m/I1nk1SrKjeNX8jKrfvcLqncsYAwxlRadeJimHBLJ+JiorjhjQVs2XPI7ZLKFQsIY0ylllSrKm/elEZOXiE3j1/I/px8t0sqNywgjDGVXvN6NXh5cEcytmdz58QlFBT63C6pXHA0IESkl4isFpEMEbm/mGWuEpGVIrJCRCYGtReKyNLAY5qTdRpjzLkpdXm8X2u+XZPFI9NW2F3pcPA8CBHxAqOBHkAmsFBEpqnqyqBlUoAHgK6qultETgl6iUOq2t6p+owxpqiBaY35eddBXv5mHcl1q3PLeae5XZKrnNyCSAMyVHW9quYBk4G+RZa5FRitqrsBVHW7g/UYY8zvuq/nGfRpU58npq/i8+W/uF2Oq5wMiCRgc9B0ZqAtWHOguYjMEZH5ItIraF6siKQH2vs5WKcxxhzh8QjPXtWOdg1rcc+Upaz+Zb/bJbnG7UHqKCAF6A4MAl4VkVqBeU1UNRW4BnheRJoVXVlEhgZCJD0rK6uMSjbGRLrYaC9jrutI9Zgohk5IZ+/Bynlkk5MBsQVoFDTdMNAWLBOYpqr5qroBWIM/MFDVLYGv64FvgA5F30BVx6pqqqqmJiYmhr8HxphKq17NWF4ZfBZb9xziT+8uodBX+QatnQyIhUCKiCSLSBVgIFD0aKQP8W89ICJ18e9yWi8iCSISE9TeFViJMcaUoY5NajPy8lZ8szqL575c7XY5Zc6xo5hUtUBEhgMzAC8wTlVXiMgoIF1VpwXm9RSRlUAhcJ+q7hSRLsAYEfHhD7Gngo9+MsaYsnJNWmOWZe5l9Mx1dGySwIVn1nO7pDIjkXKsb2pqqqanp7tdhjEmAuXkF9L/pbls23uI6XedR4NaVd0uKWxEZFFgvPcYbg9SG2NMuRcb7WX0NR3IL/AxYtIS8ivJmdYWEMYYUwKnJcbxzwFtWPTzbp75onKMR1hAGGNMCfVtn8Q1nRozZtZ6Zq2J/EPrLSCMMaYUHr60JSmnxHHfez+w+0Ce2+U4ygLCGGNKITbay/MD27P7YB4P/HdZRF/UzwLCGGNKqVWDeO7teQafr/iFqYsy3S7HMRYQxhhzAm497zQ6Jddm5LQVbNp50O1yHGEBYYwxJ8DrEZ67uj0eEf76/g/4IvBSHBYQxhhzgpJqVeUffVowf/0u3lmwye1yws4CwhhjTsLVZzfivJS6PDV9FZm7I2tXkwWEMcacBBHhyQFtACLuqCYLCGOMOUkNE6pxf+8WfLd2B+8u3Pz7K1QQFhDGGBMG16Y1plNybf45fRVZ+3PdLicsLCCMMSYMPB7hif5tOJRfyD+nr3K7nLCwgDDGmDA5/ZQ4hp3fjA+WbGFOxg63yzlpFhDGGBNGd15wOk3qVOPBD5eTk1/odjknxQLCGGPCKDbay2N9W7NhxwFembXO7XJOigWEMcaEWbfmiVzWrgEvzVzHhh0H3C7nhFlAGGOMAx66tAUx0R4e/LDinhthAWGMMQ44pUYsf+11JnMydjLth61ul3NCHA0IEeklIqtFJENE7i9mmatEZKWIrBCRiUHtN4jI2sDjBifrNMYYJ1yT1ph2DeN5/NNV7DuUB/Pnwwcf+L9WgK2KKKdeWES8wGigB5AJLBSRaaq6MmiZFOABoKuq7haRUwLttYFHgFRAgUWBdXc7Va8xxoSb1yM81q81/7rnebTRYMg9AB4P+HxQqxaMGQO9e7tdZrGc3IJIAzJUdb2q5gGTgb5FlrkVGH34F7+qbg+0Xwx8qaq7AvO+BHo5WKsxxjii7Y9zGfPRU8Tv/BWys2HfPv/XzEy44gqYPt3tEovlZEAkAcEXJckMtAVrDjQXkTkiMl9EepViXURkqIiki0h6Vlbk30DcGFPBqMLQoVTJK+bSG4cOwW23ldvdTW4PUkcBKUB3YBDwqojUKunKqjpWVVNVNTUxMdGZCo0x5kR9/z3s3Xv8ZfbsgQULyqSc0nIyILYAjYKmGwbagmUC01Q1X1U3AGvwB0ZJ1jXGmPJt2zb/mMPxeDywtXwe5eRkQCwEUkQkWUSqAAOBaUWW+RD/1gMiUhf/Lqf1wAygp4gkiEgC0DPQZowxFUf9+v4B6ePx+aBBg7Kpp5QcO4pJVQtEZDj+X+xeYJyqrhCRUUC6qk7jtyBYCRQC96nqTgAReQx/yACMUtVdTtVqjDGO6NQJ4uP9g9LFqVUL0tLKrKTSkIp6hl9Rqampmp6e7nYZxhhztOnT/UcrHTp0zCytWhWZOtXVQ11FZJGqpoaa5/YgtTHGRLbevWHqVGjYEOLioGZN8qtVZ2uNunz7xEvl+jwIx3YxGWOMCejdGzZt8h+ttHUrUfXrc/dSH2u3Z/P1gTwSqldxu8KQbAvCGGPKgoh/TKJ/f+Scc3isXxv25RTwfzNWu11ZsSwgjDHGBWecWoMbuzRl8sJNLN28x+1yQrKAMMYYl9zdozmn1IjhwQ+XUegrfwcMWUAYY4xL4mKi+Eeflizfso+JCza5Xc4xLCCMMcZFl7WtT5dmdXj685/I2l/MNZtcYgFhjDEuEhFG9W1NToGPhz5cXq7uPmcBYYwxLjv9lDj+/IfmfL7iFz75cZvb5RxhAWGMMeXArecl065RLR7+aHm52dVkAWGMMeVAlNfDs1e25UBeYbnZ1WQBYYwx5cTpp9Tgnh7+XU0fLXX/EuAWEMYYU47ccm4yqU0S+McHy9iw44CrtVhAGGNMORLl9fDCoA5ER3kYPnExuQWFrtViAWGMMeVMg1pVeeaKdqzYuo8np//kWh0WEMYYUw79oWU9bj43mfFzN/L5cncOfbWAMMaYcupvvc6kXcN47p3yA6u27Svz97eAMMaYcqpKlIcx16USFxvFLW+ml/n5ERYQxhhTjp0aH8ur16ey80Auw95eRE5+2Q1aOxoQItJLRFaLSIaI3B9i/hARyRKRpYHHLUHzCoPapzlZpzHGlGdtG9bi2Svbs+jn3dz//o/4yujS4I7dclREvMBooAeQCSwUkWmqurLIou+q6vAQL3FIVds7VZ8xxlQkfdrWZ8OO5jzzxRoSqlfh4UtbIiKOvqeT96ROAzJUdT2AiEwG+gJFA8IYY0wJ3HnB6ew8kMcbczYSXzWau//Q3NH3c3IXUxKwOWg6M9BW1B9F5EcRmSoijYLaY0UkXUTmi0i/UG8gIkMDy6RnZWWFr3JjjCmHRISH+rTkio4Nef5/axk3e4Oj7+f2IPXHQFNVbQt8CbwZNK+JqqYC1wDPi0izoiur6lhVTVXV1MTExLKp2BhjXOTxCE8NaEOvVqcy6pOVjJ/jXEg4GRBbgOAtgoaBtiNUdaeqHj5u6zWgY9C8LYGv64FvgA4O1mqMMRVGlNfDvwe15+JW9Rj58UpGz8xw5H2cDIiFQIqIJItIFWAgcNTRSCJSP2jycmBVoD1BRGICz+sCXbGxC2OMOSImysvoa86iX/sGLN28h0IHjmxybJBaVQtEZDgwA/AC41R1hYiMAtJVdRpwl4hcDhQAu4AhgdVbAGNExIc/xJ4KcfSTMcZUalFeD89d1Z4Cn+L1hP+IJikPN6UIh9TUVE1PT3e7DGOMqVBEZFFgvPcYbg9SG2OMKacsIIwxxoRkAWGMMSYkCwhjjDEhWUAYY4wJyQLCGGNMSBYQxhhjQoqY8yBEJAv4+SReIh7YexLLhJpXtO1406Ge1wV2/E5NJ1pvSZeLxH6VtL0k/QpuK4t+nexnVbStJM8rQr/K+nuwuLpKs0x56VcTVQ19MTtVtYc/JMeezDKh5hVtO950qOf4zzh3tE+VsV8lbS9Jv4q0Od6vk/2sSvL5VMR+lfX3YCT3K/hhu5h+8/FJLhNqXtG2400X9/xklPR1Klu/Stpekn6Fq08lfa2T/ayKtjn9WZX0tSra92BJX6si9uuIiNnFFIlEJF2LOQW+IrN+VSyR2K9I7BOEv1+2BVG+jXW7AIdYvyqWSOxXJPYJwtwv24IwxhgTkm1BGGOMCckCwhhjTEgWEMYYY0KygKigRMQjIk+IyIsicoPb9YSLiHQXke9E5BUR6e52PeEiItVFJF1ELnW7lnARkRaBz2mqiNzudj3hIiL9RORVEXlXRHq6XU+4iMhpIvK6iEwt6ToWEC4QkXEisl1Elhdp7yUiq0UkQ0Tu/52X6Qs0BPKBTKdqLY0w9UuBbCCWctCvMPUJ4G/AFGeqLL1w9EtVV6nqMOAq/PeNd12Y+vWhqt4KDAOudrLekgpTv9ar6s2lel87iqnsiUg3/L8E31LV1oE2L7AG6IH/F+NCYBD++3k/WeQlbgo8dqvqGBGZqqpXlFX9xQlTv3aoqk9E6gHPqeq1ZVV/KGHqUzugDv7Q26Gqn5RN9cULR79UdXvgnvK3AxNUdWJZ1V+ccPUrsN6zwDuquriMyi9WmPtV4t8XUeEp35SGqn4rIk2LNKcBGaq6HkBEJgN9VfVJ4JjdEiKSCeQFJgsdLLfEwtGvILuBGEcKLYUwfVbdgepAS+CQiExXVZ+Tdf+ecH1WqjoNmCYinwKuB0SYPi8BngI+Kw/hAGH/2SoxC4jyIwnYHDSdCXQ6zvL/BV4UkfOAb50s7CSVql8iMgC4GKgF/MfRyk5cqfqkqv8AEJEhBLaQHK3uxJX2s+oODMAf5NOdLOwklfZnawTwByBeRE5X1VecLO4klPbzqgM8AXQQkQcCQXJcFhAVlKoeBEq1P7EiUNX/4g+/iKOq492uIZxU9RvgG5fLCDtVfQF4we06wk1Vd+IfVykxG6QuP7YAjYKmGwbaKrpI7Fck9gmsXxWN4/2ygCg/FgIpIpIsIlWAgcA0l2sKh0jsVyT2CaxfFY3j/bKAcIGITALmAWeISKaI3KyqBcBwYAawCpiiqivcrLO0IrFfkdgnsH5Zv0r4vnaYqzHGmFBsC8IYY0xIFhDGGGNCsoAwxhgTkgWEMcaYkCwgjDHGhGQBYYwxJiQLCBPxRCS7jN9vbhm/Xy0RuaMs39NUDhYQxpSSiBz3Gmaq2qWM37MWYAFhws4CwlRKItJMRD4XkUXiv4PdmYH2y0TkexFZIiL/C9yXAhEZKSITRGQOMCEwPU5EvhGR9SJyV9BrZwe+dg/MnyoiP4nIO4FLSSMivQNti0TkBRE55h4RIjJERKaJyNfAVyISJyJfichiEVkmIn0Diz4FNBORpSLydGDd+0RkoYj8KCKPOvl/aSKXXc3VVFZjgWGqulZEOgEvARcCs4FzVFVF5Bbgr8C9gXVaAueq6iERGQmcCVwA1ABWi8jLqppf5H06AK2ArcAcoKuIpANjgG6quiFwGYXinAW0VdVdga2I/qq6T0TqAvNFZBpwP9BaVdsDiP82mSn47xcg+O/X0E1Vy/Nl4U05ZAFhKh0RiQO6AO8F/qCH325O1BB4V0TqA1WADUGrTlPVQ0HTn6pqLpArItuBehx7m9QFqpoZeN+lQFP8dwZbr6qHX3sSMLSYcr9U1V2HSwf+Kf67i/nw3w+gXoh1egYeSwLTcfgDwwLClIoFhKmMPMCew39xF/Ei/ludTgvcEGdk0LwDRZbNDXpeSOifp5IsczzB73ktkAh0VNV8EdmI/zamRQnwpKqOKeV7GXMUG4MwlY6q7gM2iMiV4L/FpIi0C8yO57dr6t/gUAmrgdOCbiF5dQnXiwe2B8LhAqBJoH0//t1ch80AbgpsKSEiSSJyysmXbSob24IwlUE18d/D+7Dn8P81/rKIPAhEA5OBH/BvMbwnIruBr4HkcBcTGMO4A/hcRA7gv65/SbwDfCwiy4B04KfA6+0UkTkishz/fZTvE5EWwLzALrRsYDCwPdx9MZHNLvdtjAtEJE5VswNHNY0G1qrqv9yuy5hgtovJGHfcGhi0XoF/15GNF5hyx7YgjDHGhGRbEMYYY0KygDDGGBOSBYQxxpiQLCCMMcaEZAFhjDEmJAsIY4wxIf1/Znz65TEz8YgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Learning rate finding')\n",
    "bs = 4000\n",
    "bs = N if bs>N else bs\n",
    "criterion = LadderLoss()\n",
    "tmp_optimizer = SGDGC(model.parameters(), lr=1e-7, use_gc=True, nesterov=True, momentum=0.9)\n",
    "trainloader = get_dataloader(X_u_train, u_train, bs=4000)\n",
    "lr_finder = LRFinder(model, optimizer=tmp_optimizer, criterion=criterion, device=\"cpu\")\n",
    "lr_finder.range_test(trainloader, val_loader=None, end_lr=100, num_iter=300)\n",
    "_, suggested_lr = lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ccfd3a-1353-43d1-a286-aeea221a50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init using xavier\n"
     ]
    }
   ],
   "source": [
    "# Create the network\n",
    "network = Network(model=model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973af118-178f-477e-b2a1-d42a9123a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure():\n",
    "    n_obj = 2 # There are two tasks\n",
    "    losses = network.loss(X_u_train, u_train, include_unsup=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(n_obj):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in network.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(network.parameters()): \n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "#         param.grad = (updated_grads[0][idx]+updated_grads[1][idx]).requires_grad_(True)\n",
    "        \n",
    "    return sum(losses)\n",
    "\n",
    "def closure():\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad()\n",
    "    l = network.loss(X_u_train, u_train, include_unsup=False)[0]\n",
    "    if l.requires_grad:\n",
    "        l.backward()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d31ae1-c3ae-4be7-9c0a-eb1279539ea5",
   "metadata": {},
   "source": [
    "### Copy weights from network.model.encoder and build a new feedforward model!\n",
    "### Change a model architecture? (ResNet, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6797e381-a987-4838-817c-10c017d93c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using the lookahead option\n",
      "1st Phase optimization using SGD/Adam with PCGrad gradient modification\n",
      "Epoch 0:  0.7178621292114258\n",
      "Epoch 10:  0.5869560837745667\n",
      "Epoch 20:  0.5000008344650269\n",
      "Epoch 30:  0.4935041666030884\n",
      "Epoch 40:  0.48503804206848145\n",
      "Epoch 50:  0.4801144003868103\n",
      "Epoch 60:  0.47327136993408203\n",
      "Epoch 70:  0.4585772156715393\n",
      "Epoch 80:  0.42347151041030884\n",
      "Epoch 90:  0.36388298869132996\n",
      "Epoch 100:  0.31896787881851196\n",
      "Epoch 110:  0.3068297207355499\n",
      "Epoch 120:  0.29307249188423157\n",
      "Epoch 130:  0.2789275050163269\n",
      "Epoch 140:  0.2708604335784912\n",
      "Epoch 150:  0.26617422699928284\n",
      "Epoch 160:  0.26245543360710144\n",
      "Epoch 170:  0.25991272926330566\n",
      "Epoch 180:  0.25798702239990234\n",
      "Epoch 190:  0.2562295198440552\n",
      "Epoch 200:  0.25475215911865234\n",
      "Epoch 210:  0.25340062379837036\n",
      "Epoch 220:  0.25214728713035583\n",
      "Epoch 230:  0.25097477436065674\n",
      "Epoch 240:  0.2498430758714676\n",
      "Epoch 250:  0.24876131117343903\n",
      "Epoch 260:  0.24770504236221313\n",
      "Epoch 270:  0.24666035175323486\n",
      "Epoch 280:  0.2456265687942505\n",
      "Epoch 290:  0.24464119970798492\n",
      "Epoch 300:  0.24364180862903595\n",
      "Epoch 310:  0.24265193939208984\n",
      "Epoch 320:  0.2417083978652954\n",
      "Epoch 330:  0.24075809121131897\n",
      "Epoch 340:  0.23988530039787292\n",
      "Epoch 350:  0.23901595175266266\n",
      "Epoch 360:  0.2382081151008606\n",
      "Epoch 370:  0.2374458611011505\n",
      "Epoch 380:  0.23671069741249084\n",
      "Epoch 390:  0.23606173694133759\n",
      "Epoch 400:  0.2354513257741928\n",
      "Epoch 410:  0.23489931225776672\n",
      "Epoch 420:  0.2343686819076538\n",
      "Epoch 430:  0.23389840126037598\n",
      "Epoch 440:  0.2334555983543396\n",
      "Epoch 450:  0.23304946720600128\n",
      "Epoch 460:  0.2326815128326416\n",
      "Epoch 470:  0.23233655095100403\n",
      "Epoch 480:  0.23199313879013062\n",
      "Epoch 490:  0.23166576027870178\n",
      "Epoch 500:  0.2313787192106247\n",
      "Epoch 510:  0.23109635710716248\n",
      "Epoch 520:  0.23082533478736877\n",
      "Epoch 530:  0.23057520389556885\n",
      "Epoch 540:  0.2303583323955536\n",
      "Epoch 550:  0.23010197281837463\n",
      "Epoch 560:  0.22986525297164917\n",
      "Epoch 570:  0.2296571135520935\n",
      "Epoch 580:  0.22941750288009644\n",
      "Epoch 590:  0.22924818098545074\n",
      "Epoch 600:  0.22901694476604462\n",
      "Epoch 610:  0.22880980372428894\n",
      "Epoch 620:  0.22857414186000824\n",
      "Epoch 630:  0.2283620536327362\n",
      "Epoch 640:  0.22811046242713928\n",
      "Epoch 650:  0.22787758708000183\n",
      "Epoch 660:  0.22764040529727936\n",
      "Epoch 670:  0.22737224400043488\n",
      "Epoch 680:  0.22711704671382904\n",
      "Epoch 690:  0.2268700748682022\n",
      "Epoch 700:  0.2266198694705963\n",
      "Epoch 710:  0.22635725140571594\n",
      "Epoch 720:  0.22617730498313904\n",
      "Epoch 730:  0.22593393921852112\n",
      "Epoch 740:  0.22573067247867584\n",
      "Epoch 750:  0.2255532443523407\n",
      "Epoch 760:  0.22535914182662964\n",
      "Epoch 770:  0.22520151734352112\n",
      "Epoch 780:  0.22505605220794678\n",
      "Epoch 790:  0.22491011023521423\n",
      "Epoch 800:  0.22480013966560364\n",
      "Epoch 810:  0.22469253838062286\n",
      "Epoch 820:  0.22458256781101227\n",
      "Epoch 830:  0.22449903190135956\n",
      "Epoch 840:  0.22440974414348602\n",
      "Epoch 850:  0.2243252992630005\n",
      "Epoch 860:  0.22428244352340698\n",
      "Epoch 870:  0.22420842945575714\n",
      "Epoch 880:  0.22418507933616638\n",
      "Epoch 890:  0.2241150140762329\n",
      "Epoch 900:  0.22406291961669922\n",
      "Epoch 910:  0.22402232885360718\n",
      "Epoch 920:  0.22403478622436523\n",
      "Epoch 930:  0.22400535643100739\n",
      "Epoch 940:  0.2239963412284851\n",
      "Epoch 950:  0.22397534549236298\n",
      "Epoch 960:  0.22400300204753876\n",
      "Epoch 970:  0.2240666151046753\n",
      "Epoch 980:  0.22409993410110474\n",
      "Epoch 990:  0.2241562306880951\n",
      "Epoch 999:  0.22419819235801697\n",
      "2nd Phase optimization using LBFGS\n",
      "Epoch 0:  0.01361596118658781\n",
      "Epoch 10:  5.9364632761571556e-05\n",
      "Epoch 20:  9.405867785972077e-06\n",
      "Epoch 30:  2.5231033760064747e-06\n",
      "Epoch 40:  1.0969433787977323e-06\n",
      "Epoch 50:  1.0765807019197382e-06\n",
      "Epoch 60:  9.521036190562882e-07\n",
      "Epoch 70:  9.347220384370303e-07\n",
      "Epoch 80:  9.06071761619387e-07\n",
      "Epoch 90:  8.538114002476505e-07\n",
      "Epoch 100:  8.538114002476505e-07\n",
      "Epoch 110:  8.538114002476505e-07\n",
      "Epoch 120:  8.538114002476505e-07\n",
      "Epoch 130:  8.538114002476505e-07\n",
      "Epoch 140:  8.538114002476505e-07\n",
      "Epoch 150:  8.538114002476505e-07\n",
      "Epoch 160:  8.538114002476505e-07\n",
      "Epoch 170:  8.538114002476505e-07\n",
      "Epoch 180:  8.538114002476505e-07\n",
      "Epoch 190:  8.538114002476505e-07\n",
      "Epoch 200:  8.538114002476505e-07\n",
      "Epoch 210:  8.538114002476505e-07\n",
      "Epoch 220:  8.538114002476505e-07\n",
      "Epoch 230:  8.538114002476505e-07\n",
      "Epoch 240:  8.538114002476505e-07\n",
      "Epoch 250:  8.538114002476505e-07\n",
      "Epoch 260:  8.538114002476505e-07\n",
      "Epoch 270:  8.538114002476505e-07\n",
      "Epoch 280:  8.538114002476505e-07\n",
      "Epoch 290:  8.538114002476505e-07\n",
      "Epoch 299:  8.538114002476505e-07\n"
     ]
    }
   ],
   "source": [
    "lookahead = False \n",
    "\n",
    "# optimizer1 = torch.optim.Adam(network.parameters(), lr=5e-3, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "# optimizer1 = torch.optim.SGD(network.parameters(), lr=5e-3)\n",
    "optimizer1 = SGDGC(network.parameters(), lr=suggested_lr, use_gc=True, nesterov=True, momentum=0.9)\n",
    "if lookahead:\n",
    "    print(\"Using the lookahead option\")\n",
    "    optimizer1 = Lookahead(optimizer1)\n",
    "else:\n",
    "    print(\"Not using the lookahead option\")\n",
    "    \n",
    "epochs1 = 1000 # How long this should be ??? (500 seems to be a good number.)\n",
    "network.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using SGD/Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(pcgrad_closure)\n",
    "    l = pcgrad_closure()\n",
    "    \n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "\n",
    "if not bias[0]:\n",
    "    print('Adding encoder biases.')\n",
    "    # Loading weights to a new encoder model with biases\n",
    "    # The bias for decoder could be whatever you want, it doesn't matter.\n",
    "    model = LadderNetwork(d_in=d_in, hidden_dims=hidden_nodes, n_layers=n_layers,\n",
    "                          d_out=d_out, bias=(True, False), activation_function=activation_function, \n",
    "                          noise_std=noise_std)\n",
    "\n",
    "    # Reinit the biases as 0.01\n",
    "    model.load_state_dict(network.model.state_dict(), strict=False)\n",
    "\n",
    "    # delete the old one and create the new network\n",
    "    del network\n",
    "    network = Network(model=model, lambda_1_init=lambda_1_init, lambda_2_init=lambda_2_init)\n",
    "\n",
    "# 2nd Phase optimizer\n",
    "optimizer2 = torch.optim.LBFGS(network.parameters(), lr=5e-2, max_iter=80, max_eval=100, history_size=120, line_search_fn='strong_wolfe')\n",
    "epochs2 = 300\n",
    "cur_loss = None\n",
    "\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    \n",
    "    # To early stop from the loop\n",
    "    if cur_loss != l.item(): cur_loss = l.item()\n",
    "    else: break\n",
    "\n",
    "    if (i % 10) == 0 or i == epochs2-1:\n",
    "        print(\"Epoch {}: \".format(i), cur_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8dcd3-04f5-400c-9ea1-6317eef36b94",
   "metadata": {},
   "source": [
    "### Evaluate the MSE loss comparing btw with & without the sparsity (Average the results from 5 evaluations?)\n",
    "### The better one would benefit the Symbolic regression process to recover PDE relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3802d3d9-a25d-4674-afd2-e0ef3176c2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.473501465123263e-06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((network(X_star)[0].detach() - u_star)**2).mean().item()\n",
    "# BEST-full: 5.905130819883198e-07\n",
    "# BEST-2000: 2.4505434339516796e-06, 3.473501465123263e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79479aff-8d90-4541-941c-a15acf5d11fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e54cfc-7bc2-4652-9e6d-4b4a6de78181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d1dfc-6cb8-4a44-91bd-75cd6c5acea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f3763-baa9-453d-b920-df6a083b959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a38dee-e49c-4bcd-8402-29349a964954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eaf7dd-3eff-4799-bfbb-c5c3efd08c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64c7d5-7cfb-4d36-b99b-c3586ac44d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0add1f9-9cd7-4bdf-b5a1-55bf750a403c",
   "metadata": {},
   "source": [
    "### Precise pde parameters recovery using the PINN technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7dc94-8253-4ee6-9781-c17e2728b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_1_init, lambda_2_init = network.get_theta(X_u_train[:, 0:1], X_u_train[:, 1:2])\n",
    "# network.set_lambdas(lambda_1_init, lambda_2_init)\n",
    "\n",
    "lambda_1_init = 0.6860763\n",
    "lambda_2_init = np.log(0.0020577204)\n",
    "\n",
    "### Choosing btw reset model weights or pretraining ###\n",
    "network = Network(model=model, lambda_1_init=lambda_1_init, lambda_2_init=lambda_2_init)\n",
    "optimizer = torch.optim.LBFGS(network.parameters(), lr=5e-2, max_iter=50, max_eval=50, line_search_fn='strong_wolfe')\n",
    "\n",
    "network.train(); best_train_loss = 1e6\n",
    "for i in range(epochs):\n",
    "    ### Add the closure function to calculate the gradient. For LBFGS.\n",
    "    def closure():\n",
    "        if torch.is_grad_enabled():\n",
    "            optimizer.zero_grad()\n",
    "        l = network.loss(X_u_train[:, 0:1], X_u_train[:, 1:2], u_train, is_pde_parameters_update=True)\n",
    "        if l.requires_grad:\n",
    "            l.backward()\n",
    "        return l\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    # calculate the loss again for monitoring\n",
    "    l = closure()\n",
    "\n",
    "    if i > 400 and float(l.item()) < best_train_loss:\n",
    "        torch.save(network.state_dict(), 'nn_with_physical_reg_from_symreg.pth')\n",
    "        best_train_loss = float(l.item())\n",
    "\n",
    "    if (i % 100) == 0:\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07367905-4fd8-437c-a273-f7336fa04cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the best weights ###\n",
    "network.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05d873-7549-446c-a74d-54d6aa9a414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d61c0-ef35-49fd-ad92-bea99bea8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "\n",
    "error_lambda_1 = np.abs(network.lambda_1.detach().item() - 1.0)*100\n",
    "error_lambda_2 = np.abs(torch.exp(network.lambda_2).detach().item() - nu) / nu * 100\n",
    "\n",
    "error_lambda_1, error_lambda_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54aa2a5-710e-46f5-8911-9c11ec91d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0, network.lambda_1.detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9a904-9c5d-4357-a948-4030d36bc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu, torch.exp(network.lambda_2).detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc4d74-3c7e-4ad7-ac86-b8661e9fe4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15e257-03d1-4028-8cf0-5117623cca0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c927fc-f993-40b7-85d6-41a94ee58a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69daf27d-ae44-497e-af18-99571086c455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d481e-f32e-4374-90b2-fd4558e3d5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6e68-d6c9-49cf-924a-ca2e6af4e347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a456d-1e99-48be-8b3f-8615ac00df0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "377ac2df-6c6a-4665-998b-5a15520afe5f",
   "metadata": {},
   "source": [
    "### Symbolic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee654cf1-39f3-4eb4-b53a-91f34986d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_dict, target = network.get_gradients_dict(X_u_train[:, 0:1], X_u_train[:, 1:2])\n",
    "index2features = grads_dict.keys()\n",
    "print(index2features)\n",
    "\n",
    "G = torch.cat(list(grads_dict.values()), dim=1).detach().numpy()\n",
    "target = torch.squeeze(target).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7aebfb-f20f-4eb5-bc1f-5d3249475c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "equations = pysr(G, target, niterations=20, binary_operators=[\"plus\", \"sub\", \"mult\"], unary_operators=[], batching=True, procs=4, populations=10, npop=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00804df-ffa5-46a4-9080-62c65e81a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the one with best score => might be overfitting (the lowest loss)\n",
    "print(best(equations))\n",
    "# fn = best_callable(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc305283-c3d6-4f40-9385-f5075a7827af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = equations.drop(labels='lambda_format', axis=1)\n",
    "df.to_pickle('./saved_path_inverse_burger/equations_from_pysr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c51bb-f659-454d-9108-14c72ae994bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The one config that I used, and it was giving a good approx symbolic representation of the data. ###\n",
    "\n",
    "# (1)\n",
    "# est_gp = SymbolicRegressor(population_size=50000, generations=20, function_set=('add', 'sub', 'mul'),\n",
    "#                            p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "#                            p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "#                            verbose=1, low_memory=True, n_jobs=2)\n",
    "\n",
    "# (2)\n",
    "# est_gp = SymbolicRegressor(population_size=60000, generations=20, function_set=('add', 'sub', 'mul'),\n",
    "#                            p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "#                            p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "#                            verbose=1, low_memory=True, n_jobs=-1)\n",
    "\n",
    "# const_range=(-1. float(G.shape[1])) ?\n",
    "\n",
    "### Current experiment ###\n",
    "est_gp = SymbolicRegressor(population_size=60000, generations=25, function_set=('add', 'sub', 'mul'),\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                           p_point_mutation=0.1, max_samples=0.9, parsimony_coefficient=0.001,\n",
    "                           verbose=1, low_memory=True, n_jobs=-1)\n",
    "\n",
    "est_gp.fit(G, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4f40c-8d91-4595-a92e-42f47de5c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_exp\n",
    "program = est_gp._program\n",
    "print(build_exp(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dcee4-1d51-4b8f-a00a-12854420205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import pickle_save\n",
    "# pickle_save(est_gp, './data/gp_symreg_with_noisy_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d5668-7bf0-4634-9ff9-7bf8fc355b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exreacted equation (for further fine-tuning)\n",
    "# u_t + 0.6860763*uf*u_x - 0.0020577204*u_xx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
