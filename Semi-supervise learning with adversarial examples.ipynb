{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# always import gbm_algos first !\n",
    "import xgboost, lightgbm, catboost\n",
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from optimizers import Lookahead, AdamGC, SGDGC\n",
    "# Modify at /usr/local/lib/python3.9/site-packages/torch_lr_finder/lr_finder.py\n",
    "from torch_lr_finder import LRFinder\n",
    "from onecyclelr import OneCycleLR\n",
    "import pcgrad\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2000 samples\n",
      "Training with 2000 unsup samples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\"\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print(f\"Training with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# Unsup data\n",
    "N_res = 1000\n",
    "idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "idx_res = np.random.choice(idx_res.shape[0], N_res, replace=True)\n",
    "X_res = X_star[idx_res, :]\n",
    "print(f\"Training with {N} unsup samples\")\n",
    "X_u_train = np.vstack([X_u_train, X_res])\n",
    "u_train = np.vstack([u_train, torch.rand(X_res.shape[0], 1) - 1000])\n",
    "# del X_res\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)\n",
    "\n",
    "feature_names=['uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Network, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking\n",
    "        self.index2features = ('uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx')\n",
    "        self.uf = None\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        X_selector = torch.cat([uf, u_x, u_xx, u_tt, u_xt, u_tx], dim=1)\n",
    "        y_selector = u_t\n",
    "        \n",
    "        return X_selector, y_selector\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the SeclectorNetwork has to be a neural networks ???\n",
    "class SeclectorNetwork(nn.Module):\n",
    "    def __init__(self, X_train_dim, bn=None):\n",
    "        super().__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        self.nonlinear_model = TorchMLP(dimensions=[X_train_dim, 50, 50, 1], activation_function=nn.Tanh, bn=bn, dropout=nn.Dropout(p=0.1), inp_drop=False)\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        ut_approx = self.nonlinear_model(inn)\n",
    "        return ut_approx\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = F.mse_loss(ut_approx, y_input, reduction='mean')\n",
    "        return mse_loss\n",
    "\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "    def forward(self, X_u_train):\n",
    "        inn = X_u_train\n",
    "        if self.normalize_derivative_features:\n",
    "            inn = minmax_normalize(inn)\n",
    "        unsup_loss = self.selector.loss(*self.network.get_selector_data(*dimension_slicing(inn)))\n",
    "        return self.network.uf, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network(model=TorchMLP(dimensions=[6, 50, 50, 50 ,50, 50, 1], bn=nn.BatchNorm1d))\n",
    "# selector = SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm)\n",
    "semisup_model = SemiSupModel(network=Network(model=TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1], activation_function=nn.Tanh, bn=nn.LayerNorm, dropout=None)),\n",
    "                             selector=SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm),\n",
    "                             normalize_derivative_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure():\n",
    "    global N, X_u_train, u_train\n",
    "    uf, unsup_loss = semisup_model(X_u_train)\n",
    "    losses = [F.mse_loss(uf[:N, :], u_train), unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)\n",
    "\n",
    "def closure():\n",
    "    global N, X_u_train, u_train\n",
    "    optimizer2.zero_grad()\n",
    "    mse_loss = F.mse_loss(semisup_model.network(*dimension_slicing(X_u_train))[:N, :], u_train)\n",
    "    mse_loss.backward(retain_graph=True)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate finding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f82cec9dd4b828492eca7dd73e590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 5.88E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = semisup_model.parameters()\n",
    "\n",
    "### For SGD and Adam ###\n",
    "learning_rate1, learning_rate2 = 1e-7, 1e-1\n",
    "\n",
    "### For LBFGS (a good choice already!!!) ###\n",
    "# print(\"Using LBFGS's learning rate set\")\n",
    "# learning_rate1, learning_rate2 = 8e-2, 5e-2 # (1e-1, 5e-2) is also OK!\n",
    "\n",
    "choice = 'Adam'; auto_lr = True\n",
    "if choice == 'LBFGS':\n",
    "    optimizer1 = torch.optim.LBFGS(params, lr=learning_rate1, \n",
    "                                   max_iter=100, max_eval=125, \n",
    "                                  history_size=120, line_search_fn='strong_wolfe')\n",
    "if choice == 'Adam':\n",
    "    optimizer1 = AdamGC(params, lr=learning_rate1, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "if choice == 'SGD':\n",
    "    optimizer1 = SGDGC(params, lr=learning_rate1, use_gc=True, nesterov=True, momentum=0.95)\n",
    "\n",
    "if choice != 'LBFGS' and auto_lr:\n",
    "    print('Learning rate finding')\n",
    "    bs = 4000; bs = X_u_train.shape[0] if bs>X_u_train.shape[0] else bs\n",
    "    criterion = LadderLoss(return_list=True)\n",
    "    trainloader = get_dataloader(X_u_train, u_train, bs=bs)\n",
    "    \n",
    "    lr_finder = LRFinder(semisup_model, optimizer=optimizer1, \n",
    "                         closure=pcgrad_update, criterion=criterion, device=\"cpu\")\n",
    "    lr_finder.range_test(trainloader, val_loader=None, end_lr=100, num_iter=300)\n",
    "    \n",
    "    # to inspect the loss-learning rate graph\n",
    "    suggested_lr, _ = lr_finder.plot()\n",
    "    # To prevent divergence during the second stage training.\n",
    "    # suggested_lr = min(suggested_lr, 5e-3)\n",
    "    lr_finder.reset(); plt.show()\n",
    "\n",
    "else: suggested_lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learing_rate to the suggested one.\n",
    "# suggested_lr = float(input())\n",
    "\n",
    "if suggested_lr:\n",
    "    optimizer1 = lr_finder.optimizer\n",
    "    for g in optimizer1.param_groups:\n",
    "        g['lr'] = suggested_lr\n",
    "        \n",
    "epochs1 = 2000; epochs2 = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the fake labels\n",
      "Epoch 0:  37.85175323486328\n",
      "Epoch 100:  0.714329183101654\n",
      "Epoch 200:  0.4442145824432373\n",
      "Epoch 300:  0.3690534234046936\n",
      "Epoch 400:  0.33468031883239746\n",
      "Epoch 500:  0.31790053844451904\n",
      "Epoch 600:  0.2985714375972748\n",
      "Epoch 700:  0.2859709560871124\n",
      "Epoch 800:  0.2707577347755432\n",
      "Epoch 900:  0.26513704657554626\n",
      "Epoch 1000:  0.2584910988807678\n",
      "Epoch 1100:  0.2579079866409302\n",
      "Epoch 1200:  0.2378813624382019\n",
      "Epoch 1300:  0.23757082223892212\n",
      "Epoch 1400:  0.22094209492206573\n",
      "Epoch 1500:  0.2088353931903839\n",
      "Epoch 1600:  0.21056687831878662\n",
      "Epoch 1700:  0.2119634747505188\n",
      "Epoch 1800:  0.20661620795726776\n",
      "Epoch 1900:  0.19416649639606476\n"
     ]
    }
   ],
   "source": [
    "print(\"Deleting the fake labels\")\n",
    "u_train = u_train[:N, :]\n",
    "\n",
    "semisup_model.train()\n",
    "curr_loss = 1000; F_print = 10 if choice == 'LBFGS' else 100\n",
    "\n",
    "# Stage I\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(pcgrad_closure)\n",
    "    l = pcgrad_closure()\n",
    "    if (i % F_print) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Epoch {}: \".format(i), curr_loss)\n",
    "            print(\"Finishing the first stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  0.00034681669785641134\n",
      "Epoch 10:  8.608055850345409e-07\n",
      "Epoch 20:  6.999637776061718e-07\n",
      "Epoch 30:  6.642484891017375e-07\n",
      "Epoch 40:  6.62222703340376e-07\n",
      "Finishing the second stage\n",
      "Testing\n",
      "Test MSE: 2.7533938009582926e-06\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(semisup_model.network.parameters(), \n",
    "                              lr=learning_rate2, max_iter=100, max_eval=125, \n",
    "                              history_size=120, line_search_fn='strong_wolfe')\n",
    "\n",
    "curr_loss = 1000\n",
    "# Stage II\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    if (i % 10) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Finishing the second stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)\n",
    "\n",
    "print(\"Testing\")\n",
    "semisup_model.network.eval()\n",
    "\n",
    "# Compare btw the two semi-supervise learning?\n",
    "print('Test MSE:', F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST-2000: 1e-06 (LBFGS)\n",
    "# torch.save(semisup_model.state_dict(), \"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000labeledsamples_trained1000unlabeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model and testing\n",
    "# semisup_model.load_state_dict(torch.load(\"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000labeledsamples_trained1000unlabeledsamples.pth\"), strict=False)\n",
    "# semisup_model.eval()\n",
    "# F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivatives_test, dynamics_test = semisup_model.network.get_selector_data(*dimension_slicing(X_star))\n",
    "# derivatives_train, dynamics_train = semisup_model.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "\n",
    "# derivatives_test, dynamics_test = to_numpy(derivatives_test), to_numpy(dynamics_test)\n",
    "# derivatives_train, dynamics_train = to_numpy(derivatives_train), to_numpy(dynamics_train)\n",
    "\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-4000-V1-with-1000unlabledsamples.npy\", derivatives_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-4000-V1-with-1000unlabledsamples.npy\", dynamics_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-25600-V1-with-1000unlabledsamples.npy\", derivatives_test)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-25600-V1-with-1000unlabledsamples.npy\", dynamics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
