{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# always import gbm_algos first !\n",
    "import xgboost, lightgbm, catboost\n",
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from optimizers import Lookahead, AdamGC, SGDGC\n",
    "# Modify at /usr/local/lib/python3.9/site-packages/torch_lr_finder/lr_finder.py\n",
    "from torch_lr_finder import LRFinder\n",
    "from onecyclelr import OneCycleLR\n",
    "import pcgrad\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2000 samples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\"\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print(f\"Training with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)\n",
    "\n",
    "feature_names=['uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = model\n",
    "#         self.model.apply(self.xavier_init)\n",
    "        # For tracking\n",
    "        self.index2features = ('uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx')\n",
    "        self.uf = None\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        X_selector = torch.cat([uf, u_x, u_xx, u_tt, u_xt, u_tx], dim=1)\n",
    "        y_selector = u_t\n",
    "        \n",
    "        return X_selector, y_selector\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the SeclectorNetwork has to be a neural networks ???\n",
    "class SeclectorNetwork(nn.Module):\n",
    "    def __init__(self, X_train_dim, bn=None):\n",
    "        super().__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        self.nonlinear_model = TorchMLP(dimensions=[X_train_dim, 50, 50, 1], activation_function=nn.Tanh, bn=bn, dropout=nn.Dropout(p=0.1), inp_drop=False)\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        ut_approx = self.nonlinear_model(inn)\n",
    "        return ut_approx\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = F.mse_loss(ut_approx, y_input, reduction='mean')\n",
    "        return mse_loss\n",
    "\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "    def forward(self, X_u_train):\n",
    "        inn = X_u_train\n",
    "        if self.normalize_derivative_features:\n",
    "            inn = minmax_normalize(inn)\n",
    "        unsup_loss = self.selector.loss(*self.network.get_selector_data(*dimension_slicing(inn)))\n",
    "        return self.network.uf, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network(model=TorchMLP(dimensions=[6, 50, 50, 50 ,50, 50, 1], bn=nn.BatchNorm1d))\n",
    "# selector = SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm)\n",
    "semisup_model = SemiSupModel(network=Network(model=TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1], activation_function=nn.Tanh, bn=nn.LayerNorm, dropout=None)),\n",
    "                             selector=SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm),\n",
    "                             normalize_derivative_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure():\n",
    "    uf, unsup_loss = semisup_model(X_u_train)\n",
    "    losses = [F.mse_loss(uf, u_train), unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)\n",
    "\n",
    "def closure():\n",
    "    optimizer2.zero_grad()\n",
    "    mse_loss = F.mse_loss(semisup_model.network(*dimension_slicing(X_u_train)), u_train)\n",
    "    mse_loss.backward(retain_graph=True)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate finding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a4b1e20104920870ffc7ff209b27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.69E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = semisup_model.parameters()\n",
    "\n",
    "### For SGD and Adam ###\n",
    "learning_rate1, learning_rate2 = 1e-7, 1e-1\n",
    "\n",
    "### For LBFGS (a good choice already!!!) ###\n",
    "# print(\"Using LBFGS's learning rate set\")\n",
    "# learning_rate1, learning_rate2 = 8e-2, 5e-2 # (1e-1, 5e-2) is also OK!\n",
    "\n",
    "choice = 'Adam'; auto_lr = True\n",
    "if choice == 'LBFGS':\n",
    "    optimizer1 = torch.optim.LBFGS(params, lr=learning_rate1, \n",
    "                                   max_iter=100, max_eval=125, \n",
    "                                  history_size=120, line_search_fn='strong_wolfe')\n",
    "if choice == 'Adam':\n",
    "    optimizer1 = AdamGC(params, lr=learning_rate1, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "if choice == 'SGD':\n",
    "    optimizer1 = SGDGC(params, lr=learning_rate1, use_gc=True, nesterov=True, momentum=0.95)\n",
    "\n",
    "if choice != 'LBFGS' and auto_lr:\n",
    "    print('Learning rate finding')\n",
    "    bs = 4000; bs = X_u_train.shape[0] if bs>X_u_train.shape[0] else bs\n",
    "    criterion = LadderLoss(return_list=True)\n",
    "    trainloader = get_dataloader(X_u_train, u_train, bs=bs)\n",
    "    \n",
    "    lr_finder = LRFinder(semisup_model, optimizer=optimizer1, \n",
    "                         closure=pcgrad_update, criterion=criterion, device=\"cpu\")\n",
    "    lr_finder.range_test(trainloader, val_loader=None, end_lr=100, num_iter=300)\n",
    "    \n",
    "    # to inspect the loss-learning rate graph\n",
    "    suggested_lr, _ = lr_finder.plot()\n",
    "    # To prevent divergence during the second stage training.\n",
    "    # suggested_lr = min(suggested_lr, 5e-3)\n",
    "    lr_finder.reset(); plt.show()\n",
    "else:\n",
    "    suggested_lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learing_rate to the suggested one.\n",
    "# suggested_lr = float(input())\n",
    "\n",
    "if suggested_lr:\n",
    "    optimizer1 = lr_finder.optimizer\n",
    "    for g in optimizer1.param_groups:\n",
    "        g['lr'] = suggested_lr\n",
    "        \n",
    "epochs1 = 2000; epochs2 = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14.920145034790039\n",
      "Epoch 100:  2.623967409133911\n",
      "Epoch 200:  1.433295488357544\n",
      "Epoch 300:  0.9319897294044495\n",
      "Epoch 400:  0.6328073143959045\n",
      "Epoch 500:  0.4846898913383484\n",
      "Epoch 600:  0.42993128299713135\n",
      "Epoch 700:  0.3857579231262207\n",
      "Epoch 800:  0.3714942932128906\n",
      "Epoch 900:  0.3469527065753937\n",
      "Epoch 1000:  0.321806937456131\n",
      "Epoch 1100:  0.30950286984443665\n",
      "Epoch 1200:  0.294646292924881\n",
      "Epoch 1300:  0.27605581283569336\n",
      "Epoch 1400:  0.269552618265152\n",
      "Epoch 1500:  0.26018327474594116\n",
      "Epoch 1600:  0.25334906578063965\n",
      "Epoch 1700:  0.24817679822444916\n",
      "Epoch 1800:  0.24253202974796295\n",
      "Epoch 1900:  0.23060369491577148\n"
     ]
    }
   ],
   "source": [
    "semisup_model.train()\n",
    "curr_loss = 1000; F_print = 10 if choice == 'LBFGS' else 100\n",
    "\n",
    "# Stage I\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(pcgrad_closure)\n",
    "    l = pcgrad_closure()\n",
    "    if (i % F_print) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Epoch {}: \".format(i), curr_loss)\n",
    "            print(\"Finishing the first stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  0.0006348021561279893\n",
      "Epoch 10:  1.2846247727793525e-06\n",
      "Epoch 20:  9.593999266144237e-07\n",
      "Epoch 30:  8.126725674628688e-07\n",
      "Epoch 40:  7.384220452877344e-07\n",
      "Epoch 50:  5.956203494861256e-07\n",
      "Finishing the second stage\n",
      "Testing\n",
      "Test MSE: 1.8055061445920728e-06\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(semisup_model.network.parameters(), \n",
    "                              lr=learning_rate2, max_iter=100, max_eval=125, \n",
    "                              history_size=120, line_search_fn='strong_wolfe')\n",
    "\n",
    "curr_loss = 1000\n",
    "# Stage II\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    if (i % 10) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Finishing the second stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)\n",
    "\n",
    "print(\"Testing\")\n",
    "semisup_model.network.eval()\n",
    "\n",
    "# should be able to reach the order of 1e-6.\n",
    "# So that I can use this algo instead of the ladder networks\n",
    "# Compare btw the two semi-supervise learning?\n",
    "print('Test MSE:', F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST-2000: 1e-06 (LBFGS)\n",
    "# torch.save(semisup_model.state_dict(), \"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000samples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model and testing\n",
    "# semisup_model.load_state_dict(torch.load(\"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000samples.pth\"), strict=False)\n",
    "# semisup_model.eval()\n",
    "# F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivatives_test, dynamics_test = semisup_model.network.get_selector_data(*dimension_slicing(X_star))\n",
    "# derivatives_train, dynamics_train = semisup_model.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "\n",
    "# derivatives_test, dynamics_test = to_numpy(derivatives_test), to_numpy(dynamics_test)\n",
    "# derivatives_train, dynamics_train = to_numpy(derivatives_train), to_numpy(dynamics_train)\n",
    "\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-2000-V3.npy\", derivatives_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-2000-V3.npy\", dynamics_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-25600-V3.npy\", derivatives_test)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-25600-V3.npy\", dynamics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
