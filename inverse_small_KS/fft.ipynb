{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.6\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# always import gbm_algos first !\n",
    "import xgboost, lightgbm, catboost\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from preprocess import *\n",
    "from models import RobustPCANN\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from optimizers import Lookahead, AdamGC, SGDGC\n",
    "from madgrad import MADGRAD\n",
    "from lbfgsnew import LBFGSNew\n",
    "\n",
    "from pytorch_robust_pca import *\n",
    "\n",
    "# Modify at /usr/local/lib/python3.9/site-packages/torch_lr_finder/lr_finder.py\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "# Tracking\n",
    "from tqdm import trange\n",
    "\n",
    "import sympy\n",
    "import sympytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ../deephpms_data/KS_simple3.pkl\n",
      "Noisy (x, t)\n",
      "Fine-tuning with 5000 samples\n",
      "Perturbed Exact with intensity = 1.0\n",
      "Running Robust PCA on X_u_train\n",
      "Robust PCA Loss: 2.871306478090326e-32\n",
      "Running Robust PCA on X_u_train\n",
      "Robust PCA Loss: 5.934679067485165e-34\n"
     ]
    }
   ],
   "source": [
    "# Loading the KS sol\n",
    "DATA_PATH = \"../deephpms_data/KS_simple3.pkl\"\n",
    "data = pickle_load(DATA_PATH)\n",
    "t = data['t']\n",
    "x = data['x']\n",
    "X, T = np.meshgrid(x, t)\n",
    "Exact = data['u'].T\n",
    "\n",
    "# Adding noise\n",
    "noise_intensity = 1\n",
    "noisy_xt = True\n",
    "\n",
    "x_star = X.flatten()[:,None]\n",
    "t_star = T.flatten()[:,None]\n",
    "X_star = np.hstack((x_star, t_star))\n",
    "u_star = Exact.T.flatten()[:,None]\n",
    "\n",
    "if noisy_xt: \n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_star = perturb(X_star, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "N = 5000\n",
    "print(f\"Fine-tuning with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "u_train_clean = u_train\n",
    "noise = perturb(u_train, intensity=noise_intensity, noise_type=\"normal\", overwrite=False)\n",
    "u_train = u_train + noise\n",
    "print(\"Perturbed Exact with intensity =\", float(noise_intensity))\n",
    "\n",
    "# Robust PCA\n",
    "print(\"Running Robust PCA on X_u_train\")\n",
    "rpca = R_pca_numpy(X_u_train)\n",
    "X_train_L, X_train_S = rpca.fit(tol=1e-20, max_iter=25000, iter_print=100, verbose=False)\n",
    "print('Robust PCA Loss:', mean_squared_error(X_u_train, X_train_L+X_train_S))\n",
    "X_train_S = to_tensor(X_train_S, False)\n",
    "\n",
    "print(\"Running Robust PCA on X_u_train\")\n",
    "rpca = R_pca_numpy(u_train)\n",
    "u_train_L, u_train_S = rpca.fit(tol=1e-20, max_iter=25000, iter_print=100, verbose=False)\n",
    "print('Robust PCA Loss:', mean_squared_error(u_train, u_train_L+u_train_S))\n",
    "u_train_S = to_tensor(u_train_S, False)\n",
    "\n",
    "# del rpca, X_train_L, u_train_L, X_star, u_star, Exact, data\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = to_tensor(X_u_train, True)\n",
    "u_train = to_tensor(u_train, False)\n",
    "\n",
    "# lb and ub are used in adversarial training\n",
    "scaling_factor = 1.0\n",
    "lb = scaling_factor*to_tensor(lb, False)\n",
    "ub = scaling_factor*to_tensor(ub, False)\n",
    "\n",
    "# Feature names, base on the symbolic regression results\n",
    "feature_names=('uf', 'u_x', 'u_xx', 'u_xxxx'); feature2index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801254001922349"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((noise-u_train_S.numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, PSD = fft1d_denoise(u_train, thres=None, c=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7683256645290987"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((noise-(u_train-out).numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
