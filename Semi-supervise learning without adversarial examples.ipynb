{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# always import gbm_algos first !\n",
    "# import xgboost, lightgbm, catboost\n",
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from mlens.ensemble import SuperLearner\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from optimizers import Lookahead, AdamGC, SGDGC\n",
    "# Modify at /usr/local/lib/python3.9/site-packages/torch_lr_finder/lr_finder.py\n",
    "from torch_lr_finder import LRFinder\n",
    "from onecyclelr import OneCycleLR\n",
    "import pcgrad\n",
    "from pytorch_stats_loss import torch_wasserstein_loss, torch_energy_loss\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2000 samples\n",
      "Training with 2000 unsup samples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\"\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print(f\"Training with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# Unsup data\n",
    "N_res = 1000\n",
    "idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "idx_res = np.random.choice(idx_res.shape[0], N_res, replace=True)\n",
    "X_res = X_star[idx_res, :]\n",
    "print(f\"Training with {N} unsup samples\")\n",
    "X_u_train = np.vstack([X_u_train, X_res])\n",
    "u_train = np.vstack([u_train, torch.rand(X_res.shape[0], 1) - 1000])\n",
    "# del X_res\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)\n",
    "\n",
    "feature_names=['uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Network, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking\n",
    "        self.index2features = ('uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx')\n",
    "        self.uf = None\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        X_selector = torch.cat([uf, u_x, u_xx, u_tt, u_xt, u_tx], dim=1)\n",
    "        y_selector = u_t\n",
    "        \n",
    "        return X_selector, y_selector\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the SeclectorNetwork has to be a neural networks ???\n",
    "class SeclectorNetwork(nn.Module):\n",
    "    def __init__(self, X_train_dim, bn=None):\n",
    "        super().__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        self.nonlinear_model = TorchMLP(dimensions=[X_train_dim, 50, 50, 1], activation_function=nn.Tanh, bn=bn, dropout=nn.Dropout(p=0.1), inp_drop=False)\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        ut_approx = self.nonlinear_model(inn)\n",
    "        return ut_approx\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = F.mse_loss(ut_approx, y_input, reduction='mean')\n",
    "        return mse_loss\n",
    "\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "    def forward(self, X_u_train):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        return self.network.uf, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network(model=TorchMLP(dimensions=[6, 50, 50, 50 ,50, 50, 1], bn=nn.BatchNorm1d))\n",
    "# selector = SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm)\n",
    "\n",
    "### Version without normalized derivatives ###\n",
    "# semisup_model = SemiSupModel(network=Network(model=TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1], activation_function=nn.Tanh, bn=nn.LayerNorm, dropout=None)),\n",
    "#                              selector=SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm),\n",
    "#                              normalize_derivative_features=False, \n",
    "#                              mini=None, \n",
    "#                              maxi=None)\n",
    "\n",
    "### Version with normalized derivatives ###\n",
    "referenced_derivatives = np.load(\"./saved_path_inverse_burger/data/derivatives-25600-V1-with-1000unlabledsamples.npy\")\n",
    "semisup_model = SemiSupModel(network=Network(model=TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1], activation_function=nn.Tanh, bn=nn.LayerNorm, dropout=None)),\n",
    "                             selector=SeclectorNetwork(X_train_dim=6, bn=nn.LayerNorm),\n",
    "                             normalize_derivative_features=True, \n",
    "                             mini=to_tensor(np.min(referenced_derivatives, axis=0), False), \n",
    "                             maxi=to_tensor(np.max(referenced_derivatives, axis=0), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure():\n",
    "    global N, X_u_train, u_train\n",
    "    uf, unsup_loss = semisup_model(X_u_train)\n",
    "    losses = [F.mse_loss(uf[:N, :], u_train), unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)\n",
    "\n",
    "def closure():\n",
    "    global N, X_u_train, u_train\n",
    "    optimizer2.zero_grad()\n",
    "    mse_loss = F.mse_loss(semisup_model.network(*dimension_slicing(X_u_train))[:N, :], u_train)\n",
    "    mse_loss.backward(retain_graph=True)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate finding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f86b23a6845415ea13a017ee5abbe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 6.75E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = semisup_model.parameters()\n",
    "\n",
    "### For SGD and Adam ###\n",
    "learning_rate1, learning_rate2 = 1e-7, 1e-1\n",
    "\n",
    "### For LBFGS (a good choice already!!!) ###\n",
    "# print(\"Using LBFGS's learning rate set\")\n",
    "# learning_rate1, learning_rate2 = 8e-2, 5e-2 # (1e-1, 5e-2) is also OK!\n",
    "\n",
    "choice = 'Adam'; auto_lr = True\n",
    "if choice == 'LBFGS':\n",
    "    optimizer1 = torch.optim.LBFGS(params, lr=learning_rate1, \n",
    "                                   max_iter=100, max_eval=125, \n",
    "                                  history_size=120, line_search_fn='strong_wolfe')\n",
    "if choice == 'Adam':\n",
    "    optimizer1 = AdamGC(params, lr=learning_rate1, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "if choice == 'SGD':\n",
    "    optimizer1 = SGDGC(params, lr=learning_rate1, use_gc=True, nesterov=True, momentum=0.95)\n",
    "\n",
    "if choice != 'LBFGS' and auto_lr:\n",
    "    print('Learning rate finding')\n",
    "    bs = 4000; bs = X_u_train.shape[0] if bs>X_u_train.shape[0] else bs\n",
    "    criterion = LadderLoss(return_list=True)\n",
    "    trainloader = get_dataloader(X_u_train, u_train, bs=bs)\n",
    "    \n",
    "    lr_finder = LRFinder(semisup_model, optimizer=optimizer1, \n",
    "                         closure=pcgrad_update, criterion=criterion, device=\"cpu\")\n",
    "    lr_finder.range_test(trainloader, val_loader=None, end_lr=100, num_iter=300)\n",
    "    \n",
    "    # to inspect the loss-learning rate graph\n",
    "    suggested_lr, _ = lr_finder.plot()\n",
    "    # To prevent divergence during the second stage training.\n",
    "    # suggested_lr = min(suggested_lr, 5e-3)\n",
    "    lr_finder.reset(); plt.show()\n",
    "\n",
    "else: suggested_lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learing_rate to the suggested one.\n",
    "# suggested_lr = float(input())\n",
    "\n",
    "if suggested_lr:\n",
    "    optimizer1 = lr_finder.optimizer\n",
    "    for g in optimizer1.param_groups:\n",
    "        g['lr'] = suggested_lr\n",
    "        \n",
    "epochs1 = 2000; epochs2 = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the fake labels\n",
      "Epoch 0:  117.77490997314453\n",
      "Epoch 100:  1.8253216743469238\n",
      "Epoch 200:  0.8371785283088684\n",
      "Epoch 300:  0.6457735896110535\n",
      "Epoch 400:  0.5886563658714294\n",
      "Epoch 500:  1.2832204103469849\n",
      "Epoch 600:  0.731191873550415\n",
      "Epoch 700:  0.6104317307472229\n",
      "Epoch 800:  0.5092794299125671\n",
      "Epoch 900:  0.48208585381507874\n",
      "Epoch 1000:  0.4340379536151886\n",
      "Epoch 1100:  0.40349888801574707\n",
      "Epoch 1200:  0.4122401773929596\n",
      "Epoch 1300:  0.5024141073226929\n",
      "Epoch 1400:  0.5263808369636536\n",
      "Epoch 1500:  0.4792367219924927\n",
      "Epoch 1600:  0.37256038188934326\n",
      "Epoch 1700:  0.3253960609436035\n",
      "Epoch 1800:  0.296333909034729\n",
      "Epoch 1900:  0.2829264998435974\n"
     ]
    }
   ],
   "source": [
    "print(\"Deleting the fake labels\")\n",
    "u_train = u_train[:N, :]\n",
    "\n",
    "semisup_model.train()\n",
    "curr_loss = 1000; F_print = 10 if choice == 'LBFGS' else 100\n",
    "\n",
    "# Stage I\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(pcgrad_closure)\n",
    "    l = pcgrad_closure()\n",
    "    if (i % F_print) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Epoch {}: \".format(i), curr_loss)\n",
    "            print(\"Finishing the first stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  0.00046397605910897255\n",
      "Epoch 10:  1.4794342177992803e-06\n",
      "Epoch 20:  1.3681304835699848e-06\n",
      "Epoch 30:  9.740834912008722e-07\n",
      "Epoch 40:  8.7643019242023e-07\n",
      "Epoch 50:  7.735696954114246e-07\n",
      "Epoch 60:  6.589726240235905e-07\n",
      "Epoch 70:  6.371000154103967e-07\n",
      "Epoch 80:  5.954083235337748e-07\n",
      "Epoch 90:  5.491257297762786e-07\n",
      "Finishing the second stage\n",
      "Testing\n",
      "Test MSE: 3.290522499810322e-06\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(semisup_model.network.parameters(), \n",
    "                              lr=learning_rate2, max_iter=100, max_eval=125, \n",
    "                              history_size=120, line_search_fn='strong_wolfe')\n",
    "\n",
    "curr_loss = 1000\n",
    "# Stage II\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    if (i % 10) == 0:\n",
    "        if l.item() != curr_loss:\n",
    "            curr_loss = l.item()\n",
    "        else:\n",
    "            print(\"Finishing the second stage\")\n",
    "            break\n",
    "        print(\"Epoch {}: \".format(i), curr_loss)\n",
    "\n",
    "print(\"Testing\")\n",
    "semisup_model.network.eval()\n",
    "# Compare btw the two semi-supervise learning?\n",
    "print('Test MSE:', F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST-2000: 1e-06 (LBFGS)\n",
    "# torch.save(semisup_model.state_dict(), \"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000labeledsamples_trained1000unlabeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model and testing\n",
    "# semisup_model.load_state_dict(torch.load(\"./saved_path_inverse_burger/semisup_model_with_LayerNormDropout_without_physical_reg_trained2000labeledsamples_trained1000unlabeledsamples.pth\"), strict=False)\n",
    "# semisup_model.eval()\n",
    "# F.mse_loss(semisup_model.network(*dimension_slicing(X_star)).detach(), u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivatives_test, dynamics_test = semisup_model.network.get_selector_data(*dimension_slicing(X_star))\n",
    "# derivatives_train, dynamics_train = semisup_model.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "\n",
    "# derivatives_test, dynamics_test = to_numpy(derivatives_test), to_numpy(dynamics_test)\n",
    "# derivatives_train, dynamics_train = to_numpy(derivatives_train), to_numpy(dynamics_train)\n",
    "\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-3000-V1-with-1000unlabledsamples.npy\", derivatives_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-3000-V1-with-1000unlabledsamples.npy\", dynamics_train)\n",
    "# np.save(\"./saved_path_inverse_burger/data/derivatives-25600-V1-with-1000unlabledsamples.npy\", derivatives_test)\n",
    "# np.save(\"./saved_path_inverse_burger/data/dynamics-25600-V1-with-1000unlabledsamples.npy\", dynamics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
