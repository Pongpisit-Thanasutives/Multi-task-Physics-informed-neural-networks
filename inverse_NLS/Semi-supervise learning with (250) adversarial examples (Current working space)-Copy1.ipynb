{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.6\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, \n",
    "                    cplx2tensor, ComplexTorchMLP, complex_mse, TanhProb)\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Training with 500 unsup samples\n",
      "Loading pre-calculated data for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "N = 500; include_N_res = 1\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "# Unsup data\n",
    "if include_N_res>0:\n",
    "    N_res = int(N*include_N_res)\n",
    "    idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "    idx_res = idx_res[:N_res]\n",
    "    X_res = to_tensor(X_star[idx_res, :], True)\n",
    "    print(f\"Training with {N_res} unsup samples\")\n",
    "    X_train = torch.vstack([X_train, X_res])\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n",
    "\n",
    "### Loading data code here ###\n",
    "print(\"Loading pre-calculated data for reproducibility\")\n",
    "X_train = to_tensor(np.load(\"./tmp_files/X_train_500+500samples.npy\"), True)\n",
    "u_train, v_train = dimension_slicing(to_tensor(np.load(\"./tmp_files/uv_train_500samples.npy\"), False))\n",
    "### ----- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[i,:] = FiniteDiff(Exact[i,:], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[:,i] = FiniteDiff(Exact[:,i], dx, 1)\n",
    "    fd_h_xx[:,i] = FiniteDiff(Exact[:,i], dx, 2)\n",
    "    fd_h_xxx[:,i] = FiniteDiff(Exact[:,i], dx, 3)\n",
    "    \n",
    "fd_h_t = np.reshape(fd_h_t, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_x = np.reshape(fd_h_x, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xx = np.reshape(fd_h_xx, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xxx = np.reshape(fd_h_xxx, (spatial_dim*time_dim,1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "# complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn_model.pth\"))\n",
    "complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_complex_model_500labeledsamples.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train[:N, :], True))\n",
    "predictions = complex_model(cat(xx, tt))\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.00830211490392685\n",
      "MSE Loss 3.642554656835273e-05\n"
     ]
    }
   ],
   "source": [
    "# PDE Loss 1.1325556442898232e-05\n",
    "# MSE Loss 4.512887699092971e-06\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions, u_train+1j*v_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00+0.0000000e+00j,  1.8287402e-01+9.5849973e-01j,\n",
       "         9.5216465e-01+0.0000000e+00j, ...,\n",
       "         1.7851934e+01-4.6664425e+01j,  3.1865616e+01-9.3093842e+01j,\n",
       "         5.6193420e+01-1.8545619e+02j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  6.7636567e-01+1.4373595e-01j,\n",
       "         4.7813055e-01+0.0000000e+00j, ...,\n",
       "        -2.3702056e+00+5.3106542e+00j,  6.6533599e+00-1.3724621e+01j,\n",
       "        -1.8578472e+01+3.5425545e+01j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  6.0341483e-01+2.3708993e-01j,\n",
       "         4.2032108e-01+0.0000000e+00j, ...,\n",
       "        -4.2094916e-01+4.9473611e-01j, -8.7446731e-01+1.8341792e+00j,\n",
       "        -1.1678257e+00+6.2480083e+00j],\n",
       "       ...,\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  3.6971271e-02+5.2270472e-02j,\n",
       "         4.0990775e-03+0.0000000e+00j, ...,\n",
       "         3.8725277e-04+4.5041209e-03j, -4.1001476e-07+3.6970994e-03j,\n",
       "        -2.5966717e-04+3.0123498e-03j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  1.5098518e-01+1.0398209e-01j,\n",
       "         3.3608802e-02+0.0000000e+00j, ...,\n",
       "         1.6517833e-02+3.3025961e-02j, -1.2393138e-02-2.4222329e-02j,\n",
       "         9.2946738e-03+1.7763579e-02j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  5.4721653e-02+4.6720326e-02j,\n",
       "         5.1772478e-03+0.0000000e+00j, ...,\n",
       "         4.0766774e-03+6.3557024e-03j, -2.9551531e-03-5.7514533e-03j,\n",
       "         2.0485490e-03+5.1446026e-03j]], dtype=complex64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "complex_poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (-0.008224 +0.498694i)h_xx\n",
      "    + (-0.006229 +0.997566i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, d_tol=1000, maxit=1000)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic differentiation w/ and w/o Finite difference guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = []\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives.append(cplx2tensor(uf))\n",
    "                derivatives.append((uf.real**2+uf.imag**2)+0.0j)\n",
    "            elif t=='x': derivatives.append(x)\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "        \n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=torch.sigmoid, bn=None, reg_intensity=5e-2):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, activation_function=CplxToCplx[F.relu](), bn=bn, dropout_rate=0.0)\n",
    "        self.latest_weighted_features = None\n",
    "#         self.th = 0.1\n",
    "        self.th = (1/layers[0])+(1e-10)\n",
    "        self.reg_intensity = reg_intensity\n",
    "        self.w = torch.tensor([1.0, 1.0, 2.0, 2.0, 3.0])/10\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        return self.nonlinear_model(inn*F.threshold(self.weighted_features(inn), self.th, 0.0))\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "#         self.latest_weighted_features = cplx2tensor(self.linear1(inn)).abs().mean(dim=0)\n",
    "        self.latest_weighted_features = self.prob_activation(self.linear1(inn).real).mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        l1 = complex_mse(ut_approx, y_input)\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        l2 = torch.norm(reg_term, p=0)+torch.dot(self.w, reg_term)\n",
    "        return l1 + self.reg_intensity*l2\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None, uncert=False):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        self.weights = None\n",
    "        if uncert: \n",
    "            self.weights = torch.tensor([0.0, 0.0])\n",
    "        \n",
    "    def forward(self, X_h_train, h_train, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_h_train))\n",
    "        \n",
    "        h_row = h_train.shape[0]\n",
    "        fd_guidance = complex_mse(self.network.uf[:h_row, :], h_train)\n",
    "        \n",
    "        # I am not sure a good way to normalize/scale a complex tensor\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "            \n",
    "        if include_unsup and self.weights is not None:\n",
    "            return (torch.exp(-self.weights[0])*fd_guidance)+self.weights[0], (torch.exp(-self.weights[1])*unsup_loss)+self.weights[1]\n",
    "        else:\n",
    "            return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "h_star = (u_star+1j*v_star)\n",
    "\n",
    "fd_derivatives = np.hstack([h_star, h_star.real**2+h_star.imag**2, fd_h_x, fd_h_xx, fd_h_xxx])\n",
    "\n",
    "semisup_model = SemiSupModel(\n",
    "    network=ComplexNetwork(model=complex_model, index2features=feature_names, scale=False, lb=lb, ub=ub),\n",
    "    selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=TanhProb(), bn=True),\n",
    "    normalize_derivative_features=False,\n",
    "    mini=torch.tensor(np.abs(fd_derivatives).min(axis=0), dtype=torch.cfloat),\n",
    "    maxi=torch.tensor(np.abs(fd_derivatives).max(axis=0), dtype=torch.cfloat),\n",
    "    uncert=True,\n",
    ")\n",
    "\n",
    "del h_star, fd_derivatives, fd_h_x, fd_h_xx, fd_h_xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_UNCERT = True\n",
    "def pcgrad_closure(return_list=False):\n",
    "    global IS_UNCERT, N, X_train, u_train, v_train, fd_derivatives, fd_u_t\n",
    "    fd_guidance, unsup_loss = semisup_model(X_train, u_train+1j*v_train, include_unsup=True)      \n",
    "    losses = [fd_guidance, unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return sum(losses)\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(6.8763e-05, grad_fn=<AddBackward0>), tensor(11.3717, grad_fn=<AddBackward0>)]\n",
      "tensor([0.6514, 0.5760, 0.5796, 0.6622, 0.4855], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 1, 2, 0, 3])\n",
      "[tensor(0.0021, grad_fn=<AddBackward0>), tensor(2.8651, grad_fn=<AddBackward0>)]\n",
      "tensor([0.8396, 0.6801, 0.4925, 0.7325, 0.1650], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 1, 3, 0])\n",
      "[tensor(0.0040, grad_fn=<AddBackward0>), tensor(0.4965, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9288, 0.7093, 0.4192, 0.4603, 0.1058], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0038, grad_fn=<AddBackward0>), tensor(0.2964, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9545, 0.6722, 0.2770, 0.3319, 0.0938], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0037, grad_fn=<AddBackward0>), tensor(0.2382, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9513, 0.6536, 0.2128, 0.2989, 0.0889], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0033, grad_fn=<AddBackward0>), tensor(0.1735, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9494, 0.6327, 0.1785, 0.2842, 0.0860], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0027, grad_fn=<AddBackward0>), tensor(0.1644, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9487, 0.6139, 0.1669, 0.2737, 0.0848], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0023, grad_fn=<AddBackward0>), tensor(0.1610, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9480, 0.5908, 0.1634, 0.2653, 0.0844], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0020, grad_fn=<AddBackward0>), tensor(0.1596, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9465, 0.5693, 0.1627, 0.2594, 0.0846], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n",
      "[tensor(0.0018, grad_fn=<AddBackward0>), tensor(0.1586, grad_fn=<AddBackward0>)]\n",
      "tensor([0.9445, 0.5529, 0.1626, 0.2542, 0.0849], grad_fn=<MeanBackward1>)\n",
      "tensor([4, 2, 3, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Joint training\n",
    "optimizer = MADGRAD([{'params':semisup_model.network.parameters()}, {'params':semisup_model.selector.parameters()}], lr=1e-6)\n",
    "optimizer.param_groups[0]['lr'] = 1e-7\n",
    "optimizer.param_groups[1]['lr'] = 1e-1\n",
    "\n",
    "best_loss = 1000; best_state = None\n",
    "for i in range(100):\n",
    "    semisup_model.train()\n",
    "    optimizer.step(pcgrad_closure)\n",
    "    \n",
    "    if i%10==0: \n",
    "        loss = pcgrad_closure(return_list=True); print(loss)\n",
    "        fi = semisup_model.selector.latest_weighted_features\n",
    "        print(fi); print(torch.argsort(fi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train, True))\n",
    "predictions = semisup_model.network(xx, tt)\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.10301175713539124\n",
      "MSE Loss 0.001590954838320613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-f31165840332>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())\n"
     ]
    }
   ],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(semisup_model, \"tmp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Loading weights\")\n",
    "# semisup_model.load_state_dict(torch.load(\"tmp.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning both the solver and selector network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1891909252881305e-06\n",
      "1.1673479320961633e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n",
      "1.1664296835078858e-06\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning the solver network\n",
    "f_opt = torch.optim.LBFGS(semisup_model.network.parameters(), lr=1e-1, max_iter=500, history_size=500)\n",
    "\n",
    "def finetuning_closure():\n",
    "    global IS_UNCERT, N, X_train, u_train, v_train, fd_derivatives, fd_u_t\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # the solver network only consider the first N samples.\n",
    "    loss = complex_mse(semisup_model.network(*dimension_slicing(X_train[:N, :])), u_train+1j*v_train)\n",
    "    if loss.requires_grad: loss.backward(retain_graph=True)\n",
    "    return loss\n",
    "\n",
    "semisup_model.network.train()\n",
    "semisup_model.selector.eval()\n",
    "\n",
    "for i in range(200):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    \n",
    "    if i%10==0:\n",
    "        loss = finetuning_closure()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.006740993820130825\n",
      "MSE Loss 1.1664296835078858e-06\n",
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-3e99f5f7ba17>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (0.003453 +0.501241i)h_xx\n",
      "    + (0.002513 +1.003154i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train, True))\n",
    "predictions = semisup_model.network(xx, tt)\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)\n",
    "\n",
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())\n",
    "\n",
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "\n",
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, d_tol=1000, maxit=1000)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selector, y_selector = semisup_model.network.get_selector_data(*dimension_slicing(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the different loss calculaition in ComplexAttentionSelectorNetwork's forward pass\n",
    "# Reinit the selector network weights in a bad way\n",
    "# Reinit != slow convergence if the # of data samples are small\n",
    "\n",
    "# semisup_model.selector.nonlinear_model = ComplexTorchMLP(dimensions=[len(feature_names), 50, 50, 1], activation_function=CplxToCplx[F.relu](), bn=True, dropout_rate=0.0)\n",
    "# semisup_model.selector.th = 1/len(feature_names)+(1e-10)\n",
    "# semisup_model.selector.reg_intensity = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00022670772159472108\n",
      "[0.9381694  0.5617422  0.16231592 0.26615602 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "2.3624423192813993e-05\n",
      "[0.9377324  0.57839525 0.16231592 0.26090604 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6468551621073857e-05\n",
      "[0.93777186 0.57954735 0.16231592 0.25981903 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.646565942792222e-05\n",
      "[0.93777156 0.57954943 0.16231592 0.25982225 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6463865904370323e-05\n",
      "[0.9377713  0.57955086 0.16231592 0.2598246  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6461492123198695e-05\n",
      "[0.93777144 0.57954943 0.16231592 0.2598248  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6457182937301695e-05\n",
      "[0.937772   0.5795465  0.16231592 0.25982496 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6452508134534582e-05\n",
      "[0.9377725  0.5795433  0.16231592 0.2598248  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.644831536395941e-05\n",
      "[0.93777305 0.57953954 0.16231592 0.25982478 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6444602806586772e-05\n",
      "[0.9377736  0.5795362  0.16231592 0.25982493 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6441168554592878e-05\n",
      "[0.9377741  0.5795333  0.16231592 0.259825   0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.64378961926559e-05\n",
      "[0.9377745  0.5795316  0.16231592 0.2598248  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6434940334875137e-05\n",
      "[0.9377745  0.5795309  0.16231592 0.25982493 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6432077245553955e-05\n",
      "[0.9377746  0.5795305  0.16231592 0.25982466 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.642945790081285e-05\n",
      "[0.9377746  0.57953113 0.16231592 0.25982422 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.642701681703329e-05\n",
      "[0.9377747  0.57953095 0.16231592 0.25982422 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6424746718257666e-05\n",
      "[0.93777484 0.5795308  0.16231592 0.25982398 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6422422049799934e-05\n",
      "[0.937775   0.57953084 0.16231592 0.25982377 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.64203011081554e-05\n",
      "[0.9377753  0.57952964 0.16231592 0.2598234  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6418332961620763e-05\n",
      "[0.9377754  0.57952994 0.16231592 0.25982282 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6416470316471532e-05\n",
      "[0.93777543 0.57952946 0.16231592 0.25982276 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6414724086644128e-05\n",
      "[0.93777543 0.57953024 0.16231592 0.25982216 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6413097910117358e-05\n",
      "[0.9377754  0.57952994 0.16231592 0.25982246 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6411335309385322e-05\n",
      "[0.93777543 0.57952964 0.16231592 0.2598225  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.640964728721883e-05\n",
      "[0.9377756  0.57952935 0.16231592 0.25982228 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.640801565372385e-05\n",
      "[0.9377757  0.5795291  0.16231592 0.25982198 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.640649134060368e-05\n",
      "[0.93777573 0.5795288  0.16231592 0.2598221  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6405181668233126e-05\n",
      "[0.93777597 0.57952845 0.16231592 0.2598218  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6403797417297028e-05\n",
      "[0.9377761  0.57952815 0.16231592 0.25982168 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6402496839873493e-05\n",
      "[0.93777615 0.5795281  0.16231592 0.25982153 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6401208995375782e-05\n",
      "[0.9377764  0.5795274  0.16231592 0.25982144 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.639986294321716e-05\n",
      "[0.9377764  0.57952726 0.16231592 0.25982127 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6398660591221415e-05\n",
      "[0.9377764  0.57952684 0.16231592 0.25982133 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6397296349168755e-05\n",
      "[0.93777645 0.57952636 0.16231592 0.25982136 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6396073988289572e-05\n",
      "[0.9377765  0.5795262  0.16231592 0.25982118 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.639486254134681e-05\n",
      "[0.9377767  0.5795259  0.16231592 0.25982103 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6393640180467628e-05\n",
      "[0.93777686 0.57952553 0.16231592 0.259821   0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.639263064134866e-05\n",
      "[0.937777   0.5795254  0.16231592 0.25982073 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6391308236052282e-05\n",
      "[0.9377771  0.5795251  0.16231592 0.25982076 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6390098608098924e-05\n",
      "[0.9377772  0.5795248  0.16231592 0.2598206  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.638897811062634e-05\n",
      "[0.93777746 0.57952404 0.16231592 0.25982052 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6387750292778946e-05\n",
      "[0.93777746 0.579524   0.16231592 0.25982058 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.638656249269843e-05\n",
      "[0.9377777  0.5795233  0.16231592 0.2598205  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.638551475480199e-05\n",
      "[0.9377778  0.57952297 0.16231592 0.25982034 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6384323316742666e-05\n",
      "[0.9377778  0.57952255 0.16231592 0.2598202  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6383226466132328e-05\n",
      "[0.93777794 0.57952195 0.16231592 0.2598202  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.638207322685048e-05\n",
      "[0.937778   0.5795217  0.16231592 0.25982004 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6381531168008223e-05\n",
      "[0.93777806 0.5795211  0.16231592 0.25982004 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6380599845433608e-05\n",
      "[0.9377783  0.5795215  0.16231592 0.25981954 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6380163287976757e-05\n",
      "[0.93777835 0.5795215  0.16231592 0.25981963 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.637948298593983e-05\n",
      "[0.9377784  0.57952154 0.16231592 0.2598196  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6378835425712168e-05\n",
      "[0.9377784  0.5795211  0.16231592 0.25981995 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.637788773223292e-05\n",
      "[0.9377786  0.5795209  0.16231592 0.25981984 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6377052816096693e-05\n",
      "[0.9377787  0.5795203  0.16231592 0.25981978 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6376097846659832e-05\n",
      "[0.93777883 0.5795197  0.16231592 0.25981957 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6375011909985915e-05\n",
      "[0.93777895 0.5795192  0.16231592 0.2598196  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6373991456930526e-05\n",
      "[0.93777907 0.5795188  0.16231592 0.2598194  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.63730037456844e-05\n",
      "[0.9377792  0.5795183  0.16231592 0.25981936 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.637189052416943e-05\n",
      "[0.93777925 0.579518   0.16231592 0.25981906 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.637083914829418e-05\n",
      "[0.9377793  0.5795175  0.16231592 0.2598191  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6369793229387142e-05\n",
      "[0.9377794  0.5795172  0.16231592 0.25981882 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6368825527024455e-05\n",
      "[0.9377795  0.5795167  0.16231592 0.25981876 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.636766319279559e-05\n",
      "[0.9377796  0.5795166  0.16231592 0.25981852 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6366588170058094e-05\n",
      "[0.9377799  0.579516   0.16231592 0.25981838 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.636567321838811e-05\n",
      "[0.9377799  0.57951564 0.16231592 0.25981817 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.636460001464002e-05\n",
      "[0.9377799  0.5795154  0.16231592 0.2598181  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6363737813662738e-05\n",
      "[0.93778    0.57951516 0.16231592 0.25981805 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.636281012906693e-05\n",
      "[0.93778014 0.579515   0.16231592 0.259818   0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6361966117983684e-05\n",
      "[0.93778014 0.5795145  0.16231592 0.25981793 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.636100932955742e-05\n",
      "[0.93778026 0.5795144  0.16231592 0.25981772 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6360207155230455e-05\n",
      "[0.93778026 0.57951415 0.16231592 0.2598178  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.63594086188823e-05\n",
      "[0.93778026 0.57951367 0.16231592 0.25981772 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6358564607799053e-05\n",
      "[0.9377803  0.5795138  0.16231592 0.2598175  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6357873391825706e-05\n",
      "[0.9377804  0.57951355 0.16231592 0.25981763 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6357251297449693e-05\n",
      "[0.9377804  0.5795133  0.16231592 0.25981754 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6356436390196905e-05\n",
      "[0.9377805  0.5795133  0.16231592 0.25981727 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6355676052626222e-05\n",
      "[0.9377806  0.57951313 0.16231592 0.25981715 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6354846593458205e-05\n",
      "[0.9377807  0.5795126  0.16231592 0.25981706 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6354122635675594e-05\n",
      "[0.93778074 0.5795124  0.16231592 0.25981694 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.635337685002014e-05\n",
      "[0.93778074 0.5795122  0.16231592 0.259817   0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6352563761756755e-05\n",
      "[0.93778074 0.57951194 0.16231592 0.25981703 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6351783415302634e-05\n",
      "[0.9377809  0.579512   0.16231592 0.25981683 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.635105218156241e-05\n",
      "[0.9377811  0.5795115  0.16231592 0.25981677 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.635018634260632e-05\n",
      "[0.937781   0.57951134 0.16231592 0.25981706 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.634937507333234e-05\n",
      "[0.93778116 0.5795109  0.16231592 0.2598167  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.63486365636345e-05\n",
      "[0.93778116 0.57951075 0.16231592 0.25981677 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.634783075132873e-05\n",
      "[0.9377812  0.5795103  0.16231592 0.2598167  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6347144992323592e-05\n",
      "[0.93778116 0.5795106  0.16231592 0.25981668 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6346624761354178e-05\n",
      "[0.9377812  0.57951003 0.16231592 0.25981668 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6345824406016618e-05\n",
      "[0.9377814  0.5795102  0.16231592 0.25981662 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6345298718078993e-05\n",
      "[0.9377814  0.5795101  0.16231592 0.25981656 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.634472209843807e-05\n",
      "[0.9377816  0.5795098  0.16231592 0.2598165  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.634402542549651e-05\n",
      "[0.9377817  0.5795094  0.16231592 0.25981647 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6343328752554953e-05\n",
      "[0.93778175 0.5795094  0.16231592 0.2598163  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6342666640412062e-05\n",
      "[0.9377818  0.57950914 0.16231592 0.2598165  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.634186082810629e-05\n",
      "[0.937782   0.57950866 0.16231592 0.25981626 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6341087757609785e-05\n",
      "[0.9377819  0.57950866 0.16231592 0.2598164  0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.6340400179615244e-05\n",
      "[0.937782   0.5795084  0.16231592 0.25981647 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.633970532566309e-05\n",
      "[0.937782   0.57950807 0.16231592 0.25981617 0.0887525 ]\n",
      "[4 2 3 1 0]\n",
      "1.633896135899704e-05\n",
      "[0.937782   0.57950795 0.16231592 0.25981632 0.0887525 ]\n",
      "[4 2 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning the selector network\n",
    "f_opt = torch.optim.LBFGS(semisup_model.selector.parameters(), lr=1e-1, max_iter=500, history_size=500)\n",
    "\n",
    "def finetuning_closure():\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # Am I forget to normalize the derivative features?, NVM\n",
    "    # loss = semisup_model.selector.loss(X_selector, y_selector) | V2\n",
    "    loss = complex_mse(semisup_model.selector(X_selector), y_selector) # V1\n",
    "    if loss.requires_grad: loss.backward(retain_graph=True)\n",
    "    return loss\n",
    "\n",
    "semisup_model.network.eval()\n",
    "semisup_model.selector.train()\n",
    "\n",
    "for i in range(500):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    \n",
    "    if i%5==0:\n",
    "        with torch.no_grad():\n",
    "            loss = finetuning_closure()\n",
    "            print(loss.item())\n",
    "            \n",
    "            fi = semisup_model.selector.latest_weighted_features.detach().numpy()\n",
    "            print(fi)\n",
    "            print(np.argsort(fi))\n",
    "\n",
    "            # Changing the optimizer\n",
    "            if i==20: f_opt = MADGRAD(semisup_model.selector.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(semisup_model, \"semisup_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = semisup_model.selector.latest_weighted_features.detach().numpy()\n",
    "print(\"--- Feature importance ranking ---\")\n",
    "for idx in np.argsort(feature_importance)[::-1]:\n",
    "    print(feature_names[idx], feature_importance[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_neural_net(feature_importances, feature_names, threshold=0.2, save_path=None):\n",
    "    # split it up\n",
    "    above_threshold = np.maximum(feature_importance - threshold, 0)\n",
    "    below_threshold = np.minimum(feature_importance, threshold)\n",
    "\n",
    "    # and plot it\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(feature_names, below_threshold, 0.35, color=\"g\")\n",
    "    ax.bar(feature_names, above_threshold, 0.35, color=\"r\",\n",
    "            bottom=below_threshold)\n",
    "    # horizontal line indicating the threshold\n",
    "    ax.plot([0., 4.5], [threshold, threshold], \"k--\")\n",
    "    plt.xlabel(\"Partial derivative features (possible candidates)\")\n",
    "    plt.ylabel(\"Softmax layer's outputs as feature importances\")\n",
    "    \n",
    "    if save_path is not None: fig.savefig(save_path, dpi=200)\n",
    "\n",
    "plot_feature_importance_neural_net(feature_importance, feature_names,threshold=1/len(feature_names), save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
