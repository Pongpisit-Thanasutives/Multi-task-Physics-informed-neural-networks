{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, ComplexTorchMLP, complex_mse\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from complexPyTorch.complexLayers import ComplexBatchNorm1d, ComplexLinear\n",
    "# from complexPyTorch.complexFunctions import complex_relu\n",
    "# class ComplexNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ComplexNet, self).__init__()\n",
    "#         self.fc1 = ComplexLinear(5, 100)\n",
    "#         self.fc2 = ComplexLinear(100, 100)\n",
    "#         self.fc3 = ComplexLinear(100, 1)\n",
    "#     def forward(self, inp):\n",
    "#         inp = complex_relu(self.fc1(inp))\n",
    "#         inp = complex_relu(self.fc2(inp))\n",
    "#         return self.fc3(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "N = 15000\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[i,:] = FiniteDiff(Exact[i,:], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[:,i] = FiniteDiff(Exact[:,i], dx, 1)\n",
    "    fd_h_xx[:,i] = FiniteDiff(Exact[:,i], dx, 2)\n",
    "    fd_h_xxx[:,i] = FiniteDiff(Exact[:,i], dx, 3)\n",
    "    \n",
    "fd_h_t = np.reshape(fd_h_t, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_x = np.reshape(fd_h_x, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xx = np.reshape(fd_h_xx, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xxx = np.reshape(fd_h_xxx, (spatial_dim*time_dim,1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComplexPhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, model, lb, ub, scale=False):\n",
    "        super(ComplexPhysicsInformedNN, self).__init__()\n",
    "        self.model = model\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.scale = scale\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if self.scale: \n",
    "            return self.model(self.neural_net_scale(X))\n",
    "        return self.model(X)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return CplxToReal()(self.forward(self.preprocess(*dimension_slicing(X_test))))\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return (2.0*(inp-self.lb)/(self.ub-self.lb))-1.0\n",
    "\n",
    "    def preprocess(self, spatial, time):\n",
    "        return cat(spatial, time)\n",
    "    \n",
    "    def loss(self, X_f, X0, h0, X_lb, X_ub):\n",
    "        loss = self.net_f(*dimension_slicing(X_f))\n",
    "        h0_pred = self.predict(X0); u0 = h0_pred[:, 0:1]; v0 = h0_pred[:, 1:2]\n",
    "        loss += F.mse_loss(u0, h0[:, 0:1])+F.mse_loss(v0, h0[:, 1:2])\n",
    "        u_lb, v_lb, u_lb_x, v_lb_x = self.net_h(*dimension_slicing(X_lb))\n",
    "        u_ub, v_ub, u_ub_x, v_ub_x = self.net_h(*dimension_slicing(X_ub))\n",
    "        loss += F.mse_loss(u_lb, u_ub)\n",
    "        loss += F.mse_loss(v_lb, v_ub)\n",
    "        loss += F.mse_loss(u_lb_x, u_ub_x)\n",
    "        loss += F.mse_loss(v_lb_x, v_ub_x)\n",
    "        return loss\n",
    "    \n",
    "    def net_h(self, x, t):\n",
    "        X = cat(x, t)\n",
    "        h = self.forward(X)\n",
    "        u = h.real\n",
    "        v = h.imag\n",
    "        return u, v, self.diff(u, x), self.diff(v, x)\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        u, v, u_x, v_x = self.net_h(x, t)\n",
    "        u_t, v_t = self.diff(u, t), self.diff(v, t)\n",
    "        u_xx, v_xx = self.diff(u_x, x), self.diff(v_x, x)\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "        return (f_u**2).mean()+(f_v**2).mean()\n",
    "\n",
    "    def diff(self, func, inp):\n",
    "        return grad(func, inp, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape, dtype=func.dtype).to(device))[0]\n",
    "\n",
    "    def complex_mse(self, v1, v2):\n",
    "        assert v1.shape == v2.shape\n",
    "        assert v1.shape[1] == 1\n",
    "        return F.mse_loss(v1.real, v2.real)+F.mse_loss(v2.imag, v2.imag)\n",
    "\n",
    "    def add_imag_dim(self, v1):\n",
    "        z = torch.zeros(v1.shape).requires_grad_(False).to(device)\n",
    "        return torch.complex(v1, z)\n",
    "    \n",
    "cpinn = ComplexPhysicsInformedNN(model=complex_model, lb=lb, ub=ub, scale=False).to(device)\n",
    "cpinn.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "(1) Re-implement the semisup_model for a complex network.\n",
    "\n",
    "(2) Implement the self.gradients function.\n",
    "- complex_model(input) -> diff(u_pred, x) & diff(v_pred, x) -> combine 2 diff terms as 1 complex vector -> compute PDE loss / passing to the selector network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx, tt = dimension_slicing(to_tensor(X_train, True))\n",
    "# predictions = complex_model(cat(xx, tt))\n",
    "# h = cplx2tensor(predictions)\n",
    "# h_x = complex_diff(predictions, xx)\n",
    "# h_xx = complex_diff(h_x, xx)\n",
    "# h_xxx = complex_diff(h_xx, xx)\n",
    "# h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "# avg_loss = (real_loss+imag_loss)*0.5\n",
    "# print(\"PDE Loss\", avg_loss.item())\n",
    "# print(\"MSE Loss\", complex_mse(predictions, u_train+1j*v_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "# dictionary = {}\n",
    "# for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "# complex_poly_features = c_poly.fit()\n",
    "# complex_poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-6, 1000, maxit=100)\n",
    "# print(\"PDE derived using STRidge\")\n",
    "# print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic differentiation w/ and w/o Finite difference guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = []\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives.append(cplx2tensor(uf))\n",
    "                derivatives.append((uf.real**2+uf.imag**2)+0.0j)\n",
    "            elif t=='x': derivatives.append(x)\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "        \n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    }
   ],
   "source": [
    "complex_network = ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "X_selector, y_selector = complex_network.get_selector_data(*dimension_slicing(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=torch.sigmoid, bn=None, reg_intensity=0.1):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, activation_function=CplxToCplx[F.relu](), bn=bn, dropout_rate=0.0)\n",
    "        self.latest_weighted_features = None\n",
    "        self.th = 0.1\n",
    "        self.reg_intensity = reg_intensity\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        feature_importances = self.weighted_features(inn)\n",
    "        inn = inn*feature_importances\n",
    "        return self.nonlinear_model(inn)\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "        self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n",
    "        self.latest_weighted_features = self.latest_weighted_features.mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = complex_mse(ut_approx, y_input)\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        return mse_loss+self.reg_intensity*(torch.norm(reg_term, p=0)+(torch.tensor([1.0, 1.0, 2.0, 3.0, 4.0])*reg_term).sum())\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        \n",
    "    def forward(self, X_u_train, fd_derivatives=None, fd_u_t=None, fd_weight=0.0, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "        \n",
    "        print(X_selector)\n",
    "        \n",
    "        fd_guidance = 0.0\n",
    "        if fd_weight>0.0 and fd_derivatives is not None and fd_u_t is not None:\n",
    "            # Traditional MSE Loss btw uf and u_train + the fd_guidance loss\n",
    "            row, col = fd_derivatives.shape\n",
    "            fd_guidance += complex_mse(X_selector[:row, 0:1], fd_derivatives[:, 0:1])\n",
    "            fd_guidance += fd_weight*(col-1)*complex_mse(X_selector[:row, 1:], fd_derivatives[:, 1:])\n",
    "            fd_guidance += fd_weight*complex_mse(y_selector[:row, :], fd_u_t)\n",
    "            \n",
    "        else: fd_guidance = self.network.uf\n",
    "            \n",
    "        # I am not sure a good way to normalize/scale a complex tensor\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "        \n",
    "        return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n",
      "tensor([[ 1.8681e+00-0.4283j,  3.6732e+00+0.0000j,  1.0911e-01-0.0656j,\n",
      "         -6.3769e-02+0.0298j, -1.3228e-02+0.0196j],\n",
      "        [ 9.0228e-02-1.6510j,  2.7338e+00+0.0000j,  4.3882e-01+1.0984j,\n",
      "         -1.7767e-01-0.4126j, -1.0638e-01-0.2520j],\n",
      "        [ 1.0704e+00+1.0218j,  2.1899e+00+0.0000j,  1.6723e-02+0.3527j,\n",
      "         -3.8557e-02+0.0851j,  1.9367e-03-0.0274j],\n",
      "        ...,\n",
      "        [ 2.9767e-02-3.5050j,  1.2286e+01+0.0000j,  2.9730e-02+0.5513j,\n",
      "         -1.9390e-02+0.1457j, -9.5730e-03-0.1507j],\n",
      "        [ 3.9468e-01-2.5958j,  6.8939e+00+0.0000j,  4.8346e-02+0.5776j,\n",
      "         -4.1190e-02+0.0498j, -1.3955e-02-0.1486j],\n",
      "        [ 9.0984e-01+1.5876j,  3.3483e+00+0.0000j, -7.0029e-02+0.4571j,\n",
      "         -2.3335e-02+0.0048j,  4.1886e-02-0.1531j]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-b055b5ac80e9>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Cplx(\n",
       "   real=tensor([[1.8681],\n",
       "         [0.0902],\n",
       "         [1.0704],\n",
       "         ...,\n",
       "         [0.0298],\n",
       "         [0.3947],\n",
       "         [0.9098]], grad_fn=<AddBackward0>),\n",
       "   imag=tensor([[-0.4283],\n",
       "         [-1.6510],\n",
       "         [ 1.0218],\n",
       "         ...,\n",
       "         [-3.5050],\n",
       "         [-2.5958],\n",
       "         [ 1.5876]], grad_fn=<AddBackward0>)\n",
       " ),\n",
       " tensor(87.6773, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_star = (u_star+1j*v_star)\n",
    "\n",
    "fd_derivatives = np.hstack([h_star, h_star.real**2+h_star.imag**2, fd_h_x, fd_h_xx, fd_h_xxx])\n",
    "\n",
    "semisup_model = SemiSupModel(\n",
    "    network=ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub),\n",
    "    selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True),\n",
    "    normalize_derivative_features=False,\n",
    "    mini=torch.tensor(np.abs(fd_derivatives).min(axis=0), dtype=torch.cfloat),\n",
    "    maxi=torch.tensor(np.abs(fd_derivatives).max(axis=0), dtype=torch.cfloat)\n",
    ")\n",
    "\n",
    "del h_star, fd_derivatives, fd_h_x, fd_h_xx, fd_h_xxx\n",
    "\n",
    "semisup_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-b055b5ac80e9>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.44834899902344\n",
      "66.04901123046875\n",
      "50.43925857543945\n",
      "36.649662017822266\n",
      "22.741655349731445\n",
      "11.524919509887695\n",
      "6.80875301361084\n",
      "7.250322341918945\n",
      "6.639248371124268\n",
      "4.758763790130615\n",
      "3.149500608444214\n",
      "2.7190613746643066\n",
      "2.7672371864318848\n",
      "2.3246827125549316\n",
      "1.572084903717041\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0f86bdca7c1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mselector_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mselector_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_selector = (X_selector - semisup_model.mini) / (semisup_model.maxi-semisup_model.mini)\n",
    "selector_optimizer = MADGRAD(selector.parameters(), lr=5e-2)\n",
    "for i in range(50000):\n",
    "    selector_optimizer.zero_grad()\n",
    "    l = complex_mse(selector(X_selector), y_selector)\n",
    "    l.backward(retain_graph=True)\n",
    "    selector_optimizer.step()\n",
    "    print(l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(selector.state_dict(), './saved_path_inverse_nls/selector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
