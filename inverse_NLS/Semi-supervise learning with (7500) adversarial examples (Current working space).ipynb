{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "# complex valued tensor class\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, ComplexTorchMLP\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "N = 15000\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u)\n",
    "v_star = to_column_vector(Exact_v)\n",
    "\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[i,:] = FiniteDiff(Exact[i,:], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[:,i] = FiniteDiff(Exact[:,i], dx, 1)\n",
    "    fd_h_xx[:,i] = FiniteDiff(Exact[:,i], dx, 2)\n",
    "    fd_h_xxx[:,i] = FiniteDiff(Exact[:,i], dx, 3)\n",
    "    \n",
    "fd_h_t = np.reshape(fd_h_t, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_x = np.reshape(fd_h_x, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xx = np.reshape(fd_h_xx, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xxx = np.reshape(fd_h_xxx, (spatial_dim*time_dim,1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComplexPhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, model, lb, ub, scale=False):\n",
    "        super(ComplexPhysicsInformedNN, self).__init__()\n",
    "        self.model = model\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.scale = scale\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if self.scale: \n",
    "            return self.model(self.neural_net_scale(X))\n",
    "        return self.model(X)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return CplxToReal()(self.forward(self.preprocess(*dimension_slicing(X_test))))\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return (2.0*(inp-self.lb)/(self.ub-self.lb))-1.0\n",
    "\n",
    "    def preprocess(self, spatial, time):\n",
    "        return cat(spatial, time)\n",
    "    \n",
    "    def loss(self, X_f, X0, h0, X_lb, X_ub):\n",
    "        loss = self.net_f(*dimension_slicing(X_f))\n",
    "        h0_pred = self.predict(X0); u0 = h0_pred[:, 0:1]; v0 = h0_pred[:, 1:2]\n",
    "        loss += F.mse_loss(u0, h0[:, 0:1])+F.mse_loss(v0, h0[:, 1:2])\n",
    "        u_lb, v_lb, u_lb_x, v_lb_x = self.net_h(*dimension_slicing(X_lb))\n",
    "        u_ub, v_ub, u_ub_x, v_ub_x = self.net_h(*dimension_slicing(X_ub))\n",
    "        loss += F.mse_loss(u_lb, u_ub)\n",
    "        loss += F.mse_loss(v_lb, v_ub)\n",
    "        loss += F.mse_loss(u_lb_x, u_ub_x)\n",
    "        loss += F.mse_loss(v_lb_x, v_ub_x)\n",
    "        return loss\n",
    "    \n",
    "    def net_h(self, x, t):\n",
    "        X = cat(x, t)\n",
    "        h = self.forward(X)\n",
    "        u = h.real\n",
    "        v = h.imag\n",
    "        return u, v, self.diff(u, x), self.diff(v, x)\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        u, v, u_x, v_x = self.net_h(x, t)\n",
    "        u_t, v_t = self.diff(u, t), self.diff(v, t)\n",
    "        u_xx, v_xx = self.diff(u_x, x), self.diff(v_x, x)\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "        return (f_u**2).mean()+(f_v**2).mean()\n",
    "\n",
    "    def diff(self, func, inp):\n",
    "        return grad(func, inp, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape, dtype=func.dtype).to(device))[0]\n",
    "\n",
    "    def complex_mse(self, v1, v2):\n",
    "        assert v1.shape == v2.shape\n",
    "        assert v1.shape[1] == 1\n",
    "        return F.mse_loss(v1.real, v2.real)+F.mse_loss(v2.imag, v2.imag)\n",
    "\n",
    "    def add_imag_dim(self, v1):\n",
    "        z = torch.zeros(v1.shape).requires_grad_(False).to(device)\n",
    "        return torch.complex(v1, z)\n",
    "    \n",
    "cpinn = ComplexPhysicsInformedNN(model=complex_model, lb=lb, ub=ub, scale=False).to(device)\n",
    "cpinn.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "(1) Re-implement the semisup_model for a complex network.\n",
    "\n",
    "(2) Implement the self.gradients function.\n",
    "- complex_model(input) -> diff(u_pred, x) & diff(v_pred, x) -> combine 2 diff terms as 1 complex vector -> compute PDE loss / passing to the selector network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../utils.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train, True))\n",
    "predictions = complex_model(cat(xx, tt))\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.278501238441095e-06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "avg_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hf': array([[ 0.59681845+0.23667818j],\n",
       "        [-0.44909674+0.17685312j],\n",
       "        [ 0.879527  +0.68292147j],\n",
       "        ...,\n",
       "        [ 0.05834496+0.00590008j],\n",
       "        [ 0.76030886+0.3223831j ],\n",
       "        [ 0.29872465+2.2492747j ]], dtype=complex64),\n",
       " '|hf|': array([[4.1220880e-01+0.j],\n",
       "        [2.3296493e-01+0.j],\n",
       "        [1.2399495e+00+0.j],\n",
       "        ...,\n",
       "        [3.4389454e-03+0.j],\n",
       "        [6.8200046e-01+0.j],\n",
       "        [5.1484737e+00+0.j]], dtype=complex64),\n",
       " 'h_x': array([[ 0.27015495-0.00621095j],\n",
       "        [ 4.0820913 +0.5407842j ],\n",
       "        [ 0.03203336+1.2565445j ],\n",
       "        ...,\n",
       "        [ 0.06036643+0.00272644j],\n",
       "        [-0.3735373 -0.53195214j],\n",
       "        [-1.0037583 +2.4175246j ]], dtype=complex64),\n",
       " 'h_xx': array([[ -0.49388748-0.6165564j ],\n",
       "        [-13.366825  -1.9379109j ],\n",
       "        [ -1.3241913 +2.4222994j ],\n",
       "        ...,\n",
       "        [  0.08268727+0.00619484j],\n",
       "        [ -0.47708657+1.0874285j ],\n",
       "        [  2.104299  -5.629319j  ]], dtype=complex64),\n",
       " 'h_xxx': array([[-2.0106227e+00-1.9418793e+00j],\n",
       "        [ 3.7891842e+01+5.1843562e+00j],\n",
       "        [-2.0652862e+00+3.7043414e+00j],\n",
       "        ...,\n",
       "        [ 2.9463485e-02+1.3792347e-03j],\n",
       "        [ 1.9243127e+00-2.3267562e+00j],\n",
       "        [ 2.1152889e+01-4.6445541e+01j]], dtype=complex64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00+0.0000000e+00j,  5.9681845e-01+2.3667818e-01j,\n",
       "         4.1220880e-01+0.0000000e+00j, ...,\n",
       "        -1.3621695e-01+6.0901898e-01j, -2.0425671e-01+2.1987321e+00j,\n",
       "         2.7170897e-01+7.8087730e+00j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j, -4.4909674e-01+1.7685312e-01j,\n",
       "         2.3296493e-01+0.0000000e+00j, ...,\n",
       "         1.7491652e+02+5.1807434e+01j, -4.9644681e+02-1.4272940e+02j,\n",
       "         1.4089141e+03+3.9288962e+02j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  8.7952697e-01+6.8292147e-01j,\n",
       "         1.2399495e+00+0.0000000e+00j, ...,\n",
       "        -4.1140513e+00-6.4151759e+00j, -6.2381907e+00-9.9079981e+00j,\n",
       "        -9.4567375e+00-1.5301050e+01j],\n",
       "       ...,\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  5.8344960e-02+5.9000850e-03j,\n",
       "         3.4389454e-03+0.0000000e+00j, ...,\n",
       "         6.7988089e-03+1.0244690e-03j,  2.4277112e-03+2.9656675e-04j,\n",
       "         8.6619466e-04+8.1274120e-05j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  7.6030886e-01+3.2238311e-01j,\n",
       "         6.8200046e-01+0.0000000e+00j, ...,\n",
       "        -9.5488900e-01-1.0375950e+00j,  1.6121172e+00+3.2026167e+00j,\n",
       "        -1.7108152e+00-8.9548130e+00j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  2.9872465e-01+2.2492747e+00j,\n",
       "         5.1484737e+00+0.0000000e+00j, ...,\n",
       "        -2.7261160e+01-2.3691542e+01j, -2.1694478e+02-2.1681168e+02j,\n",
       "        -1.7097435e+03-1.9649148e+03j]], dtype=complex64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "complex_poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_poly_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (-0.000069 +0.499961i)h_xx\n",
      "    + (-0.000127 +0.999955i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-6, 1000, maxit=100)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic differentiation w/ and w/o Finite difference guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = []\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives.append(cplx2tensor(uf))\n",
    "                derivatives.append((uf.real**2+uf.imag**2)+0.0j)\n",
    "            elif t=='x': derivatives.append(x)\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "        \n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    }
   ],
   "source": [
    "complex_network = ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "X_selector, y_selector = complex_network.get_selector_data(xx, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=CplxToCplx[torch.sigmoid], bn=None, reg_intensity=0.1):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, bn=bn, dropout_rate=0.1)\n",
    "        self.latest_weighted_features = None\n",
    "        self.th = 0.1\n",
    "        self.reg_intensity = reg_intensity\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        feature_importances = self.weighted_features(inn)\n",
    "        inn.real = inn.real*feature_importances.real\n",
    "        inn.imag = inn.imag*feature_importances.imag\n",
    "        return self.nonlinear_model(inn)\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "        self.latest_weighted_features = self.prob_activation(self.linear1(inn))\n",
    "        self.latest_weighted_features = self.latest_weighted_features.real.mean(dim=0)+1j*self.latest_weighted_features.imag.mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = F.mse_loss(ut_approx, y_input, reduction='mean')\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        return mse_loss+self.reg_intensity*(torch.norm(reg_term, p=0)+(torch.tensor([1.0, 1.0, 2.0, 3.0, 4.0])*reg_term).sum())\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        \n",
    "    def forward(self, X_u_train, fd_derivatives=None, fd_u_t=None, fd_weight=0.0, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "        \n",
    "        fd_guidance = 0.0\n",
    "        if fd_weight>0.0 and fd_derivatives is not None and fd_u_t is not None:\n",
    "            # Traditional MSE Loss btw uf and u_train + the fd_guidance loss\n",
    "            row, col = fd_derivatives.shape\n",
    "            fd_guidance += F.mse_loss(X_selector[:row, 0:1], fd_derivatives[:, 0:1])\n",
    "            fd_guidance += fd_weight*(col-1)*F.mse_loss(X_selector[:row, 1:], fd_derivatives[:, 1:])\n",
    "            fd_guidance += fd_weight*F.mse_loss(y_selector[:row, :], fd_u_t)\n",
    "            \n",
    "        else: fd_guidance = self.network.uf\n",
    "            \n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "        \n",
    "        return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n",
      "/usr/local/lib/python3.9/site-packages/cplxmodule/cplx.py:197: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return type(self)(f(self.__real, *a, **k), f(self.__imag, *a, **k))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cplx(\n",
       "  real=tensor([[0.1009],\n",
       "        [0.0776],\n",
       "        [0.0835],\n",
       "        ...,\n",
       "        [0.0387],\n",
       "        [0.0910],\n",
       "        [0.0864]], grad_fn=<AddBackward0>),\n",
       "  imag=tensor([[-0.1251],\n",
       "        [-0.1170],\n",
       "        [-0.1380],\n",
       "        ...,\n",
       "        [-0.0967],\n",
       "        [-0.1335],\n",
       "        [-0.1413]], grad_fn=<AddBackward0>)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=CplxToCplx[F.softmax](), bn=None)\n",
    "selector(X_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semisup_model = SemiSupModel(network=Network(\n",
    "#                                     model=TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1],\n",
    "#                                                    activation_function=nn.Tanh,\n",
    "#                                                    bn=nn.LayerNorm, dropout=None),\n",
    "#                                     index2features=feature_names, scale=True, lb=lb, ub=ub),\n",
    "#                             selector=AttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=nn.Softmax(dim=1), bn=nn.LayerNorm),\n",
    "#                             normalize_derivative_features=True,\n",
    "#                             mini=None,\n",
    "#                             maxi=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
