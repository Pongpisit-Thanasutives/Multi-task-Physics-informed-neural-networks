{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.7.10\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from lightning_utils import *\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, \n",
    "                    ComplexTorchMLP, ComplexSymPyModule, complex_mse)\n",
    "from pytorch_robust_pca import *\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Loading pre-calculated (clean) data for reproducibility\n",
      "Noisy (x, t)\n",
      "Running Robust PCA...\n",
      "iteration: 1, error: 5.214361366905212\n",
      "iteration: 1000, error: 9.776343901985502e-05\n",
      "iteration: 2000, error: 1.4370710661712087e-11\n",
      "iteration: 3000, error: 2.262270387157573e-15\n",
      "iteration: 4000, error: 2.262270387157573e-15\n",
      "iteration: 5000, error: 2.262270387157573e-15\n",
      "iteration: 6000, error: 2.262270387157573e-15\n",
      "iteration: 7000, error: 2.262270387157573e-15\n",
      "iteration: 8000, error: 2.262270387157573e-15\n",
      "iteration: 9000, error: 2.262270387157573e-15\n",
      "iteration: 10000, error: 2.262270387157573e-15\n",
      "iteration: 11000, error: 2.262270387157573e-15\n",
      "iteration: 12000, error: 2.262270387157573e-15\n",
      "iteration: 13000, error: 2.262270387157573e-15\n",
      "iteration: 14000, error: 2.262270387157573e-15\n",
      "iteration: 15000, error: 2.262270387157573e-15\n",
      "iteration: 16000, error: 2.262270387157573e-15\n",
      "iteration: 17000, error: 2.262270387157573e-15\n",
      "iteration: 18000, error: 2.262270387157573e-15\n",
      "iteration: 19000, error: 2.262270387157573e-15\n",
      "iteration: 20000, error: 2.262270387157573e-15\n",
      "iteration: 21000, error: 2.262270387157573e-15\n",
      "iteration: 22000, error: 2.262270387157573e-15\n",
      "iteration: 23000, error: 2.262270387157573e-15\n",
      "iteration: 24000, error: 2.262270387157573e-15\n",
      "iteration: 25000, error: 2.262270387157573e-15\n",
      "iteration: 26000, error: 2.262270387157573e-15\n",
      "iteration: 27000, error: 2.262270387157573e-15\n",
      "iteration: 28000, error: 2.262270387157573e-15\n",
      "iteration: 29000, error: 2.262270387157573e-15\n",
      "iteration: 30000, error: 2.262270387157573e-15\n",
      "Robust PCA Loss: 2.5600115923796852e-33\n",
      "Perturbed u_train and v_train with intensity = 0.0070710678118654745\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Adding noise\n",
    "noise_intensity = 0.01/np.sqrt(2)\n",
    "noisy_xt = True\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "N = 500\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "# if noisy_xt:\n",
    "#     print(\"Noisy (x, t)\")\n",
    "#     X_star = perturb(X_star, intensity=noise_intensity, noise_type=\"normal\")\n",
    "# else: print(\"Clean (x, t)\")\n",
    "\n",
    "# X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "# u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "# v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_xx']\n",
    "\n",
    "### Loading (clean) data code here ###\n",
    "print(\"Loading pre-calculated (clean) data for reproducibility\")\n",
    "X_train = np.load(\"./tmp_files/X_train_500+500samples.npy\")\n",
    "\n",
    "if noisy_xt:\n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_train = perturb(X_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "\n",
    "rpca_option = 3\n",
    "print(\"Running Robust PCA...\")\n",
    "rpca = R_pca_numpy(X_train)\n",
    "X_train_L, X_train_S = rpca.fit(tol=1e-20, max_iter=30000, iter_print=1000)\n",
    "print('Robust PCA Loss:', mean_squared_error(X_train, X_train_L+X_train_S))\n",
    "\n",
    "X_train = to_tensor(X_train, True)[:N, :]\n",
    "X_train_L = to_tensor(X_train_L, True)[:N, :]\n",
    "X_train_S = to_tensor(X_train_S, True)[:N, :]\n",
    "uv_train = np.load(\"./tmp_files/uv_train_500samples.npy\")\n",
    "u_train = uv_train[:, 0:1]; v_train = uv_train[:, 1:2]\n",
    "if noise_intensity > 0.0:\n",
    "    u_train = perturb(u_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "    v_train = perturb(v_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "    print(\"Perturbed u_train and v_train with intensity =\", float(noise_intensity))\n",
    "u_train, v_train = to_tensor(u_train, False), to_tensor(v_train, False)\n",
    "u_train = u_train[:N, :]; v_train = v_train[:N, :]\n",
    "h_train = torch.complex(u_train, v_train)\n",
    "\n",
    "del X_train\n",
    "### ----- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sumsquare_error</th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "      <th>kl_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>norm</th>\n",
       "      <td>0.892037</td>\n",
       "      <td>535.331981</td>\n",
       "      <td>-7008.187711</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>1.433631</td>\n",
       "      <td>463.124087</td>\n",
       "      <td>-6533.729353</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sumsquare_error         aic          bic  kl_div\n",
       "norm            0.892037  535.331981 -7008.187711     inf\n",
       "uniform         1.433631  463.124087 -6533.729353     inf"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fitter import Fitter\n",
    "data = to_numpy(X_train_S).flatten()\n",
    "d_finder = Fitter(data, distributions=[\"norm\", \"uniform\"]); d_finder.fit()\n",
    "d_finder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1 = 0.002494+1.002397*1j\n",
    "cn2 = 0.003655+0.500415*1j\n",
    "cns = [cn1, cn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X1 {X0, X1}\n",
      "X2 {X2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ComplexSymPyModule(\n",
       "  (sympymodule): SymPyModule(expressions=(X0*X1, X2))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X1\"\n",
    "pde_expr1, variables1,  = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X2\"\n",
    "pde_expr2, variables2,  = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, beta=False):\n",
    "        super(ComplexPINN, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        # Beta-Robust PCA\n",
    "        self.beta = None\n",
    "        if beta: \n",
    "            self.beta = nn.Parameter(data=torch.FloatTensor([0.0]), requires_grad=True)\n",
    "            self.mean = nn.Parameter(data=torch.zeros((500, 1)), requires_grad=True)\n",
    "            self.std = nn.Parameter(data=torch.ones((500, 1)), requires_grad=True)\n",
    "\n",
    "        self.callable_loss_fn = loss_fn\n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None):\n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def forward(self, H):\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, HL, HS, y_input, update_network_params=True, update_pde_params=True):\n",
    "        total_loss = []\n",
    "#         H = HL + HS - self.beta*(torch.randn_like(self.std).mul(self.std).add_(self.mean))\n",
    "        H = HL + HS - self.beta*(torch.normal(self.mean, torch.clamp(self.std, min=0.0)))\n",
    "        \n",
    "        grads_dict, u_t = self.grads_dict(H[:, 0:1], H[:, 1:2])\n",
    "        # MSE Loss\n",
    "        if update_network_params:\n",
    "            mse_loss = complex_mse(grads_dict['X'+self.feature2index['hf']], y_input)\n",
    "            total_loss.append(mse_loss)\n",
    "        # PDE Loss\n",
    "        if update_pde_params:\n",
    "            l_eq = complex_mse(self.callable_loss_fn(grads_dict), u_t)\n",
    "            total_loss.append(l_eq)\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(cat(x, t))\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = {}\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives['X'+self.feature2index[t]] = cplx2tensor(uf)\n",
    "                derivatives['X1'] = (uf.real**2+uf.imag**2)+0.0j\n",
    "            elif t=='x': derivatives['X'+self.feature2index[t]] = x\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives['X'+self.feature2index['h_'+t[::-1]]] = out\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "    \n",
    "    # Must ensure that the implementation of neural_net_scale is consistent\n",
    "    # and hopefully correct\n",
    "    # also, you might not need this function in some datasets\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/envs/py3.7/lib/python3.7/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model\n",
    "semisup_model_state_dict = cpu_load(\"./saved_path_inverse_nls/NLS_complex_model_500labeledsamples_jointtrainwith500unlabeledsamples.pth\")\n",
    "parameters = OrderedDict()\n",
    "\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = ComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, scale=False, lb=lb, ub=ub, beta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global X_train, h_train\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train_L, X_train_S, h_train, update_network_params=True, update_pde_params=True)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad:\n",
    "        l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def mtl_closure():\n",
    "    global X_train, h_train\n",
    "    n_obj = 2 # There are two tasks\n",
    "    losses = pinn.loss(X_train_L, X_train_S, h_train, update_network_params=True, update_pde_params=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(n_obj):\n",
    "        optimizer1.zero_grad(set_to_none=True)\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(pinn.parameters()): \n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Phase optimization using Adam with PCGrad gradient modification\n",
      "Epoch 0:  0.013192374259233475\n",
      "Epoch 10:  0.009974602609872818\n",
      "Epoch 20:  0.008491888642311096\n",
      "Epoch 30:  0.007762376684695482\n",
      "Epoch 40:  0.007710049394518137\n",
      "Epoch 50:  0.008349229581654072\n",
      "Epoch 60:  0.0070140426978468895\n",
      "Epoch 70:  0.006757463328540325\n",
      "Epoch 80:  0.006492312066257\n",
      "Epoch 90:  0.006286589428782463\n",
      "Epoch 100:  0.0062048062682151794\n",
      "Epoch 110:  0.006059261970221996\n",
      "Epoch 120:  0.00590141024440527\n",
      "Epoch 130:  0.019837988540530205\n",
      "Epoch 140:  0.0072663817554712296\n",
      "Epoch 150:  0.008053798228502274\n",
      "Epoch 160:  0.007072280626744032\n",
      "Epoch 170:  0.006345926318317652\n",
      "Epoch 180:  0.006083035841584206\n",
      "Epoch 190:  0.0059686265885829926\n",
      "Epoch 200:  0.005840723402798176\n",
      "Epoch 210:  0.005745231173932552\n",
      "Epoch 220:  0.005649639293551445\n",
      "Epoch 230:  0.005566319450736046\n",
      "Epoch 240:  0.0054940576665103436\n",
      "Epoch 250:  0.0054267393425107\n",
      "Epoch 260:  0.005375410430133343\n",
      "Epoch 270:  0.005325807258486748\n",
      "Epoch 280:  0.005277346819639206\n",
      "Epoch 290:  0.00523202121257782\n",
      "Epoch 299:  0.005193421617150307\n"
     ]
    }
   ],
   "source": [
    "epochs1, epochs2 = 300, 30\n",
    "# TODO: Save best state dict and training for more epochs.\n",
    "optimizer1 = MADGRAD(pinn.parameters(), lr=1e-7, momentum=0.9)\n",
    "pinn.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        l = mtl_closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Phase optimization using LBFGS\n",
      "Epoch 0:  0.005190030671656132\n",
      "Epoch 5:  0.005198806989938021\n",
      "Epoch 10:  0.0051930490881204605\n",
      "Epoch 15:  0.005182681139558554\n",
      "Epoch 20:  0.005170617252588272\n",
      "Epoch 25:  0.005182419903576374\n",
      "Epoch 29:  0.005178993567824364\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=500, max_eval=int(500*1.25), history_size=150, line_search_fn='strong_wolfe')\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    if (i % 5) == 0 or i == epochs2-1:\n",
    "        l = closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights for testing\n",
    "# pinn = load_weights(pinn, \"./saved_path_inverse_nls/final_finetuned_uncert_cpinn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00080113+1.0039288j , 0.00082442+0.49846026j], dtype=complex64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_coeffs = pinn.callable_loss_fn.complex_coeffs().detach().numpy().ravel()\n",
    "est_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3504127264022827, 0.04246532917022705)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_coeffs = pinn.callable_loss_fn.complex_coeffs().detach().numpy().ravel()\n",
    "grounds = np.array([1j, 0+0.5j])\n",
    "\n",
    "errs = []\n",
    "for i in range(len(grounds)):\n",
    "    err = est_coeffs[i]-grounds[i]\n",
    "    errs.append(100*abs(err.imag)/abs(grounds[i].imag))\n",
    "errs = np.array(errs)\n",
    "errs.mean(), errs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00010761896555777639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the coeff should be 1.0 (ทำการทดลองไปแล้ว)\n",
    "pinn.beta.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(pinn, \"./saved_path_inverse_nls/noisy2_final_finetuned_betarpca2_cpinn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Exact & Clean (x, t)\n",
    "# (0.05885958671569824, 0.021964311599731445)\n",
    "# array([-0.00046226+0.99919176j, -0.00056662+0.49981552j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t)\n",
    "# (0.6996273994445801, 0.01595020294189453)\n",
    "# array([0.00149273+0.9928442j, 0.00079829+0.5034184j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Clean (x, t) & X_star = X_star-X_star_S\n",
    "# (0.7112264633178711, 0.00553131103515625)\n",
    "# array([ 3.449592e-03+1.007057j , -7.125967e-05+0.5035838j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t) & X_star = X_star-X_star_S\n",
    "# (0.7093071937561035, 0.0036716461181640625)\n",
    "# array([ 3.4442921e-03+1.0070564j, -5.4004795e-05+0.5035649j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Clean (x, t) & X_star = X_star_L+1*X_star_S\n",
    "# (0.1215517520904541, 0.08192658424377441)\n",
    "# array([-8.2360100e-05+0.99960375j, -6.1671366e-05+0.5010174j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t) & X_star = X_star_L+1*X_star_S\n",
    "# (0.511014461517334, 0.25589466094970703)\n",
    "# array([-0.01472272+1.0076691j, -0.02164156+0.5012756j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Noisy (x, t) & X_train = X_train_L+1*1*X_train_S+beta*NN(X_train_S)\n",
    "# (0.5050361156463623, 0.1848280429840088)\n",
    "# array([ 0.00107117+1.0032021j, -0.01103256+0.5034493j], dtype=complex64)\n",
    "# beta = 0.005178438033908606\n",
    "# \n",
    "# betarpca2\n",
    "# reparameterization\n",
    "# (0.27244389057159424, 0.20924508571624756)\n",
    "# array([-0.00100172+1.0048169j, -0.00026962+0.499684j ], dtype=complex64)\n",
    "# beta = -0.0003170908021274954\n",
    "# torch.normal\n",
    "# (0.3504127264022827, 0.04246532917022705)\n",
    "# array([0.00080113+1.0039288j , 0.00082442+0.49846026j], dtype=complex64)\n",
    "# beta = -0.00010761896555777639\n",
    "\n",
    "# Notes\n",
    "# X_star = X_star-X_star_S -> Seems robust but not stable\n",
    "# X_star = X_star_L+X_star_S -> The best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
