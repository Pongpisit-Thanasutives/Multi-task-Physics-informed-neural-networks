{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.6\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from lightning_utils import *\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, \n",
    "                    ComplexTorchMLP, ComplexSymPyModule, complex_mse)\n",
    "from models import RobustPCANN\n",
    "from pytorch_robust_pca import *\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD\n",
    "import lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Loading pre-calculated (clean) data for reproducibility\n",
      "Noisy (x, t)\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Adding noise\n",
    "noise_intensity = 0.01/np.sqrt(2)\n",
    "noisy_xt = True\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "N = 500\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "# if noisy_xt:\n",
    "#     print(\"Noisy (x, t)\")\n",
    "#     X_star = perturb(X_star, intensity=noise_intensity, noise_type=\"normal\")\n",
    "# else: print(\"Clean (x, t)\")\n",
    "\n",
    "# X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "# u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "# v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_xx']\n",
    "\n",
    "### Loading (clean) data code here ###\n",
    "print(\"Loading pre-calculated (clean) data for reproducibility\")\n",
    "X_train = np.load(\"./tmp_files/X_train_500+500samples.npy\")\n",
    "\n",
    "if noise_intensity > 0.0 and noisy_xt:\n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_train = perturb(X_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "\n",
    "X_train = to_tensor(X_train, True)[:N, :]\n",
    "\n",
    "uv_train = np.load(\"./tmp_files/uv_train_500samples.npy\")\n",
    "u_train = uv_train[:, 0:1]; v_train = uv_train[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbed u_train and v_train with intensity = 0.0070710678118654745\n"
     ]
    }
   ],
   "source": [
    "if noise_intensity > 0.0:\n",
    "    noise_u = perturb(u_train, intensity=noise_intensity, noise_type=\"normal\", overwrite=False)\n",
    "    u_train = u_train + noise_u\n",
    "    noise_v = perturb(v_train, intensity=noise_intensity, noise_type=\"normal\", overwrite=False)\n",
    "    v_train = v_train + noise_v\n",
    "    print(\"Perturbed u_train and v_train with intensity =\", float(noise_intensity))\n",
    "u_train = u_train[:N, :]; v_train = v_train[:N, :]\n",
    "\n",
    "u_train, v_train = to_tensor(u_train, False), to_tensor(v_train, False)\n",
    "h_train = torch.complex(u_train, v_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1 = 0.002494+1.002397*1j\n",
    "cn2 = 0.003655+0.500415*1j\n",
    "cns = [cn1, cn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X1 {X1, X0}\n",
      "X2 {X2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ComplexSymPyModule(\n",
       "  (sympymodule): SymPyModule(expressions=(X0*X1, X2))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X1\"\n",
    "pde_expr1, variables1,  = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X2\"\n",
    "pde_expr2, variables2,  = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, init_cs=(0.0, -1.0), init_betas=(0.0, 0.0)):\n",
    "        super(RobustComplexPINN, self).__init__()\n",
    "        # FFTNN\n",
    "        self.out_fft_nn = FFTNN(c=init_cs[0])\n",
    "        self.in_fft_nn = FFTNN(c=init_cs[1])\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # Beta-Robust PCA\n",
    "        self.inp_rpca = RobustPCANN(beta=init_betas[0], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        self.out_rpca = RobustPCANN(beta=init_betas[1], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "\n",
    "        self.callable_loss_fn = loss_fn\n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None):\n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def forward(self, H):\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, HL, HS, y_input, y_input_S, update_network_params=True, update_pde_params=True):\n",
    "        total_loss = []\n",
    "        \n",
    "        # Denoising FFT on (x, t)\n",
    "        HS = cat(torch.fft.ifft(self.in_fft_nn(HS[1])*HS[0]).real.reshape(-1, 1), \n",
    "                 torch.fft.ifft(self.in_fft_nn(HS[3])*HS[2]).real.reshape(-1, 1))\n",
    "        HS = HL-HS\n",
    "        \n",
    "        # Denoising FFT on y_input\n",
    "        y_input_S = y_input-torch.fft.ifft(self.out_fft_nn(y_input_S[1])*y_input_S[0]).reshape(-1, 1)\n",
    "        \n",
    "        H = self.inp_rpca(HL, HS, normalize=True)\n",
    "        \n",
    "        y_input = self.out_rpca(cat(y_input.real, y_input.imag), \n",
    "                                cat(y_input_S.real, y_input_S.imag), \n",
    "                                normalize=True)\n",
    "        y_input = torch.complex(y_input[:, 0:1], y_input[:, 1:2])\n",
    "        \n",
    "        grads_dict, u_t = self.grads_dict(H[:, 0:1], H[:, 1:2])\n",
    "        \n",
    "        # MSE Loss\n",
    "        if update_network_params:\n",
    "            total_loss.append(complex_mse(grads_dict['X'+self.feature2index['hf']], y_input))\n",
    "        # PDE Loss\n",
    "        if update_pde_params:\n",
    "            total_loss.append(complex_mse(self.callable_loss_fn(grads_dict), u_t))\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(cat(x, t))\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = {}\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives['X'+self.feature2index[t]] = cplx2tensor(uf)\n",
    "                derivatives['X1'] = (uf.real**2+uf.imag**2)+0.0j\n",
    "            elif t=='x': derivatives['X'+self.feature2index[t]] = x\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives['X'+self.feature2index['h_'+t[::-1]]] = out\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "    \n",
    "    # Must ensure that the implementation of neural_net_scale is consistent\n",
    "    # and hopefully correct\n",
    "    # also, you might not need this function in some datasets\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model\n",
    "semisup_model_state_dict = cpu_load(\"./saved_path_inverse_nls/NLS_complex_model_500labeledsamples_jointtrainwith500unlabeledsamples.pth\")\n",
    "parameters = OrderedDict()\n",
    "\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = RobustComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, scale=False, lb=lb, ub=ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global X_train, X_train_S, h_train, h_train_S, x_fft, x_PSD, t_fft, t_PSD\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), h_train, (h_train_fft, h_train_PSD), update_network_params=True, update_pde_params=True)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: \n",
    "        l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def mtl_closure():\n",
    "    global X_train, X_train_S, h_train, h_train_S, x_fft, x_PSD, t_fft, t_PSD\n",
    "    n_obj = 2 # There are two tasks\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), h_train, (h_train_fft, h_train_PSD), update_network_params=True, update_pde_params=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(n_obj):\n",
    "        optimizer1.zero_grad(set_to_none=True)\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in list(pinn.model.parameters())+list(pinn.inp_rpca.parameters())+list(pinn.out_rpca.parameters()):\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(list(pinn.model.parameters())+list(pinn.inp_rpca.parameters())+list(pinn.out_rpca.parameters())):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best thresold wrt to the first-epoch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_x, x_fft, x_PSD = fft1d_denoise(X_train[:, 0:1], c=0, return_real=True)\n",
    "noise_x = X_train[:, 0:1]-noise_x\n",
    "noise_t, t_fft, t_PSD = fft1d_denoise(X_train[:, 1:2], c=0, return_real=True)\n",
    "noise_t = X_train[:, 1:2]-noise_t\n",
    "X_train_S = cat(noise_x, noise_t)\n",
    "\n",
    "h_train_S, h_train_fft, h_train_PSD = fft1d_denoise(h_train, c=-1, return_real=False)\n",
    "h_train_S = h_train-h_train_S\n",
    "\n",
    "del noise_x, noise_t\n",
    "### ----- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.fft.ifft(FFTNN(c=0.)(x_PSD)*x_fft)\n",
    "# X_train_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pinn = RobustComplexPINN(model=complex_model, loss_fn=mod, \n",
    "                         index2features=feature_names, scale=False, lb=lb, ub=ub, \n",
    "                         init_cs=(0.0, -1.0), init_betas=(1.0, 1.0))\n",
    "\n",
    "c_range = np.arange(-5.0, 5.1, step=0.1)\n",
    "\n",
    "performances = []\n",
    "for c in c_range:\n",
    "    pinn.out_fft_nn.c = nn.Parameter(data=torch.FloatTensor([float(c)]), requires_grad=False)\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), h_train, (h_train_fft, h_train_PSD), update_network_params=True, update_pde_params=True)\n",
    "    performances.append(sum(losses).item())\n",
    "if 'pinn' in globals(): del pinn\n",
    "plt.plot(c_range, performances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best c = 0.9999999999999787\n"
     ]
    }
   ],
   "source": [
    "performances = npar(performances)\n",
    "indices = np.where(performances == performances.min())[0]\n",
    "if c_range[indices.min()] > 0.0: \n",
    "    bcs = (min(c_range[indices.min()], c_range[indices.max()]), -1.0)\n",
    "else: \n",
    "    bcs = (max(c_range[indices.min()], c_range[indices.max()]), -1.0)\n",
    "print(\"The best c =\", bcs[0])\n",
    "del c_range, performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Phase optimization using Adam with PCGrad gradient modification\n",
      "Epoch 0:  0.014002625830471516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../lookahead.py:38: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  0.010704325512051582\n",
      "Epoch 20:  0.009239306673407555\n",
      "Epoch 30:  0.008272606879472733\n",
      "Epoch 40:  0.00858551636338234\n",
      "Epoch 50:  0.008114614523947239\n",
      "Epoch 60:  0.007695917971432209\n",
      "Epoch 70:  0.007646770682185888\n",
      "Epoch 80:  0.007540084421634674\n",
      "Epoch 90:  0.007300939876586199\n",
      "Epoch 99:  0.0073193819262087345\n"
     ]
    }
   ],
   "source": [
    "pinn = RobustComplexPINN(model=complex_model, loss_fn=mod, \n",
    "                         index2features=feature_names, scale=False, lb=lb, ub=ub, \n",
    "                         init_cs=bcs, init_betas=(0.0, 0.0))\n",
    "\n",
    "epochs1, epochs2 = 100, 0\n",
    "# list(pinn.model.parameters())+list(pinn.inp_rpca.parameters())+list(pinn.out_rpca.parameters())\n",
    "# pinn.parameters()\n",
    "optimizer1 = MADGRAD(list(pinn.model.parameters())+list(pinn.inp_rpca.parameters())+list(pinn.out_rpca.parameters()), lr=1e-7, momentum=0.9)\n",
    "in_fft_opt = lookahead.LookaheadAdam(pinn.in_fft_nn.parameters(), lr=1.0)\n",
    "out_fft_opt = lookahead.LookaheadAdam(pinn.out_fft_nn.parameters(), lr=1.0)\n",
    "\n",
    "pinn.train(); best_train_loss = 1e6\n",
    "print('1st Phase optimization using Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    in_fft_opt.step()\n",
    "    in_fft_opt.zero_grad()\n",
    "    out_fft_opt.step()\n",
    "    out_fft_opt.zero_grad()\n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        l = mtl_closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Phase optimization using LBFGS\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=500, max_eval=int(500*1.25), history_size=150, line_search_fn='strong_wolfe')\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    if (i % 5) == 0 or i == epochs2-1:\n",
    "        l = closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        print(pinn.callable_loss_fn.complex_coeffs().detach().numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9999985098838806, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn.in_fft_nn.c.item(), pinn.out_fft_nn.c.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights for testing\n",
    "# pinn = load_weights(pinn, \"./saved_path_inverse_nls/final_finetuned_uncert_cpinn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.002494+1.002397j, 0.003655+0.500415j], dtype=complex64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_coeffs = pinn.callable_loss_fn.complex_coeffs().detach().numpy().ravel()\n",
    "est_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16134977340698242, 0.07834434509277344)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_coeffs = pinn.callable_loss_fn.complex_coeffs().detach().numpy().ravel()\n",
    "grounds = np.array([1j, 0+0.5j])\n",
    "\n",
    "errs = []\n",
    "for i in range(len(grounds)):\n",
    "    err = est_coeffs[i]-grounds[i]\n",
    "    errs.append(100*abs(err.imag)/abs(grounds[i].imag))\n",
    "errs = np.array(errs)\n",
    "errs.mean(), errs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(pinn, \"./saved_path_inverse_nls/noisy2_final_finetuned_doublebetarpca_fftcpinn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.0004], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0002], requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn.inp_rpca.beta, pinn.out_rpca.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Exact & Clean (x, t)\n",
    "# (0.05885958671569824, 0.021964311599731445)\n",
    "# array([-0.00046226+0.99919176j, -0.00056662+0.49981552j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t)\n",
    "# (0.6996273994445801, 0.01595020294189453)\n",
    "# array([0.00149273+0.9928442j, 0.00079829+0.5034184j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Clean (x, t) & X_star = X_star-X_star_S\n",
    "# (0.7112264633178711, 0.00553131103515625)\n",
    "# array([ 3.449592e-03+1.007057j , -7.125967e-05+0.5035838j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t) & X_star = X_star-X_star_S\n",
    "# (0.7093071937561035, 0.0036716461181640625)\n",
    "# array([ 3.4442921e-03+1.0070564j, -5.4004795e-05+0.5035649j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Clean (x, t) & X_star = X_star_L+1*X_star_S\n",
    "# (0.1215517520904541, 0.08192658424377441)\n",
    "# array([-8.2360100e-05+0.99960375j, -6.1671366e-05+0.5010174j], dtype=complex64)\n",
    "# Noisy Exact & Noisy (x, t) & X_star = X_star_L+1*X_star_S\n",
    "# (0.511014461517334, 0.25589466094970703)\n",
    "# array([-0.01472272+1.0076691j, -0.02164156+0.5012756j], dtype=complex64)\n",
    "\n",
    "# Noisy Exact & Noisy (x, t) & X_train = X_train_L+1*1*X_train_S+beta*NN(X_train_S)\n",
    "# (0.5050361156463623, 0.1848280429840088)\n",
    "# array([ 0.00107117+1.0032021j, -0.01103256+0.5034493j], dtype=complex64)\n",
    "# beta = 0.005178438033908606\n",
    "\n",
    "# Notes\n",
    "# X_star = X_star-X_star_S -> Seems robust but not stable\n",
    "# X_star = X_star_L+X_star_S -> The best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### New results on Double Beta-RobustFFT ###\n",
    "# Noisy Exact & Clean (x, t)\n",
    "# array([-4.01791149e-05+0.9997733j, 1.09734545e-04+0.5006671j], dtype=complex64)\n",
    "# (0.07804334163665771, 0.05537569522857666)\n",
    "# (pinn.inp_rpca.beta Parameter containing:\n",
    "#  tensor([0.0085], requires_grad=True),\n",
    "#  pinn.out_rpca.beta Parameter containing:\n",
    "#  tensor([0.0027], requires_grad=True))\n",
    "\n",
    "# Noisy Exact & Noisy (x, t)\n",
    "# array([0.002494+1.002397j, 0.003655+0.500415j], dtype=complex64)\n",
    "# (0.16134977340698242, 0.07834434509277344)\n",
    "# (pinn.inp_rpca.beta Parameter containing:\n",
    "#  tensor([0.0003], requires_grad=True),\n",
    "#  pinn.out_rpca.beta Parameter containing:\n",
    "#  tensor([-0.0003], requires_grad=True))\n",
    "\n",
    "### Results on Double Beta-RobustPCA ###\n",
    "# Noisy Exact & Clean (x, t)\n",
    "# array([0.00077563+1.0028679j, 0.00166233+0.50137794j], dtype=complex64)\n",
    "# (0.2811908721923828, 0.005602836608886719)\n",
    "# (pinn.inp_rpca.beta Parameter containing:\n",
    "#  tensor([-0.0002], requires_grad=True),\n",
    "#  pinn.out_rpca.beta Parameter containing:\n",
    "#  tensor([0.0002], requires_grad=True))\n",
    "\n",
    "# Noisy Exact & Noisy (x, t)\n",
    "# array([-0.00045199+1.0037338j, 0.00022461+0.5013247j], dtype=complex64)\n",
    "# (0.31915903091430664, 0.05421638488769531)\n",
    "# (pinn.inp_rpca.beta Parameter containing:\n",
    "#  tensor([-0.0011], requires_grad=True),\n",
    "#  pinn.out_rpca.beta Parameter containing:\n",
    "#  tensor([-0.0002], requires_grad=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
