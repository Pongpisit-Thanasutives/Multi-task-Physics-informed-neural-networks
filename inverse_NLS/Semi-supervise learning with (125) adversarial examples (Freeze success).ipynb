{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, ComplexTorchMLP, complex_mse\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Training with 500 unsup samples\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "N = 250; include_N_res = 2\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "# Unsup data\n",
    "if include_N_res>0:\n",
    "    N_res = int(N*include_N_res)\n",
    "    idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "    idx_res = idx_res[:N_res]\n",
    "    X_res = to_tensor(X_star[idx_res, :], True)\n",
    "    print(f\"Training with {N_res} unsup samples\")\n",
    "    X_train = torch.vstack([X_train, X_res])\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[i,:] = FiniteDiff(Exact[i,:], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[:,i] = FiniteDiff(Exact[:,i], dx, 1)\n",
    "    fd_h_xx[:,i] = FiniteDiff(Exact[:,i], dx, 2)\n",
    "    fd_h_xxx[:,i] = FiniteDiff(Exact[:,i], dx, 3)\n",
    "    \n",
    "fd_h_t = np.reshape(fd_h_t, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_x = np.reshape(fd_h_x, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xx = np.reshape(fd_h_xx, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xxx = np.reshape(fd_h_xxx, (spatial_dim*time_dim,1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "# complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn_model.pth\"))\n",
    "complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_complex_model_250labeledsamples.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "(1) Re-implement the semisup_model for a complex network.\n",
    "\n",
    "(2) Implement the self.gradients function.\n",
    "- complex_model(input) -> diff(u_pred, x) & diff(v_pred, x) -> combine 2 diff terms as 1 complex vector -> compute PDE loss / passing to the selector network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train[:N, :], True))\n",
    "predictions = complex_model(cat(xx, tt))\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.06768140941858292\n",
      "MSE Loss 0.00016536572366021574\n"
     ]
    }
   ],
   "source": [
    "# PDE Loss 1.1325556442898232e-05\n",
    "# MSE Loss 4.512887699092971e-06\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions, u_train+1j*v_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00+0.0000000e+00j,  1.4905547e+00-2.1129534e-02j,\n",
       "         2.2221999e+00+0.0000000e+00j, ...,\n",
       "        -5.7524107e-02+1.8792991e-01j,  4.1990614e-01+3.2963214e+00j,\n",
       "         2.9387558e+01+4.7884449e+01j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  4.0520504e-01+1.7597510e-01j,\n",
       "         1.9515835e-01+0.0000000e+00j, ...,\n",
       "         6.7672483e-03-5.4848014e-04j, -3.3896230e-02-3.0026563e-02j,\n",
       "         1.2093678e-02+3.0177814e-01j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  2.2977489e-01+2.0623957e-01j,\n",
       "         9.5331259e-02+0.0000000e+00j, ...,\n",
       "         8.0982819e-03+1.0625677e-01j,  1.7564371e-04-7.2466865e-02j,\n",
       "        -3.9830990e-03+4.9118374e-02j],\n",
       "       ...,\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  2.7723348e-01+9.5022783e-02j,\n",
       "         8.5887730e-02+0.0000000e+00j, ...,\n",
       "         1.9977279e-02+3.2644931e-02j,  3.6835643e-03-9.8376647e-03j,\n",
       "        -2.7500875e-03+8.6603750e-04j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  3.2089651e-02+1.8794075e-02j,\n",
       "         1.3829629e-03+0.0000000e+00j, ...,\n",
       "         1.3814771e-03+6.3435931e-04j, -1.3652126e-03-7.8891945e-04j,\n",
       "         1.3334451e-03+9.4695901e-04j],\n",
       "       [ 1.0000000e+00+0.0000000e+00j,  6.9279075e-02+7.3127896e-03j,\n",
       "         4.8530670e-03+0.0000000e+00j, ...,\n",
       "         6.3693915e-03+3.5046027e-03j,  4.7720755e-03+2.3826163e-03j,\n",
       "         3.5682116e-03+1.6068856e-03j]], dtype=complex64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "complex_poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (0.043077 +0.207892i)hf\n",
      "    + (0.080817 -0.032134i)|hf|\n",
      "    + (0.055382 +0.535730i)h_xx\n",
      "    + (0.003828 +0.001476i)h_xxx\n",
      "    + (-0.177429 -0.119500i)hf^2\n",
      "    + (0.025840 +0.974030i)hf |hf|\n",
      "    + (-0.028750 -0.013797i)hf h_xx\n",
      "    + (-0.021393 +0.017177i)|hf|^2\n",
      "    + (-0.007629 -0.017062i)|hf| h_xx\n",
      "    + (-0.000762 -0.000025i)|hf| h_xxx\n",
      "    + (0.026439 +0.021175i)h_x^2\n",
      "    + (0.000106 +0.001197i)h_x h_xxx\n",
      "    + (0.002654 +0.000072i)h_xx^2\n",
      "    + (-0.000072 -0.000060i)h_xx h_xxx\n",
      "    + (-0.000040 +0.000050i)h_xxx^2\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, 500, maxit=500)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic differentiation w/ and w/o Finite difference guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = []\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives.append(cplx2tensor(uf))\n",
    "                derivatives.append((uf.real**2+uf.imag**2)+0.0j)\n",
    "            elif t=='x': derivatives.append(x)\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "        \n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    }
   ],
   "source": [
    "complex_network = ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "X_selector, y_selector = complex_network.get_selector_data(*dimension_slicing(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=torch.sigmoid, bn=None, reg_intensity=0.1):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, activation_function=CplxToCplx[F.relu](), bn=bn, dropout_rate=0.0)\n",
    "        self.latest_weighted_features = None\n",
    "        self.th = 0.1\n",
    "        self.reg_intensity = reg_intensity\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        feature_importances = self.weighted_features(inn)\n",
    "        inn = inn*feature_importances\n",
    "        return self.nonlinear_model(inn)\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "        self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n",
    "        self.latest_weighted_features = self.latest_weighted_features.mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = complex_mse(ut_approx, y_input)\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        return mse_loss+self.reg_intensity*(torch.norm(reg_term, p=0)+(torch.tensor([1.0, 1.0, 2.0, 3.0, 4.0])*reg_term).sum())\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None, uncert=False):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        self.weights = None\n",
    "        if uncert: \n",
    "            self.weights = torch.tensor([0.0, 0.0])\n",
    "        \n",
    "    def forward(self, X_h_train, h_train, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_h_train))\n",
    "        \n",
    "        h_row = h_train.shape[0]\n",
    "        fd_guidance = complex_mse(self.network.uf[:h_row, :], h_train)\n",
    "        \n",
    "        # I am not sure a good way to normalize/scale a complex tensor\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "            \n",
    "        if include_unsup and self.weights is not None:\n",
    "            return (torch.exp(-self.weights[0])*fd_guidance)+self.weights[0], (torch.exp(-self.weights[1])*unsup_loss)+self.weights[1]\n",
    "        else:\n",
    "            return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "h_star = (u_star+1j*v_star)\n",
    "\n",
    "fd_derivatives = np.hstack([h_star, h_star.real**2+h_star.imag**2, fd_h_x, fd_h_xx, fd_h_xxx])\n",
    "\n",
    "semisup_model = SemiSupModel(\n",
    "    network=ComplexNetwork(model=complex_model, index2features=feature_names, scale=False, lb=lb, ub=ub),\n",
    "    selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True),\n",
    "    normalize_derivative_features=False,\n",
    "    mini=torch.tensor(np.abs(fd_derivatives).min(axis=0), dtype=torch.cfloat),\n",
    "    maxi=torch.tensor(np.abs(fd_derivatives).max(axis=0), dtype=torch.cfloat),\n",
    "    uncert=True,\n",
    ")\n",
    "\n",
    "del h_star, fd_derivatives, fd_h_x, fd_h_xx, fd_h_xxx\n",
    "\n",
    "# semisup_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_selector = (X_selector - semisup_model.mini) / (semisup_model.maxi-semisup_model.mini)\n",
    "# selector_optimizer = MADGRAD(selector.parameters(), lr=5e-2)\n",
    "# for i in range(50000):\n",
    "#     selector_optimizer.zero_grad()\n",
    "#     l = complex_mse(selector(X_selector), y_selector)\n",
    "#     l.backward(retain_graph=True)\n",
    "#     selector_optimizer.step()\n",
    "#     print(l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(selector.state_dict(), './saved_path_inverse_nls/selector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_UNCERT = True\n",
    "def pcgrad_closure(return_list=False):\n",
    "    global IS_UNCERT, N, X_train, u_train, v_train, fd_derivatives, fd_u_t\n",
    "    fd_guidance, unsup_loss = semisup_model(X_train, u_train+1j*v_train, include_unsup=True)      \n",
    "    losses = [fd_guidance, unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return sum(losses)\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.2797, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.3639, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.3625, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.2557, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.3674, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.4608, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.3587, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.2534, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.2550, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0002, grad_fn=<AddBackward0>), tensor(0.3535, grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# Joint training\n",
    "optimizer = MADGRAD([{'params':semisup_model.network.parameters()}, {'params':semisup_model.selector.parameters()}], lr=1e-6)\n",
    "optimizer.param_groups[0]['lr'] = 1e-11\n",
    "optimizer.param_groups[1]['lr'] = 1e-1\n",
    "\n",
    "best_loss = 1000; best_state = None\n",
    "# TODO: also need the adversarial examples as well (Use ~idx to sample)\n",
    "for i in range(100):\n",
    "    semisup_model.train()\n",
    "    optimizer.step(pcgrad_closure)\n",
    "    loss = pcgrad_closure(return_list=True)\n",
    "\n",
    "#     if 1000*loss[0].item()+loss[1].item() < best_loss:\n",
    "#         best_loss = 1000*loss[0].item()+loss[1].item()\n",
    "#         best_state = semisup_model.state_dict()\n",
    "    \n",
    "    if i%10==0:\n",
    "        print(loss)\n",
    "        \n",
    "# semisup_model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n",
      "/Users/pongpisit/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.04343290627002716\n",
      "MSE Loss 0.00015923423052299768\n",
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n",
      "PDE derived using STRidge\n",
      "u_t = (0.005410 +0.490379i)h_xx\n",
      "    + (0.011262 +0.978652i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train[:N, :], True))\n",
    "predictions = semisup_model.network(xx, tt)\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)\n",
    "\n",
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())\n",
    "\n",
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "\n",
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, d_tol=500, maxit=500)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(semisup_model.state_dict(), \"saved_path_inverse_nls/NLS_complex_model_250labeledsamples_jointtrainwith125unlabeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
