{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.6\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, ComplexTorchMLP, complex_mse\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from complexPyTorch.complexLayers import ComplexBatchNorm1d, ComplexLinear\n",
    "# from complexPyTorch.complexFunctions import complex_relu\n",
    "# class ComplexNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ComplexNet, self).__init__()\n",
    "#         self.fc1 = ComplexLinear(5, 100)\n",
    "#         self.fc2 = ComplexLinear(100, 100)\n",
    "#         self.fc3 = ComplexLinear(100, 1)\n",
    "#     def forward(self, inp):\n",
    "#         inp = complex_relu(self.fc1(inp))\n",
    "#         inp = complex_relu(self.fc2(inp))\n",
    "#         return self.fc3(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Training with 500 unsup samples\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "\n",
    "DATA_PATH = '../experimental_data/NLS.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = to_column_vector(Exact_u.T)\n",
    "v_star = to_column_vector(Exact_v.T)\n",
    "\n",
    "N = 500; include_N_res = 1\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "\n",
    "# Unsup data\n",
    "if include_N_res>0:\n",
    "    N_res = int(N*include_N_res)\n",
    "    idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "    idx_res = idx_res[:N_res]\n",
    "    X_res = to_tensor(X_star[idx_res, :], True)\n",
    "    print(f\"Training with {N_res} unsup samples\")\n",
    "    X_train = torch.vstack([X_train, X_res])\n",
    "\n",
    "feature_names = ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-calculated (clean) data for reproducibility\n",
      "Noisy (x, t)\n",
      "Perturbed u_train and v_train with intensity = 0.01\n"
     ]
    }
   ],
   "source": [
    "### Loading (clean) data code here ###\n",
    "noise_intensity = 0.01; noisy_xt = True\n",
    "\n",
    "print(\"Loading pre-calculated (clean) data for reproducibility\")\n",
    "X_train = np.load(\"./tmp_files/X_train_500+500samples.npy\")\n",
    "\n",
    "if noise_intensity > 0.0 and noisy_xt:\n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_train = perturb(X_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "\n",
    "X_train = to_tensor(X_train, True)[:N, :]\n",
    "\n",
    "uv_train = np.load(\"./tmp_files/uv_train_500samples.npy\")\n",
    "u_train = uv_train[:, 0:1]; v_train = uv_train[:, 1:2]\n",
    "\n",
    "if noise_intensity > 0.0:\n",
    "    noise_u = perturb(u_train, intensity=noise_intensity, noise_type=\"normal\", overwrite=False)\n",
    "    u_train = u_train + noise_u\n",
    "    noise_v = perturb(v_train, intensity=noise_intensity, noise_type=\"normal\", overwrite=False)\n",
    "    v_train = v_train + noise_v\n",
    "    print(\"Perturbed u_train and v_train with intensity =\", float(noise_intensity))\n",
    "u_train = u_train[:N, :]; v_train = v_train[:N, :]\n",
    "\n",
    "u_train, v_train = to_tensor(u_train, False), to_tensor(v_train, False)\n",
    "h_train = torch.complex(u_train, v_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((spatial_dim, time_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[i,:] = FiniteDiff(Exact[i,:], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[:,i] = FiniteDiff(Exact[:,i], dx, 1)\n",
    "    fd_h_xx[:,i] = FiniteDiff(Exact[:,i], dx, 2)\n",
    "    fd_h_xxx[:,i] = FiniteDiff(Exact[:,i], dx, 3)\n",
    "    \n",
    "fd_h_t = np.reshape(fd_h_t, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_x = np.reshape(fd_h_x, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xx = np.reshape(fd_h_xx, (spatial_dim*time_dim,1), order='F')\n",
    "fd_h_xxx = np.reshape(fd_h_xxx, (spatial_dim*time_dim,1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "# complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn_model.pth\"))\n",
    "complex_model.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_complex_model_500labeledsamples.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ComplexPhysicsInformedNN(nn.Module):\n",
    "#     def __init__(self, model, lb, ub, scale=False):\n",
    "#         super(ComplexPhysicsInformedNN, self).__init__()\n",
    "#         self.model = model\n",
    "#         self.lb = lb\n",
    "#         self.ub = ub\n",
    "#         self.scale = scale\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         if self.scale: \n",
    "#             return self.model(self.neural_net_scale(X))\n",
    "#         return self.model(X)\n",
    "\n",
    "#     def predict(self, X_test):\n",
    "#         return CplxToReal()(self.forward(self.preprocess(*dimension_slicing(X_test))))\n",
    "    \n",
    "#     def neural_net_scale(self, inp):\n",
    "#         return (2.0*(inp-self.lb)/(self.ub-self.lb))-1.0\n",
    "\n",
    "#     def preprocess(self, spatial, time):\n",
    "#         return cat(spatial, time)\n",
    "    \n",
    "#     def loss(self, X_f, X0, h0, X_lb, X_ub):\n",
    "#         loss = self.net_f(*dimension_slicing(X_f))\n",
    "#         h0_pred = self.predict(X0); u0 = h0_pred[:, 0:1]; v0 = h0_pred[:, 1:2]\n",
    "#         loss += F.mse_loss(u0, h0[:, 0:1])+F.mse_loss(v0, h0[:, 1:2])\n",
    "#         u_lb, v_lb, u_lb_x, v_lb_x = self.net_h(*dimension_slicing(X_lb))\n",
    "#         u_ub, v_ub, u_ub_x, v_ub_x = self.net_h(*dimension_slicing(X_ub))\n",
    "#         loss += F.mse_loss(u_lb, u_ub)\n",
    "#         loss += F.mse_loss(v_lb, v_ub)\n",
    "#         loss += F.mse_loss(u_lb_x, u_ub_x)\n",
    "#         loss += F.mse_loss(v_lb_x, v_ub_x)\n",
    "#         return loss\n",
    "    \n",
    "#     def net_h(self, x, t):\n",
    "#         X = cat(x, t)\n",
    "#         h = self.forward(X)\n",
    "#         u = h.real\n",
    "#         v = h.imag\n",
    "#         return u, v, self.diff(u, x), self.diff(v, x)\n",
    "    \n",
    "#     def net_f(self, x, t):\n",
    "#         u, v, u_x, v_x = self.net_h(x, t)\n",
    "#         u_t, v_t = self.diff(u, t), self.diff(v, t)\n",
    "#         u_xx, v_xx = self.diff(u_x, x), self.diff(v_x, x)\n",
    "#         f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "#         f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "#         return (f_u**2).mean()+(f_v**2).mean()\n",
    "\n",
    "#     def diff(self, func, inp):\n",
    "#         return grad(func, inp, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape, dtype=func.dtype).to(device))[0]\n",
    "\n",
    "#     def complex_mse(self, v1, v2):\n",
    "#         assert v1.shape == v2.shape\n",
    "#         assert v1.shape[1] == 1\n",
    "#         return F.mse_loss(v1.real, v2.real)+F.mse_loss(v2.imag, v2.imag)\n",
    "\n",
    "#     def add_imag_dim(self, v1):\n",
    "#         z = torch.zeros(v1.shape).requires_grad_(False).to(device)\n",
    "#         return torch.complex(v1, z)\n",
    "    \n",
    "# cpinn = ComplexPhysicsInformedNN(model=complex_model, lb=lb, ub=ub, scale=False).to(device)\n",
    "# cpinn.load_state_dict(cpu_load(\"./saved_path_inverse_nls/NLS_cpinn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "(1) Re-implement the semisup_model for a complex network.\n",
    "\n",
    "(2) Implement the self.gradients function.\n",
    "- complex_model(input) -> diff(u_pred, x) & diff(v_pred, x) -> combine 2 diff terms as 1 complex vector -> compute PDE loss / passing to the selector network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train[:N, :], True))\n",
    "predictions = complex_model(cat(xx, tt))\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.008728397078812122\n",
      "MSE Loss 0.0060231052339077\n"
     ]
    }
   ],
   "source": [
    "# PDE Loss 1.1325556442898232e-05\n",
    "# MSE Loss 4.512887699092971e-06\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions, u_train+1j*v_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00+0.00000000e+00j,  1.9147426e-01+8.85607541e-01j,\n",
       "         8.2096314e-01+0.00000000e+00j, ...,\n",
       "         2.1311289e+01-4.33222923e+01j,  4.2531631e+01-9.62094269e+01j,\n",
       "         8.4012672e+01-2.13232788e+02j],\n",
       "       [ 1.0000000e+00+0.00000000e+00j,  6.5606982e-01+1.59759939e-01j,\n",
       "         4.5595089e-01+0.00000000e+00j, ...,\n",
       "        -1.2804432e+00+5.38816977e+00j,  3.8101616e+00-1.40026169e+01j,\n",
       "        -1.1165583e+01+3.63486748e+01j],\n",
       "       [ 1.0000000e+00+0.00000000e+00j,  6.0534793e-01+2.37217247e-01j,\n",
       "         4.2271811e-01+0.00000000e+00j, ...,\n",
       "        -4.4467512e-01+4.95724231e-01j, -9.3275571e-01+1.83878565e+00j,\n",
       "        -1.3165183e+00+6.24646091e+00j],\n",
       "       ...,\n",
       "       [ 1.0000000e+00+0.00000000e+00j,  3.8080871e-02+5.28199077e-02j,\n",
       "         4.2400956e-03+0.00000000e+00j, ...,\n",
       "         4.6669855e-04+4.69129067e-03j,  3.2853568e-05+3.90463625e-03j,\n",
       "        -2.6596105e-04+3.22320266e-03j],\n",
       "       [ 1.0000000e+00+0.00000000e+00j,  1.5181571e-01+1.04344785e-01j,\n",
       "         3.3935845e-02+0.00000000e+00j, ...,\n",
       "         1.6657434e-02+3.32228728e-02j, -1.2481332e-02-2.42705792e-02j,\n",
       "         9.3475142e-03+1.77282356e-02j],\n",
       "       [ 1.0000000e+00+0.00000000e+00j,  5.3703785e-02+4.62900996e-02j,\n",
       "         5.0268704e-03+0.00000000e+00j, ...,\n",
       "         3.9532250e-03+6.14245795e-03j, -2.8780724e-03-5.58121456e-03j,\n",
       "         2.0041554e-03+5.01257554e-03j]], dtype=complex64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "complex_poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (0.009804 +0.644489i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-2, d_tol=50, maxit=1000)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic differentiation w/ and w/o Finite difference guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = []\n",
    "        for t in self.diff_flag[0]:\n",
    "            if t=='hf': \n",
    "                derivatives.append(cplx2tensor(uf))\n",
    "                derivatives.append((uf.real**2+uf.imag**2)+0.0j)\n",
    "            elif t=='x': derivatives.append(x)\n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "        \n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    }
   ],
   "source": [
    "complex_network = ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "X_selector, y_selector = complex_network.get_selector_data(*dimension_slicing(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=torch.sigmoid, bn=None, reg_intensity=0.1):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, activation_function=CplxToCplx[F.relu](), bn=bn, dropout_rate=0.0)\n",
    "        self.latest_weighted_features = None\n",
    "        self.th = 0.1\n",
    "        self.reg_intensity = reg_intensity\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        feature_importances = self.weighted_features(inn)\n",
    "        inn = inn*feature_importances\n",
    "        return self.nonlinear_model(inn)\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "        self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n",
    "        self.latest_weighted_features = self.latest_weighted_features.mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = complex_mse(ut_approx, y_input)\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        return mse_loss+self.reg_intensity*(torch.norm(reg_term, p=0)+(torch.tensor([1.0, 1.0, 2.0, 3.0, 4.0])*reg_term).sum())\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None, uncert=False):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        self.weights = None\n",
    "        if uncert: \n",
    "            self.weights = torch.tensor([0.0, 0.0])\n",
    "        \n",
    "    def forward(self, X_h_train, h_train, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_h_train))\n",
    "        \n",
    "        h_row = h_train.shape[0]\n",
    "        fd_guidance = complex_mse(self.network.uf[:h_row, :], h_train)\n",
    "        \n",
    "        # I am not sure a good way to normalize/scale a complex tensor\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "            \n",
    "        if include_unsup and self.weights is not None:\n",
    "            return (torch.exp(-self.weights[0])*fd_guidance)+self.weights[0], (torch.exp(-self.weights[1])*unsup_loss)+self.weights[1]\n",
    "        else:\n",
    "            return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', '|hf|', 'h_x', 'h_xx', 'h_xxx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "h_star = (u_star+1j*v_star)\n",
    "\n",
    "fd_derivatives = np.hstack([h_star, h_star.real**2+h_star.imag**2, fd_h_x, fd_h_xx, fd_h_xxx])\n",
    "\n",
    "semisup_model = SemiSupModel(\n",
    "    network=ComplexNetwork(model=complex_model, index2features=feature_names, scale=False, lb=lb, ub=ub),\n",
    "    selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True),\n",
    "    normalize_derivative_features=False,\n",
    "    mini=torch.tensor(np.abs(fd_derivatives).min(axis=0), dtype=torch.cfloat),\n",
    "    maxi=torch.tensor(np.abs(fd_derivatives).max(axis=0), dtype=torch.cfloat),\n",
    "    uncert=True,\n",
    ")\n",
    "\n",
    "del h_star, fd_derivatives, fd_h_x, fd_h_xx, fd_h_xxx\n",
    "\n",
    "# semisup_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_selector = (X_selector - semisup_model.mini) / (semisup_model.maxi-semisup_model.mini)\n",
    "# selector_optimizer = MADGRAD(selector.parameters(), lr=5e-2)\n",
    "# for i in range(50000):\n",
    "#     selector_optimizer.zero_grad()\n",
    "#     l = complex_mse(selector(X_selector), y_selector)\n",
    "#     l.backward(retain_graph=True)\n",
    "#     selector_optimizer.step()\n",
    "#     print(l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(selector.state_dict(), './saved_path_inverse_nls/selector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_UNCERT = True\n",
    "def pcgrad_closure(return_list=False):\n",
    "    global IS_UNCERT, N, X_train, u_train, v_train, fd_derivatives, fd_u_t\n",
    "    fd_guidance, unsup_loss = semisup_model(X_train, u_train+1j*v_train, include_unsup=True)      \n",
    "    losses = [fd_guidance, unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return sum(losses)\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-72706496db04>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0060, grad_fn=<AddBackward0>), tensor(11.8411, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0083, grad_fn=<AddBackward0>), tensor(1.8544, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0108, grad_fn=<AddBackward0>), tensor(0.6180, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0113, grad_fn=<AddBackward0>), tensor(0.4567, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0111, grad_fn=<AddBackward0>), tensor(0.3907, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0107, grad_fn=<AddBackward0>), tensor(0.3713, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0099, grad_fn=<AddBackward0>), tensor(0.2623, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0092, grad_fn=<AddBackward0>), tensor(0.3591, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0086, grad_fn=<AddBackward0>), tensor(0.4578, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0081, grad_fn=<AddBackward0>), tensor(0.3569, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0077, grad_fn=<AddBackward0>), tensor(0.4566, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0073, grad_fn=<AddBackward0>), tensor(0.3615, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0067, grad_fn=<AddBackward0>), tensor(0.4746, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0063, grad_fn=<AddBackward0>), tensor(0.3638, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0061, grad_fn=<AddBackward0>), tensor(0.2585, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0060, grad_fn=<AddBackward0>), tensor(0.3614, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0060, grad_fn=<AddBackward0>), tensor(0.4572, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0059, grad_fn=<AddBackward0>), tensor(0.3611, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0058, grad_fn=<AddBackward0>), tensor(0.3587, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0058, grad_fn=<AddBackward0>), tensor(0.4540, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0056, grad_fn=<AddBackward0>), tensor(0.4159, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0054, grad_fn=<AddBackward0>), tensor(0.3918, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0054, grad_fn=<AddBackward0>), tensor(0.3618, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0053, grad_fn=<AddBackward0>), tensor(0.3601, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0052, grad_fn=<AddBackward0>), tensor(0.2551, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0052, grad_fn=<AddBackward0>), tensor(0.2539, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0052, grad_fn=<AddBackward0>), tensor(0.2525, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.4516, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.4532, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.3520, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.2519, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.2695, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.4836, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.4609, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.3550, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0051, grad_fn=<AddBackward0>), tensor(0.2522, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3513, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3508, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.4509, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.4507, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3507, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3511, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3700, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.4656, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.4529, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0050, grad_fn=<AddBackward0>), tensor(0.3515, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0049, grad_fn=<AddBackward0>), tensor(0.3512, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0049, grad_fn=<AddBackward0>), tensor(0.3507, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0049, grad_fn=<AddBackward0>), tensor(0.4506, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0049, grad_fn=<AddBackward0>), tensor(0.2508, grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# Joint training\n",
    "optimizer = MADGRAD([{'params':semisup_model.network.parameters()}, {'params':semisup_model.selector.parameters()}], lr=1e-6)\n",
    "optimizer.param_groups[0]['lr'] = 1e-11\n",
    "optimizer.param_groups[1]['lr'] = 1e-1\n",
    "\n",
    "best_loss = 1000; best_state = None\n",
    "# TODO: also need the adversarial examples as well (Use ~idx to sample)\n",
    "for i in range(500):\n",
    "    semisup_model.train()\n",
    "    optimizer.step(pcgrad_closure)\n",
    "    loss = pcgrad_closure(return_list=True)\n",
    "\n",
    "#     if 1000*loss[0].item()+loss[1].item() < best_loss:\n",
    "#         best_loss = 1000*loss[0].item()+loss[1].item()\n",
    "#         best_state = semisup_model.state_dict()\n",
    "    \n",
    "    if i%10==0: print(loss)\n",
    "        \n",
    "# semisup_model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_weights(semisup_model, \"./saved_path_inverse_nls/NLS_complex_model_500labeledsamples_jointtrainwith500unlabeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_NLS/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "xx, tt = dimension_slicing(to_tensor(X_train, True))\n",
    "predictions = semisup_model.network(xx, tt)\n",
    "h = cplx2tensor(predictions)\n",
    "h_x = complex_diff(predictions, xx)\n",
    "h_xx = complex_diff(h_x, xx)\n",
    "h_xxx = complex_diff(h_xx, xx)\n",
    "h_t = complex_diff(predictions, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE Loss 0.0602140836417675\n",
      "MSE Loss 0.004893707111477852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-f31165840332>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())\n"
     ]
    }
   ],
   "source": [
    "f = 1j*h_t+0.5*h_xx+(h.abs()**2)*h\n",
    "real_loss = (f.real**2).mean(); imag_loss = (f.imag**2).mean()\n",
    "avg_loss = (real_loss+imag_loss)*0.5\n",
    "print(\"PDE Loss\", avg_loss.item())\n",
    "print(\"MSE Loss\", complex_mse(predictions[:N, :], torch.tensor(u_train+1j*v_train, dtype=torch.cfloat)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing |hf|\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing hf^2\n",
      "Computing hf |hf|\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing |hf|^2\n",
      "Computing |hf| h_x\n",
      "Computing |hf| h_xx\n",
      "Computing |hf| h_xxx\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xxx^2\n"
     ]
    }
   ],
   "source": [
    "derivatives = to_numpy(cat(h, h.abs()**2, h_x, h_xx, h_xxx))\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDE derived using STRidge\n",
      "u_t = (-0.016447 +0.509700i)h_xx\n",
      "    + (-0.020763 +1.029535i)hf |hf|\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-6, d_tol=50) # for Clean (x, t) and noisy labels\n",
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-2, d_tol=50, maxit=1000)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(semisup_model.state_dict(), \"saved_path_inverse_nls/noisy_NLS_complex_model_500labeledsamples_jointtrainwith500unlabeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all\n",
    "# cn1 = 0.002494+1.002397*1j\n",
    "# cn2 = 0.003655+0.500415*1j\n",
    "\n",
    "# Clean (x, t) and noisy labels\n",
    "# u_t = (-0.010605 +0.507761i)h_xx\n",
    "#     + (-0.008820 +1.008750i)hf |hf|\n",
    "\n",
    "# Noisy (x, t) and noisy labels\n",
    "# u_t = (-0.016447 +0.509700i)h_xx\n",
    "#     + (-0.020763 +1.029535i)hf |hf|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
