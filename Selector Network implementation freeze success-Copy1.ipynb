{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do I need to implement the GPU version for faster computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from torch.autograd import grad\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2000 samples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/pongpisit/Desktop/research/pinn/Solving-Differential-Equations-with-Neural-Networks/SymbolicMathematics/data/burgers_shock.mat\"\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 2000\n",
    "print(f\"Training with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = torch.tensor(X_u_train).float().requires_grad_(True)\n",
    "u_train = torch.tensor(u_train).float().requires_grad_(True)\n",
    "X_star = torch.tensor(X_star).float().requires_grad_(True)\n",
    "u_star = torch.tensor(u_star).float().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = model\n",
    "#         self.model.apply(self.xavier_init)\n",
    "        # For tracking\n",
    "        self.index2features = ('uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx')\n",
    "        self.uf = None\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.uf = self.model(torch.cat([x, t], dim=1))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # first-order derivatives\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        # Homo second-order derivatives\n",
    "        u_tt = self.gradients(u_t,t)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        # Hetero second-order derivatives\n",
    "        u_xt = self.gradients(u_t, x)[0]\n",
    "        u_tx = self.gradients(u_x, t)[0]\n",
    "        \n",
    "        X_selector = torch.cat([uf, u_x, u_xx, u_tt, u_xt, u_tx], dim=1)\n",
    "        y_selector = u_t\n",
    "        \n",
    "        return X_selector, y_selector\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the SeclectorNetwork has to be a neural networks ???\n",
    "class SeclectorNetwork(nn.Module):\n",
    "    def __init__(self, X_train_dim):\n",
    "        super().__init__()\n",
    "        # Nonlinear model, Training with noisy features -> chk feature importance\n",
    "        layers = [nn.Linear(X_train_dim, 50), nn.Tanh(), nn.Linear(50, 1)]\n",
    "        self.nonlinear_model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        ut_approx = self.nonlinear_model(inn)\n",
    "        return ut_approx\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = F.mse_loss(ut_approx, y_input, reduction='mean')\n",
    "        return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(model=simple_solver_model(50))\n",
    "selector = SeclectorNetwork(X_train_dim=6)\n",
    "\n",
    "optimizer = torch.optim.LBFGS(list(network.parameters()) + list(selector.parameters()), \n",
    "                              lr=5e-2, max_iter=80, max_eval=100, \n",
    "                              history_size=120, line_search_fn='strong_wolfe')\n",
    "\n",
    "# optimizer = torch.optim.Adam(list(network.parameters()) + list(selector.parameters()), lr=1e-3)\n",
    "epochs = 5000; testing = False\n",
    "\n",
    "if testing:\n",
    "    # unsupervised_loss\n",
    "    unsup_loss = selector.loss(*network.get_selector_data(*dimension_slicing(X_u_train)))\n",
    "    sup_loss = F.mse_loss(network.uf, u_train)\n",
    "\n",
    "    # No MTL yet, apply the naive summation first to see if it's working?\n",
    "    total_loss = unsup_loss + sup_loss\n",
    "    print(total_loss)\n",
    "\n",
    "    total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  0.0391339510679245\n",
      "Epoch 10:  0.010887873359024525\n",
      "Epoch 20:  0.008779932744801044\n",
      "Epoch 30:  0.006546802818775177\n",
      "Epoch 40:  0.005111404694616795\n",
      "Epoch 50:  0.004613327328115702\n",
      "Epoch 60:  0.004308655858039856\n",
      "Epoch 70:  0.0041819061152637005\n",
      "Epoch 80:  0.0041819061152637005\n",
      "Epoch 90:  0.0041819061152637005\n",
      "Epoch 100:  0.0041819061152637005\n",
      "Epoch 110:  0.0041819061152637005\n",
      "Epoch 120:  0.0041819061152637005\n",
      "Epoch 130:  0.0041819061152637005\n",
      "Epoch 140:  0.0041819061152637005\n",
      "Epoch 150:  0.0041819061152637005\n",
      "Epoch 160:  0.0041819061152637005\n",
      "Epoch 170:  0.0041819061152637005\n",
      "Epoch 180:  0.0041819061152637005\n",
      "Epoch 190:  0.0041819061152637005\n",
      "Epoch 200:  0.0041819061152637005\n",
      "Epoch 210:  0.0041819061152637005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b4fadf11a975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001b[0m\u001b[1;32m    426\u001b[0m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[1;32m    427\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# evaluate objective and gradient using initial step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mls_func_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgtd_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mflat_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4fadf11a975>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# No MTL yet, apply the naive summation first to see if it's working?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsup_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msup_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network.train(); selector.train(); best_train_loss = 1e6\n",
    "\n",
    "for i in range(epochs):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Total loss calculation process\n",
    "        # unsupervised_loss\n",
    "        unsup_loss = selector.loss(*network.get_selector_data(*dimension_slicing(X_u_train)))\n",
    "        sup_loss = F.mse_loss(network.uf, u_train)\n",
    "\n",
    "        # No MTL yet, apply the naive summation first to see if it's working?\n",
    "        total_loss = unsup_loss + sup_loss\n",
    "        total_loss.backward()\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    l = closure()\n",
    "    \n",
    "    if (i % 10) == 0:\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0036, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.eval()\n",
    "F.mse_loss(network(*dimension_slicing(X_star)).detach(), u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "X_selector, y_selector = network.get_selector_data(*dimension_slicing(X_u_train))\n",
    "e = shap.DeepExplainer(selector, X_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    }
   ],
   "source": [
    "shap_values = e.shap_values(X_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_abs_shap</th>\n",
       "      <th>stdev_abs_shap</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475227</td>\n",
       "      <td>0.248167</td>\n",
       "      <td>uf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192460</td>\n",
       "      <td>0.440518</td>\n",
       "      <td>u_xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135427</td>\n",
       "      <td>0.257663</td>\n",
       "      <td>u_tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126486</td>\n",
       "      <td>0.325671</td>\n",
       "      <td>u_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.119796</td>\n",
       "      <td>u_xt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055789</td>\n",
       "      <td>0.041418</td>\n",
       "      <td>u_tt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_abs_shap  stdev_abs_shap  name\n",
       "0       0.475227        0.248167    uf\n",
       "2       0.192460        0.440518  u_xx\n",
       "5       0.135427        0.257663  u_tx\n",
       "1       0.126486        0.325671   u_x\n",
       "4       0.096400        0.119796  u_xt\n",
       "3       0.055789        0.041418  u_tt"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"mean_abs_shap\": np.mean(np.abs(shap_values), axis=0), \n",
    "    \"stdev_abs_shap\": np.std(np.abs(shap_values), axis=0), \n",
    "    \"name\": ['uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx']\n",
    "})\n",
    "df.sort_values(\"mean_abs_shap\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x280.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, features=X_selector, feature_names=['uf', 'u_x',  'u_xx', 'u_tt', 'u_xt', 'u_tx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
