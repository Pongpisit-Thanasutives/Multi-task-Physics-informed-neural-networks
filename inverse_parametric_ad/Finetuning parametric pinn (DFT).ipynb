{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Running Python 3.9.8\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys; sys.path.insert(0, \"../\")\n",
    "import sys; sys.path.insert(0, \"../inverse_parametric_burgers/\")\n",
    "\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from models import RobustPCANN\n",
    "from parametric_discovery_pinn import ParametricPINN, FinalParametricPINN\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from robust_pde_diff import print_pde, RobustPCA, Robust_LRSTR, DLrSR\n",
    "from parametric_pde_diff import TrainSGTRidge, create_groups\n",
    "from pytorch_robust_pca import R_pca\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from numpy.fft import fft, ifft, fftfreq\n",
    "from time import time\n",
    "\n",
    "from pysr import pysr, best\n",
    "\n",
    "fontsize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ../parametric_pde_data/parametric_advection_diffusion.pkl\n",
      "Denoising off\n",
      "Clean (x, t)\n",
      "Clean labels\n"
     ]
    }
   ],
   "source": [
    "data = pickle_load(\"../parametric_pde_data/parametric_advection_diffusion.pkl\")\n",
    "\n",
    "x = data['x']; spatial_dims = x.shape[0]\n",
    "t = data['t']; time_dims = t.shape[0]\n",
    "Exact = data['u']\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# Adding noise\n",
    "noise_intensity = 0.01\n",
    "NOISELESS_MODE = True\n",
    "if NOISELESS_MODE: print(\"Denoising off\")\n",
    "else: print(\"Denoising on\")\n",
    "noisy_xt = False; noisy_labels = False; mode = int(noisy_xt)+int(noisy_labels)\n",
    "\n",
    "X_star = np.hstack((to_column_vector(X), to_column_vector(T)))\n",
    "u_star = to_column_vector(Exact.T)\n",
    "\n",
    "# domain bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "# Sampling training data points\n",
    "N = 25000\n",
    "training_idxs = sampling_from_rows(X_star, N, True)\n",
    "X_train = X_star[training_idxs, :]\n",
    "u_train = u_star[training_idxs, :]\n",
    "\n",
    "# Add noise to (x, t) before setting the lb, and ub.\n",
    "if noisy_xt: \n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_train = perturb(X_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "if noisy_labels:\n",
    "    print(\"Noisy labels\")\n",
    "    u_train = perturb(u_train, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean labels\")\n",
    "\n",
    "# to_tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "u_star = to_tensor(u_star, False)\n",
    "X_train = to_tensor(X_train, True)\n",
    "u_train = to_tensor(u_train, False)\n",
    "lb = to_tensor(lb, False)\n",
    "ub = to_tensor(ub, False)\n",
    "\n",
    "L = 5\n",
    "u_true = -2*np.pi/L*np.sin(2*x*np.pi/L)\n",
    "u_x_true = -1.5 + 1.0*np.cos(2*x*np.pi/L)\n",
    "u_xx_true = 0.1*np.ones(spatial_dims)\n",
    "\n",
    "eq_name = \"ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = dimension_slicing(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all: (1.2523253 * sin(-1.2530949*x)) | cos(1.2594514*x)−1.5031303\n",
    "# Noisy1: (1.2536734 * sin(-1.252591*x)) | cos(1.2590762*x)−1.5028094\n",
    "# Noisy2: (1.2010298 * sin(-1.2499514*x)) | cos(1.2681643*x)−1.4841684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model's weights properly\n"
     ]
    }
   ],
   "source": [
    "pinn = ParametricPINN(n_funcs=3, scale=True, lb=lb, ub=ub, eq_name=eq_name)\n",
    "pinn = load_weights(pinn, \"./saved_path_inverse_parametric_ad/parametric_pinn_with_fg.pth\")\n",
    "model = nn.Sequential(pinn.preprocessor_net, pinn.pde_solver_net)\n",
    "\n",
    "pde_terms = [\"u\", \"u_x\", \"u_xx\"]\n",
    "\n",
    "if mode == 0 or mode > 2: func_terms = [\"-1.2523253*sin(1.2530949*x)\", \"cos(1.2594514*x)-1.5031303\", \"0.09376708\"]\n",
    "elif mode == 1: func_terms = [\"-1.2536734*sin(1.2536734*x)\", \"cos(1.2608153*x)-1.5014627\", \"0.09376708\"]\n",
    "elif mode == 2: func_terms = [\"-1.2010298*sin(1.2010298*x)\", \"cos(1.2608153*x)-1.5014627\", \"0.09376708\"]\n",
    "\n",
    "final_ad_pinn = FinalParametricPINN(model=model, pde_terms=pde_terms, \n",
    "                                        func_terms=func_terms, uncert=True, \n",
    "                                        scale=pinn.scale, lb=pinn.lb, ub=pinn.ub, \n",
    "                                        trainable_one=True\n",
    "                                       )\n",
    "del pinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-1.2523), tensor(1.2531)]\n",
      "[tensor(-1.5031), tensor(1.2595)]\n",
      "[tensor(0.0938)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3): print(see_params(final_ad_pinn.pdc.funcs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_fft, x_PSD = fft1d_denoise(X_train[:, 0:1], c=-5, return_real=True)\n",
    "_, t_fft, t_PSD = fft1d_denoise(X_train[:, 1:2], c=-5, return_real=True)\n",
    "_, u_train_fft, u_train_PSD = fft1d_denoise(u_train, c=-5, return_real=True)\n",
    "x_fft, x_PSD = x_fft.detach(), x_PSD.detach()\n",
    "t_fft, t_PSD = t_fft.detach(), t_PSD.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### New implementation ###\n",
    "class RobustFinalParametricPINN(nn.Module):\n",
    "    def __init__(self, pinn, init_cs=(0.1, 0.1), init_betas=(0.0, 0.0), noiseless_mode=True):\n",
    "        super(RobustFinalParametricPINN, self).__init__()\n",
    "        self.pinn = pinn\n",
    "        self.noiseless_mode = noiseless_mode\n",
    "        self.in_fft_nn = None; self.out_fft_nn = None\n",
    "        self.inp_rpca = None; self.out_rpca = None\n",
    "        if not self.noiseless_mode:\n",
    "            # FFTNN\n",
    "            self.in_fft_nn = FFTTh(c=init_cs[0])\n",
    "            self.out_fft_nn = FFTTh(c=init_cs[1])\n",
    "\n",
    "            # Robust Beta-PCA\n",
    "            self.inp_rpca = RobustPCANN(beta=init_betas[0], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "            self.out_rpca = RobustPCANN(beta=init_betas[1], is_beta_trainable=True, inp_dims=1, hidden_dims=32)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.pinn(x, t)\n",
    "\n",
    "    def loss(self, X_input, X_input_noise, y_input, y_input_noise):\n",
    "        if not self.noiseless_mode:\n",
    "            # (1) Denoising FFT on (x, t)\n",
    "            # This line returns the approx. recon.\n",
    "            X_input_noise = cat(torch.fft.ifft(self.in_fft_nn(X_input_noise[1])*X_input_noise[0]).real.reshape(-1, 1), \n",
    "                                torch.fft.ifft(self.in_fft_nn(X_input_noise[3])*X_input_noise[2]).real.reshape(-1, 1))\n",
    "            X_input_noise = X_input-X_input_noise\n",
    "            X_input = self.inp_rpca(X_input, X_input_noise, normalize=True)\n",
    "            \n",
    "            # (2) Denoising FFT on y_input\n",
    "            y_input_noise = y_input-torch.fft.ifft(self.out_fft_nn(y_input_noise[1])*y_input_noise[0]).real.reshape(-1, 1)\n",
    "            y_input = self.out_rpca(y_input, y_input_noise, normalize=True)\n",
    "            \n",
    "        return self.pinn.loss(X_input[:, 0:1], X_input[:, 1:2], y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_ad_pinn = RobustFinalParametricPINN(pinn=final_ad_pinn, noiseless_mode=NOISELESS_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure(return_list=False):\n",
    "    global N, x, t, u_train\n",
    "    losses = robust_ad_pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD))\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in final_ad_pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(final_ad_pinn.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return losses[0]+losses[1]\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_closure():\n",
    "    global N, x, t, u_train\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # the solver network only consider the first N samples.\n",
    "    mse_loss, pde_loss = robust_ad_pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD))\n",
    "    loss = mse_loss + pde_loss\n",
    "    if loss.requires_grad: loss.backward(retain_graph=False)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.6931, grad_fn=<AddBackward0>), tensor(1.0592, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6929, grad_fn=<AddBackward0>), tensor(0.6984, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6916, grad_fn=<AddBackward0>), tensor(0.6939, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6905, grad_fn=<AddBackward0>), tensor(0.6914, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6893, grad_fn=<AddBackward0>), tensor(0.6901, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6881, grad_fn=<AddBackward0>), tensor(0.6887, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6869, grad_fn=<AddBackward0>), tensor(0.6875, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6857, grad_fn=<AddBackward0>), tensor(0.6862, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6845, grad_fn=<AddBackward0>), tensor(0.6850, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6833, grad_fn=<AddBackward0>), tensor(0.6837, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6820, grad_fn=<AddBackward0>), tensor(0.6825, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6808, grad_fn=<AddBackward0>), tensor(0.6812, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6796, grad_fn=<AddBackward0>), tensor(0.6800, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6784, grad_fn=<AddBackward0>), tensor(0.6788, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.6772, grad_fn=<AddBackward0>), tensor(0.6775, grad_fn=<AddBackward0>)]\n",
      "tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = MADGRAD(robust_ad_pinn.parameters(), lr=1e-6, momentum=0.9)\n",
    "for i in range(150):\n",
    "    final_ad_pinn.train()\n",
    "    optimizer.step(pcgrad_closure)\n",
    "    if i%10==0: print(pcgrad_closure(return_list=True))\n",
    "        \n",
    "f_opt = torch.optim.LBFGS(robust_ad_pinn.parameters(), lr=1e-1, max_iter=500, max_eval=int(1.25*500), history_size=300, line_search_fn='strong_wolfe')\n",
    "# final_ad_pinn.is_uncert = False\n",
    "for i in range(11):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    if i%10==0: print(finetuning_closure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-1.2562), tensor(1.2566)]\n",
      "[tensor(-1.4999), tensor(1.2567)]\n",
      "[tensor(0.1000)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3): print(see_params(final_ad_pinn.pdc.funcs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = 2.0*np.pi/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25623655,  1.25656128, -1.49985731,  1.25665808,  0.09997236])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = npar([x.item() for x in final_ad_pinn.pdc.funcs.parameters()])\n",
    "grounds = npar([-cc, cc, -1.5, cc, 0.1])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015345486828358346, 0.012099642990359417)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = 100*(np.abs(preds-grounds)/np.abs(grounds))\n",
    "errs.mean(), errs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New results\n",
    "# w/o DFT\n",
    "# Clean all\n",
    "# array([-1.25623655,  1.25656128, -1.49985731,  1.25665808,  0.09997236])\n",
    "# (0.015345486828358346, 0.012099642990359417)\n",
    "# Noisy1\n",
    "# array([-1.25596786,  1.25678086, -1.49993205,  1.25670695,  0.09998032])\n",
    "# (0.018892862741893963, 0.018004370233254713)\n",
    "# Noisy2\n",
    "# array([-1.25149083,  1.25566435, -1.49853253,  1.25527477,  0.10061844])\n",
    "# (0.26232110489992866, 0.21606809907599014)\n",
    "\n",
    "# w/ DFT\n",
    "# Clean all\n",
    "# array([-1.25622261,  1.25651634, -1.49988151,  1.25663877,  0.09995594])\n",
    "# (0.018936938168554983, 0.01667836126337147)\n",
    "# Noisy1\n",
    "# array([-1.25678468,  1.25660324, -1.49969542,  1.2565794 ,  0.10003757])\n",
    "# (0.015379903264666196, 0.012705832108171925)\n",
    "# Noisy2\n",
    "# array([-1.2556591 ,  1.2577163 , -1.49899721,  1.25608265,  0.10037906])\n",
    "# (0.13074689872742037, 0.12494693424397522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std\n",
    "# (0.04264339677138114, 0.0523326488183105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
