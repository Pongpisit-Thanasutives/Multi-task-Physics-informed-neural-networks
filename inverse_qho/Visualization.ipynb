{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.8\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "# from lightning_utils import *\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, \n",
    "                    ComplexTorchMLP, ComplexSymPyModule, complex_mse)\n",
    "from models import RobustPCANN\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "DATA_PATH = '../PDE_FIND_experimental_datasets/harmonic_osc.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "xlimit = 512\n",
    "tlimit = 161\n",
    "\n",
    "x = data['x'][0][:xlimit]\n",
    "t = data['t'][:,0][:tlimit]\n",
    "\n",
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "potential = np.vstack([0.5*np.power(x,2).reshape((1,spatial_dim)) for _ in range(time_dim)])\n",
    "X, T = np.meshgrid(x, t)\n",
    "Exact = data['usol'][:tlimit, :xlimit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(e): return e.flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy labels\n",
      "Noisy (x, t)\n"
     ]
    }
   ],
   "source": [
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "# Converting in a feature vector for each feature\n",
    "X_star = np.hstack((fn(X), fn(T)))\n",
    "h_star = fn(Exact)\n",
    "potential = fn(potential)\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "N = 20000\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = X_star[idx, :]\n",
    "h_train = h_star[idx, :]\n",
    "u_train = np.real(h_train)\n",
    "v_train = np.imag(h_train)\n",
    "V = potential[idx, :]\n",
    "\n",
    "# adding noise\n",
    "noise_intensity = 0.01/np.sqrt(2)\n",
    "noisy_xt = True; noisy_labels = True\n",
    "if noisy_labels:\n",
    "    u_train = perturb(u_train, noise_intensity)\n",
    "    v_train = perturb(v_train, noise_intensity)\n",
    "    h_train = u_train+1j*v_train\n",
    "    # h_train = \n",
    "    print(\"Noisy labels\")\n",
    "else: print(\"Clean labels\")\n",
    "if noisy_xt:\n",
    "    X_train = perturb2d(X_train, noise_intensity)\n",
    "    print(\"Noisy (x, t)\")\n",
    "else: print(\"Clean X_train\")\n",
    "\n",
    "# Converting to tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "h_star = to_complex_tensor(h_star, False)\n",
    "X_train = to_tensor(X_train, True).to(device)\n",
    "u_train = to_tensor(u_train, False).to(device)\n",
    "v_train = to_tensor(v_train, False).to(device)\n",
    "h_train = torch.tensor(h_train, dtype=torch.cfloat, requires_grad=False).to(device)\n",
    "V = to_tensor(V, False).to(device)\n",
    "\n",
    "feature_names = ['hf', 'h_xx', 'V']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoising using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "noise_x, x_fft, x_PSD = fft1d_denoise(to_tensor(X_train[:, 0:1]), c=-0.05, return_real=True)\n",
    "noise_x = X_train[:, 0:1] - noise_x\n",
    "noise_t, t_fft, t_PSD = fft1d_denoise(to_tensor(X_train[:, 1:2]), c=-0.05, return_real=True)\n",
    "noise_t = X_train[:, 1:2] - noise_t\n",
    "X_train_S = cat(noise_x, noise_t)\n",
    "\n",
    "h_train_S, h_train_fft, h_train_PSD = fft1d_denoise(h_train, c=-0.05, return_real=False)\n",
    "h_train_S = h_train - h_train_S\n",
    "\n",
    "del noise_x, noise_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st stage results\n",
    "# clean all\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.000337 +0.497526i)h_xx\n",
    "#     + (-0.001670 -0.997429i)hf V\n",
    "# 161x512\n",
    "# u_t = (-0.000722 +0.499001)h_xx\n",
    "#     + (-0.002967 -1.000228i)hf V\n",
    "# noisy1\n",
    "# PDE derived using STRidge\n",
    "# u_t = (0.000702 +0.495803i)h_xx\n",
    "#     + (0.000641 -0.994030i)hf V\n",
    "# noisy2\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.001146 +0.487772i)h_xx\n",
    "#     + (-0.001516 -0.989395i)hf V\n",
    "\n",
    "mode = int(noisy_xt)+int(noisy_labels)\n",
    "\n",
    "if mode == 0:\n",
    "    cn1 = (-0.00255341-1.0000252*1j)\n",
    "    cn2 = (-0.0003066+0.4989754*1j)\n",
    "    name = \"cleanall\"\n",
    "elif mode == 1:\n",
    "    cn1 = (-0.01853757-0.931975*1j)\n",
    "    cn2 = (-0.01092263+0.47892907*1j)\n",
    "    name = \"noisy1\"\n",
    "elif mode == 2:\n",
    "    cn1 = (-0.01606621-0.9476085*1j)\n",
    "    cn2 = (-0.04285275+0.48442504*1j)\n",
    "    name = \"noisy2\"\n",
    "    \n",
    "cns = [cn1, cn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X2 {X0, X2}\n",
      "X1 {X1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ComplexSymPyModule(\n",
       "  (sympymodule): SymPyModule(expressions=(X0*X2, X1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X2\"\n",
    "pde_expr1, variables1 = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X1\"\n",
    "pde_expr2, variables2 = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing -1.0*V*hf*(0.01606621 + 0.9476085*I) - 1.0*h_xx*(0.04285275 - 0.48442504*I) {h_xx, V, hf}\n"
     ]
    }
   ],
   "source": [
    "class PDEExpression(nn.Module):\n",
    "    def __init__(self, terms, values, symbolic_module=True):\n",
    "        super(PDEExpression, self).__init__()\n",
    "        self.terms = terms\n",
    "        self.values = [complex(e) for e in values]\n",
    "        self.diff_dict = dict(zip(self.terms, self.values))\n",
    "        self.string_expression = '+'.join([str(v)+'*'+str(k) for k, v in self.diff_dict.items()])\n",
    "        pde_expr, self.variables = build_exp(self.string_expression)\n",
    "        print(\"Constructing\", pde_expr, self.variables)\n",
    "        self.pde_expr = None\n",
    "        if symbolic_module:\n",
    "            self.pde_expr = sympytorch.SymPyModule(expressions=[pde_expr])\n",
    "            \n",
    "    # Computing the approx u_t\n",
    "    def forward(self, e): return self.pde_expr(e)\n",
    "    # Get a coeff\n",
    "    def get_coeff(self, t): return self.diff_dict[t]\n",
    "\n",
    "mod = PDEExpression([\"hf*V\", \"h_xx\"], cns, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, init_cs=(-0.05, -0.05), init_betas=(0.0, 0.0)):\n",
    "        super(ComplexPINN, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        # Setting the parameters up\n",
    "        self.initial_param0 = loss_fn.get_coeff(\"hf*V\")\n",
    "        self.initial_param1 = loss_fn.get_coeff(\"h_xx\")\n",
    "        self.param0_real = nn.Parameter(torch.FloatTensor([self.initial_param0.real]))\n",
    "        self.param0_imag = nn.Parameter(torch.FloatTensor([self.initial_param0.imag]))\n",
    "        self.param1_real = nn.Parameter(torch.FloatTensor([self.initial_param1.real]))\n",
    "        self.param1_imag = nn.Parameter(torch.FloatTensor([self.initial_param1.imag]))\n",
    "        \n",
    "        global N\n",
    "        self.in_fft_nn = FFTTh(c=init_cs[0], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        self.out_fft_nn = FFTTh(c=init_cs[1], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        # Beta-Robust PCA\n",
    "        self.inp_rpca = RobustPCANN(beta=init_betas[0], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        self.out_rpca = RobustPCANN(beta=init_betas[1], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        \n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        \n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None): \n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        \n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        H = torch.cat([x, t], dim=1)\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, X_input, X_input_S, y_input, y_input_S, update_pde_params=True, pure_imag=False, denoise=False):\n",
    "        total_loss = []\n",
    "        \n",
    "        if denoise:\n",
    "            # Denoising FFT on (x, t)\n",
    "            X_input_S = cat(torch.fft.ifft(self.in_fft_nn(X_input_S[1])*X_input_S[0]).real.reshape(-1, 1), \n",
    "                     torch.fft.ifft(self.in_fft_nn(X_input_S[3])*X_input_S[2]).real.reshape(-1, 1))\n",
    "            X_input_S = X_input - X_input_S\n",
    "            X_input = self.inp_rpca(X_input, X_input_S, normalize=True)\n",
    "\n",
    "            # Denoising FFT on y_input\n",
    "            y_input_S = y_input-torch.fft.ifft(self.out_fft_nn(y_input_S[1])*y_input_S[0]).reshape(-1, 1)\n",
    "            y_input = self.out_rpca(cat(y_input.real, y_input.imag), \n",
    "                                    cat(y_input_S.real, y_input_S.imag), \n",
    "                                    normalize=True)\n",
    "            y_input = torch.complex(y_input[:, 0:1], y_input[:, 1:2])\n",
    "        \n",
    "        # Compute losses\n",
    "        grads_dict, u_t = self.grads_dict(X_input[:, 0:1], X_input[:, 1:2])\n",
    "        X0 = cplx2tensor(grads_dict['X0'])\n",
    "        \n",
    "        # MSE Loss\n",
    "        total_loss.append(complex_mse(X0, y_input))\n",
    "            \n",
    "        # PDE Loss\n",
    "        param0 = torch.complex(self.param0_real, self.param0_imag)\n",
    "        param1 = torch.complex(self.param1_real, self.param1_imag)\n",
    "        if not update_pde_params: param0, param1 = param0.detach(), param1.detach()\n",
    "        u_t_pred = (param0*X0*grads_dict['X2'])+(param1*grads_dict['X1'])\n",
    "        total_loss.append(complex_mse(u_t_pred, u_t))\n",
    "        \n",
    "        if pure_imag:\n",
    "            total_loss.append(torch.linalg.norm(param0.real, 1)+torch.linalg.norm(param1.real, 1))\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = {}\n",
    "        derivatives['X0'] = uf\n",
    "        derivatives['X1'] = complex_diff(complex_diff(uf, x), x)\n",
    "        derivatives['X2'] = 0.5*torch.pow(x, 2)\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model's weights properly\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "semisup_model_state_dict = cpu_load(\"./new_saved_path/clean_all_161x512_pretrained_semisup_model.pth\")\n",
    "parameters = OrderedDict()\n",
    "\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = ComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "pinn = load_weights(pinn, \"/Users/pongpisit/Desktop/kuramoto-sivashinsky-solver/qho_weights/noisy2_161x512_dft_pinn (fixed).pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005227134097367525"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_mse(pinn(*dimension_slicing(X_star)).detach(), h_star).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.4844])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn.param0_real.requires_grad_(False)\n",
    "pinn.param0_imag.requires_grad_(False)\n",
    "pinn.param1_real.requires_grad_(False)\n",
    "pinn.param1_imag.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise = True\n",
    "pure_imag = (mode == 0)\n",
    "update_pde_params = True\n",
    "\n",
    "def mtl_closure():\n",
    "    global X_train, h_train, update_pde_params, pure_imag\n",
    "    if torch.is_grad_enabled(): optimizer1.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), \n",
    "                       h_train, (h_train_fft, h_train_PSD), \n",
    "                       update_pde_params=update_pde_params, pure_imag=True, denoise=denoise)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def closure():\n",
    "    global X_train, h_train, update_pde_params, pure_imag\n",
    "    if torch.is_grad_enabled(): optimizer2.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), \n",
    "                      h_train, (h_train_fft, h_train_PSD), \n",
    "                      update_pde_params=update_pde_params, pure_imag=pure_imag, denoise=denoise)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: l.backward(retain_graph=True)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pure_imag: epochs1, epochs2 = 30, 0\n",
    "else: epochs1, epochs2 = 30, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs1, epochs2 = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Phase optimization using Adam with PCGrad gradient modification\n"
     ]
    }
   ],
   "source": [
    "optimizer1 = MADGRAD(pinn.parameters(), lr=1e-7, momentum=0.90)\n",
    "pinn.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    l = mtl_closure()\n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "        p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "        print(p1)\n",
    "        print(p2)\n",
    "        e1 = p1+1j\n",
    "        e2 = p2-0.5j\n",
    "        errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "        print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Phase optimization using LBFGS\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=500, max_eval=int(500*1.25), history_size=300, line_search_fn='strong_wolfe')\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    if (i % 5) == 0 or i == epochs2-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "        p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "        print(p1)\n",
    "        print(p2)\n",
    "        e1 = p1+1j\n",
    "        e2 = p2-0.5j\n",
    "        errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "        print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.style.use('science')\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_norm = torch.sqrt(h_star.real**2 + h_star.imag**2).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_norm = pinn(X_star[:, 0:1], X_star[:, 1:2])\n",
    "pred_norm = torch.sqrt(pred_norm.real**2 + pred_norm.imag**2).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_mse(pinn(X_star[:, 0:1], X_star[:, 1:2]), h_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038328134"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_l2_error(true_norm, pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_norm = true_norm.reshape(X.shape)\n",
    "pred_norm = pred_norm.reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.01606621-0.9476085j), (-0.04285275+0.48442504j)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x189 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "h = ax.imshow(pred_norm.T, interpolation='nearest', cmap='jet', \n",
    "          extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "          origin='lower', aspect='auto')\n",
    "\n",
    "# ax.set_title(\"Learned $||h||_{2}$:\\n$h_t = (-0.000+0.499i)h_{xx}+(-0.003-1.000i)Vh$\\n(V = $0.5x^{2})$\", fontsize = 10)\n",
    "ax.set_title(\"Learned $||h||_{2}$:\\n$h_t = (-0.043+0.484i)h_{xx}+(-0.016-0.948i)Vh$\\n(V = $0.5x^{2})$\", fontsize = 10)\n",
    "# ax.set_title(\"Learned $||h||_{2}$:\\n$h_t = (-0.011+0.479i)h_{xx}+(-0.019-0.932i)Vh$\\n(V = $0.5x^{2})$\", fontsize = 10)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(h, cax=cax)\n",
    "\n",
    "fig.savefig(\"./vis_pics/Learned_Dynamics_noisy2.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00119969-0.99951124j]\n",
      "[2.2208438e-05+0.49888238j]\n",
      "0.17655531381856732 0.04701219112781797\n"
     ]
    }
   ],
   "source": [
    "p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "print(p1)\n",
    "print(p2)\n",
    "e1 = p1+1j\n",
    "e2 = p2-0.5j\n",
    "errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pinn, \"clean_all_161x512_dft_pinn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pde_diff import TrainSTRidge, FiniteDiff, print_pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gd, u_t = pinn.grads_dict(X_train[:, 0:1], X_train[:, 1:2])\n",
    "# uf = cplx2tensor(gd['X0']).detach().numpy()\n",
    "# u_xx = gd['X1'].detach().numpy()\n",
    "# V = gd['X2'].detach().numpy()\n",
    "# diffs = np.hstack((uf*V, u_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = TrainSTRidge(diffs, to_numpy(u_t), 1e-6, d_tol=5)\n",
    "# print(\"PDE derived using STRidge\")\n",
    "# print_pde(w, mod.terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
