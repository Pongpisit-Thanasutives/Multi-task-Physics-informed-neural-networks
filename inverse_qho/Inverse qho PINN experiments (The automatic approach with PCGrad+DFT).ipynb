{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.8\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "# from lightning_utils import *\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, \n",
    "                    ComplexTorchMLP, ComplexSymPyModule, complex_mse)\n",
    "from models import RobustPCANN\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "# from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "DATA_PATH = '../PDE_FIND_experimental_datasets/harmonic_osc.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "xlimit = 512\n",
    "tlimit = 161\n",
    "\n",
    "x = data['x'][0][:xlimit]\n",
    "t = data['t'][:,0][:tlimit]\n",
    "\n",
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "potential = np.vstack([0.5*np.power(x,2).reshape((1,spatial_dim)) for _ in range(time_dim)])\n",
    "X, T = np.meshgrid(x, t)\n",
    "Exact = data['usol'][:tlimit, :xlimit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(e): return e.flatten()[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean labels\n",
      "Clean X_train\n"
     ]
    }
   ],
   "source": [
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "# Converting in a feature vector for each feature\n",
    "X_star = np.hstack((fn(X), fn(T)))\n",
    "h_star = fn(Exact)\n",
    "potential = fn(potential)\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "N = 10000\n",
    "# idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = X_star[idx, :]\n",
    "h_train = h_star[idx, :]\n",
    "u_train = np.real(h_train)\n",
    "v_train = np.imag(h_train)\n",
    "V = potential[idx, :]\n",
    "\n",
    "# adding noise\n",
    "noise_intensity = 0.01/np.sqrt(2)\n",
    "noisy_xt = False; noisy_labels = False\n",
    "if noisy_labels:\n",
    "    u_train = perturb(u_train, noise_intensity)\n",
    "    v_train = perturb(v_train, noise_intensity)\n",
    "    h_train = u_train+1j*v_train\n",
    "    # h_train = \n",
    "    print(\"Noisy labels\")\n",
    "else: print(\"Clean labels\")\n",
    "if noisy_xt:\n",
    "    X_train = perturb2d(X_train, noise_intensity)\n",
    "    print(\"Noisy (x, t)\")\n",
    "else: print(\"Clean X_train\")\n",
    "\n",
    "# Converting to tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "h_star = to_complex_tensor(h_star, False)\n",
    "X_train = to_tensor(X_train, True).to(device)\n",
    "u_train = to_tensor(u_train, False).to(device)\n",
    "v_train = to_tensor(v_train, False).to(device)\n",
    "h_train = torch.tensor(h_train, dtype=torch.cfloat, requires_grad=False).to(device)\n",
    "V = to_tensor(V, False).to(device)\n",
    "\n",
    "feature_names = ['hf', 'h_xx', 'V']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoising using DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../utils.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "noise_x, x_fft, x_PSD = fft1d_denoise(to_tensor(X_train[:, 0:1]), c=-0.05, return_real=True)\n",
    "noise_x = X_train[:, 0:1] - noise_x\n",
    "noise_t, t_fft, t_PSD = fft1d_denoise(to_tensor(X_train[:, 1:2]), c=-0.05, return_real=True)\n",
    "noise_t = X_train[:, 1:2] - noise_t\n",
    "X_train_S = cat(noise_x, noise_t)\n",
    "\n",
    "h_train_S, h_train_fft, h_train_PSD = fft1d_denoise(h_train, c=-0.05, return_real=False)\n",
    "h_train_S = h_train - h_train_S\n",
    "\n",
    "del noise_x, noise_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st stage results\n",
    "# clean all\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.000337 +0.497526i)h_xx\n",
    "#     + (-0.001670 -0.997429i)hf V\n",
    "# 161x512\n",
    "# u_t = (-0.000722 +0.499001)h_xx\n",
    "#     + (-0.002967 -1.000228i)hf V\n",
    "# noisy1\n",
    "# PDE derived using STRidge\n",
    "# u_t = (0.000702 +0.495803i)h_xx\n",
    "#     + (0.000641 -0.994030i)hf V\n",
    "# noisy2\n",
    "# PDE derived using STRidge\n",
    "# u_t = (-0.001146 +0.487772i)h_xx\n",
    "#     + (-0.001516 -0.989395i)hf V\n",
    "\n",
    "mode = int(noisy_xt)+int(noisy_labels)\n",
    "\n",
    "if mode == 0:\n",
    "    cn1 = (-0.002967-1.000228*1j)\n",
    "    cn2 = (-0.000722+0.499001*1j)\n",
    "elif mode == 1:\n",
    "    cn1 = (0.000641-0.994030*1j)\n",
    "    cn2 = (-0.000702+0.495803*1j)\n",
    "elif mode == 2:\n",
    "    cn1 = (0.001516-0.989395*1j)\n",
    "    cn2 = (-0.001146+0.487772*1j)\n",
    "else:\n",
    "    cn1 = (-0.001670-0.997429*1j)\n",
    "    cn2 = (-0.000337+0.497526*1j)\n",
    "    \n",
    "cns = [cn1, cn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X2 {X0, X2}\n",
      "X1 {X1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ComplexSymPyModule(\n",
       "  (sympymodule): SymPyModule(expressions=(X0*X2, X1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X2\"\n",
    "pde_expr1, variables1 = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X1\"\n",
    "pde_expr2, variables2 = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing -1.0*V*hf*(0.002967 + 1.000228*I) - 1.0*h_xx*(0.000722 - 0.499001*I) {h_xx, V, hf}\n"
     ]
    }
   ],
   "source": [
    "class PDEExpression(nn.Module):\n",
    "    def __init__(self, terms, values, symbolic_module=True):\n",
    "        super(PDEExpression, self).__init__()\n",
    "        self.terms = terms\n",
    "        self.values = [complex(e) for e in values]\n",
    "        self.diff_dict = dict(zip(self.terms, self.values))\n",
    "        self.string_expression = '+'.join([str(v)+'*'+str(k) for k, v in self.diff_dict.items()])\n",
    "        pde_expr, self.variables = build_exp(self.string_expression)\n",
    "        print(\"Constructing\", pde_expr, self.variables)\n",
    "        self.pde_expr = None\n",
    "        if symbolic_module:\n",
    "            self.pde_expr = sympytorch.SymPyModule(expressions=[pde_expr])\n",
    "            \n",
    "    # Computing the approx u_t\n",
    "    def forward(self, e): return self.pde_expr(e)\n",
    "    # Get a coeff\n",
    "    def get_coeff(self, t): return self.diff_dict[t]\n",
    "\n",
    "mod = PDEExpression([\"hf*V\", \"h_xx\"], cns, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, init_cs=(-0.05, -0.05), init_betas=(0.0, 0.0)):\n",
    "        super(ComplexPINN, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        # Setting the parameters up\n",
    "        self.initial_param0 = loss_fn.get_coeff(\"hf*V\")\n",
    "        self.initial_param1 = loss_fn.get_coeff(\"h_xx\")\n",
    "        self.param0_real = nn.Parameter(torch.FloatTensor([self.initial_param0.real]))\n",
    "        self.param0_imag = nn.Parameter(torch.FloatTensor([self.initial_param0.imag]))\n",
    "        self.param1_real = nn.Parameter(torch.FloatTensor([self.initial_param1.real]))\n",
    "        self.param1_imag = nn.Parameter(torch.FloatTensor([self.initial_param1.imag]))\n",
    "        \n",
    "        global N\n",
    "        self.in_fft_nn = FFTTh(c=init_cs[0], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        self.out_fft_nn = FFTTh(c=init_cs[1], func=lambda x: (torch.exp(-F.relu(x))))\n",
    "        # Beta-Robust PCA\n",
    "        self.inp_rpca = RobustPCANN(beta=init_betas[0], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        self.out_rpca = RobustPCANN(beta=init_betas[1], is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "        \n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        \n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None): \n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        \n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        H = torch.cat([x, t], dim=1)\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, X_input, X_input_S, y_input, y_input_S, update_pde_params=True, pure_imag=False, denoise=False):\n",
    "        total_loss = []\n",
    "        \n",
    "        if denoise:\n",
    "            # Denoising FFT on (x, t)\n",
    "            X_input_S = cat(torch.fft.ifft(self.in_fft_nn(X_input_S[1])*X_input_S[0]).real.reshape(-1, 1), \n",
    "                     torch.fft.ifft(self.in_fft_nn(X_input_S[3])*X_input_S[2]).real.reshape(-1, 1))\n",
    "            X_input_S = X_input - X_input_S\n",
    "            X_input = self.inp_rpca(X_input, X_input_S, normalize=True)\n",
    "\n",
    "            # Denoising FFT on y_input\n",
    "            y_input_S = y_input-torch.fft.ifft(self.out_fft_nn(y_input_S[1])*y_input_S[0]).reshape(-1, 1)\n",
    "            y_input = self.out_rpca(cat(y_input.real, y_input.imag), \n",
    "                                    cat(y_input_S.real, y_input_S.imag), \n",
    "                                    normalize=True)\n",
    "            y_input = torch.complex(y_input[:, 0:1], y_input[:, 1:2])\n",
    "        \n",
    "        # Compute losses\n",
    "        grads_dict, u_t = self.grads_dict(X_input[:, 0:1], X_input[:, 1:2])\n",
    "        X0 = cplx2tensor(grads_dict['X0'])\n",
    "        \n",
    "        # MSE Loss\n",
    "        total_loss.append(complex_mse(X0, y_input))\n",
    "            \n",
    "        # PDE Loss\n",
    "        param0 = torch.complex(self.param0_real, self.param0_imag)\n",
    "        param1 = torch.complex(self.param1_real, self.param1_imag)\n",
    "        if not update_pde_params: param0, param1 = param0.detach(), param1.detach()\n",
    "        u_t_pred = (param0*X0*grads_dict['X2'])+(param1*grads_dict['X1'])\n",
    "        total_loss.append(complex_mse(u_t_pred, u_t))\n",
    "        \n",
    "        if pure_imag:\n",
    "            total_loss.append(torch.linalg.norm(param0.real, 1)+torch.linalg.norm(param1.real, 1))\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        derivatives = {}\n",
    "        derivatives['X0'] = uf\n",
    "        derivatives['X1'] = complex_diff(complex_diff(uf, x), x)\n",
    "        derivatives['X2'] = 0.5*torch.pow(x, 2)\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model\n",
    "semisup_model_state_dict = cpu_load(\"./new_saved_path/clean_all_161x512_pretrained_semisup_model.pth\")\n",
    "parameters = OrderedDict()\n",
    "\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = ComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, scale=True, lb=lb, ub=ub)\n",
    "# pinn = load_weights(pinn, \"./new_saved_path/clean_all_161x512_no_dft_pinn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise = True\n",
    "pure_imag = (mode == 0)\n",
    "update_pde_params = True\n",
    "\n",
    "def mtl_closure():\n",
    "    global X_train, h_train, update_pde_params, pure_imag\n",
    "    if torch.is_grad_enabled(): optimizer1.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), \n",
    "                       h_train, (h_train_fft, h_train_PSD), \n",
    "                       update_pde_params=update_pde_params, pure_imag=True, denoise=denoise)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def closure():\n",
    "    global X_train, h_train, update_pde_params, pure_imag\n",
    "    if torch.is_grad_enabled(): optimizer2.zero_grad(set_to_none=True)\n",
    "    losses =pinn.loss(X_train, (x_fft, x_PSD, t_fft, t_PSD), \n",
    "                      h_train, (h_train_fft, h_train_PSD), \n",
    "                      update_pde_params=update_pde_params, pure_imag=pure_imag, denoise=denoise)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: l.backward(retain_graph=True)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Phase optimization using Adam with PCGrad gradient modification\n",
      "Epoch 0:  0.0169602632522583\n",
      "[-0.00295638-1.0002297j]\n",
      "[-0.00071134+0.49899942j]\n",
      "0.27103181061860254 0.025497584765724432\n",
      "Epoch 10:  0.06914667040109634\n",
      "[-0.00255341-1.0000252j]\n",
      "[-0.0003066+0.4989754j]\n",
      "0.2346262482134341 0.02072745606440643\n",
      "Epoch 20:  0.03341980278491974\n",
      "[-0.00188362-0.99974066j]\n",
      "[6.0799164e-05+0.4989344j]\n",
      "0.2018039247376666 0.01166505478040955\n",
      "Epoch 29:  0.020169410854578018\n",
      "[-0.00119969-0.99951124j]\n",
      "[2.2208438e-05+0.49888238j]\n",
      "0.17655531381856732 0.04701219112781797\n"
     ]
    }
   ],
   "source": [
    "if pure_imag: epochs1, epochs2 = 30, 0\n",
    "else: epochs1, epochs2 = 30, 20\n",
    "\n",
    "optimizer1 = MADGRAD(pinn.parameters(), lr=1e-7, momentum=0.90)\n",
    "pinn.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    l = mtl_closure()\n",
    "    if (i % 10) == 0 or i == epochs1-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "        p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "        print(p1)\n",
    "        print(p2)\n",
    "        e1 = p1+1j\n",
    "        e2 = p2-0.5j\n",
    "        errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "        print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Phase optimization using LBFGS\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=300, max_eval=int(300*1.25), history_size=300, line_search_fn='strong_wolfe')\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    l = closure()\n",
    "    if (i % 5) == 0 or i == epochs2-1:\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "        p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "        print(p1)\n",
    "        print(p2)\n",
    "        e1 = p1+1j\n",
    "        e2 = p2-0.5j\n",
    "        errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "        print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00119969-0.99951124j]\n",
      "[2.2208438e-05+0.49888238j]\n",
      "0.17655531381856732 0.04701219112781797\n"
     ]
    }
   ],
   "source": [
    "p1 = torch.complex(pinn.param0_real, pinn.param0_imag).detach().numpy()\n",
    "p2 = torch.complex(pinn.param1_real, pinn.param1_imag).detach().numpy()\n",
    "print(p1)\n",
    "print(p2)\n",
    "e1 = p1+1j\n",
    "e2 = p2-0.5j\n",
    "errs = np.abs(npar([100*(np.abs(e1.real)+1j*np.abs(e1.imag))[0], 200*(np.abs(e2.real)+1j*np.abs(e2.imag))[0]]))\n",
    "print(errs.mean(), errs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pinn, \"clean_all_161x512_dft_pinn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pde_diff import TrainSTRidge, FiniteDiff, print_pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gd, u_t = pinn.grads_dict(X_train[:, 0:1], X_train[:, 1:2])\n",
    "# uf = cplx2tensor(gd['X0']).detach().numpy()\n",
    "# u_xx = gd['X1'].detach().numpy()\n",
    "# V = gd['X2'].detach().numpy()\n",
    "# diffs = np.hstack((uf*V, u_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = TrainSTRidge(diffs, to_numpy(u_t), 1e-6, d_tol=5)\n",
    "# print(\"PDE derived using STRidge\")\n",
    "# print_pde(w, mod.terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
