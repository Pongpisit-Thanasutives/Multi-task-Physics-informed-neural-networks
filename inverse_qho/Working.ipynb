{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from models import TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, ComplexTorchMLP, complex_mse\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from robust_pde_diff import print_pde, RobustPCA, Robust_LRSTR\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "# Fancy optimizers\n",
    "from lbfgsnew import LBFGSNew\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n",
      "Training with 4000 unsup samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../utils.py:140: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "DATA_PATH = '../PDE_FIND_experimental_datasets/harmonic_osc.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "\n",
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "potential = np.vstack([0.5*np.power(x,2).reshape((1,spatial_dim)) for _ in range(time_dim)])\n",
    "Exact = data['usol']\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# Adjust the diemnsion of Exact and potential (0.5*x**2)\n",
    "if Exact.T.shape == X.shape: Exact = Exact.T\n",
    "if potential.T.shape == X.shape: potential = potential.T\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "# Converting in a feature vector for each feature\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "h_star = to_column_vector(Exact)\n",
    "u_star = to_column_vector(Exact_u)\n",
    "v_star = to_column_vector(Exact_v)\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "# Converting the grounds to be tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "h_star = to_complex_tensor(h_star, False)\n",
    "\n",
    "N = 2000; include_N_res = 2\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "h_train = torch.complex(u_train, v_train).to(device)\n",
    "\n",
    "# Unsup data\n",
    "if include_N_res>0:\n",
    "    N_res = int(N*include_N_res)\n",
    "    idx_res = np.array(range(X_star.shape[0]-1))[~idx]\n",
    "    idx_res = idx_res[:N_res]\n",
    "    X_res = to_tensor(X_star[idx_res, :], True)\n",
    "    print(f\"Training with {N_res} unsup samples\")\n",
    "    X_train = torch.vstack([X_train, X_res])\n",
    "\n",
    "# Potential is calculated from x\n",
    "# Hence, Quadratic features of x are required.\n",
    "feature_names = ['hf', 'h_x', 'h_xx', 'h_xxx', 'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = (t[1]-t[0])[0]\n",
    "dx = (x[2]-x[1])[0]\n",
    "\n",
    "fd_h_t = np.zeros((time_dim, spatial_dim), dtype=np.complex64)\n",
    "fd_h_x = np.zeros((time_dim, spatial_dim), dtype=np.complex64)\n",
    "fd_h_xx = np.zeros((time_dim, spatial_dim), dtype=np.complex64)\n",
    "fd_h_xxx = np.zeros((time_dim, spatial_dim), dtype=np.complex64)\n",
    "\n",
    "for i in range(spatial_dim):\n",
    "    fd_h_t[:,i] = FiniteDiff(Exact[:,i], dt, 1)\n",
    "for i in range(time_dim):\n",
    "    fd_h_x[i,:] = FiniteDiff(Exact[i,:], dx, 1)\n",
    "    fd_h_xx[i,:] = FiniteDiff(Exact[i,:], dx, 2)\n",
    "    fd_h_xxx[i,:] = FiniteDiff(Exact[i,:], dx, 3)\n",
    "\n",
    "fd_h_t = to_column_vector(fd_h_t)\n",
    "fd_h_x = to_column_vector(fd_h_x)\n",
    "fd_h_xx = to_column_vector(fd_h_xx)\n",
    "fd_h_xxx = to_column_vector(fd_h_xxx)\n",
    "V = to_column_vector(potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = cat_numpy(h_star.detach().numpy(), V, fd_h_x, fd_h_xx, fd_h_xxx)\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is not needed anymore.\n",
    "\n",
    "# c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "# complex_poly_features = c_poly.fit()\n",
    "# complex_poly_features\n",
    "\n",
    "# w = TrainSTRidge(complex_poly_features, fd_h_t, 1e-10, 10)\n",
    "# print(\"PDE derived using STRidge\")\n",
    "# print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_PATH = \"./saved_path_inverse_qho/pretrained_cpinn_2000labeledsamples.pth\"\n",
    "\n",
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )\n",
    "\n",
    "if PRETRAINED_PATH is not None: complex_model.load_state_dict(cpu_load(PRETRAINED_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetwork(nn.Module):\n",
    "    def __init__(self, model, index2features=None, scale=False, lb=None, ub=None):\n",
    "        super(ComplexNetwork, self).__init__()\n",
    "        # pls init the self.model before\n",
    "        self.model = model\n",
    "        # For tracking, the default tup is for the burgers' equation.\n",
    "        self.index2features = index2features\n",
    "        print(\"Considering\", self.index2features)\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uf = None\n",
    "        self.scale = scale\n",
    "        self.lb, self.ub = lb, ub\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if not self.scale: self.uf = self.model(torch.cat([x, t], dim=-1))\n",
    "        else: self.uf = self.model(self.neural_net_scale(torch.cat([x, t], dim=-1)))\n",
    "        return self.uf\n",
    "    \n",
    "    def get_selector_data(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        derivatives = []\n",
    "        ### PDE Loss calculation ###\n",
    "        # Without calling grad\n",
    "        # Appending the estimated solutions\n",
    "        derivatives.append(cplx2tensor(uf))\n",
    "        \n",
    "        # With calling grad\n",
    "        for t in self.diff_flag[1]:\n",
    "            out = uf\n",
    "            for c in t:\n",
    "                if c=='x': out = complex_diff(out, x)\n",
    "                elif c=='t': out = complex_diff(out, t)\n",
    "            derivatives.append(out)\n",
    "            \n",
    "        # Appending the potential function\n",
    "        derivatives.append(0.5*torch.pow(x,2))\n",
    "\n",
    "        return torch.cat(derivatives, dim=-1), u_t\n",
    "    \n",
    "    def neural_net_scale(self, inp):\n",
    "        return -1 + 2*(inp-self.lb)/(self.ub-self.lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexAttentionSelectorNetwork(nn.Module):\n",
    "    def __init__(self, layers, prob_activation=torch.sigmoid, bn=None, reg_intensity=0.1):\n",
    "        super(ComplexAttentionSelectorNetwork, self).__init__()\n",
    "        # Nonlinear model, Training with PDE reg.\n",
    "        assert len(layers) > 1\n",
    "        self.linear1 = CplxLinear(layers[0], layers[0], bias=True)\n",
    "        self.prob_activation = prob_activation\n",
    "        self.nonlinear_model = ComplexTorchMLP(dimensions=layers, activation_function=CplxToCplx[F.relu](), bn=bn, dropout_rate=0.0)\n",
    "        self.latest_weighted_features = None\n",
    "#         self.th = 1/layers[0]\n",
    "        self.th = 0.1\n",
    "        self.reg_intensity = reg_intensity\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, inn):\n",
    "        feature_importances = self.weighted_features(inn)\n",
    "        inn = inn*feature_importances\n",
    "        return self.nonlinear_model(inn)\n",
    "    \n",
    "    def weighted_features(self, inn):\n",
    "        self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n",
    "        self.latest_weighted_features = self.latest_weighted_features.mean(dim=0)\n",
    "        return self.latest_weighted_features\n",
    "    \n",
    "    def loss(self, X_input, y_input):\n",
    "        ut_approx = self.forward(X_input)\n",
    "        mse_loss = complex_mse(ut_approx, y_input)\n",
    "        reg_term = F.relu(self.latest_weighted_features-self.th)\n",
    "        return mse_loss+self.reg_intensity*(torch.norm(reg_term, p=0)+(torch.tensor([1.0, 1.0, 1.0, 2.0, 1.0])*reg_term).sum())\n",
    "\n",
    "# Only the SemiSupModel has changed to work with the finite difference guidance\n",
    "class SemiSupModel(nn.Module):\n",
    "    def __init__(self, network, selector, normalize_derivative_features=False, mini=None, maxi=None, uncert=False):\n",
    "        super(SemiSupModel, self).__init__()\n",
    "        self.network = network\n",
    "        self.selector = selector\n",
    "        self.normalize_derivative_features = normalize_derivative_features\n",
    "        self.mini = mini\n",
    "        self.maxi = maxi\n",
    "        self.weights = None\n",
    "        if uncert: \n",
    "            self.weights = torch.tensor([0.0, 0.0])\n",
    "        \n",
    "    def forward(self, X_h_train, h_train, include_unsup=True):\n",
    "        X_selector, y_selector = self.network.get_selector_data(*dimension_slicing(X_h_train))\n",
    "        \n",
    "        h_row = h_train.shape[0]\n",
    "        fd_guidance = complex_mse(self.network.uf[:h_row, :], h_train)\n",
    "        \n",
    "        # I am not sure a good way to normalize/scale a complex tensor\n",
    "        if self.normalize_derivative_features:\n",
    "            X_selector = (X_selector-self.mini)/(self.maxi-self.mini)\n",
    "        \n",
    "        if include_unsup: unsup_loss = self.selector.loss(X_selector, y_selector)\n",
    "        else: unsup_loss = None\n",
    "            \n",
    "        if include_unsup and self.weights is not None:\n",
    "            return (torch.exp(-self.weights[0])*fd_guidance)+self.weights[0], (torch.exp(-self.weights[1])*unsup_loss)+self.weights[1]\n",
    "        else:\n",
    "            return fd_guidance, unsup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ['hf', 'h_x', 'h_xx', 'h_xxx', 'V']\n"
     ]
    }
   ],
   "source": [
    "lets_pretrain = False\n",
    "\n",
    "semisup_model = SemiSupModel(\n",
    "    network=ComplexNetwork(model=complex_model, index2features=feature_names, scale=True, lb=lb, ub=ub),\n",
    "    selector=ComplexAttentionSelectorNetwork([len(feature_names), 50, 50, 1], prob_activation=F.softmax, bn=True),\n",
    "    normalize_derivative_features=True,\n",
    "    mini=torch.tensor(np.abs(derivatives).min(axis=0), dtype=torch.cfloat), # does not matter, will be replaced\n",
    "    maxi=torch.tensor(np.abs(derivatives).max(axis=0), dtype=torch.cfloat), # does not matter, will be replaced\n",
    "    uncert=False,\n",
    ")\n",
    "\n",
    "# semisup_model.network.load_state_dict(torch.load(\"...\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining the solver network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lets_pretrain:\n",
    "    def pretraining_closure():\n",
    "        global N, X_h_train, h_train\n",
    "        if torch.enable_grad(): pretraining_optimizer.zero_grad()\n",
    "        # Only focusing on first [:N, :] elements\n",
    "        mse_loss = complex_mse(semisup_model.network(*dimension_slicing(X_train[:N, :])), h_train[:N, :])\n",
    "        if mse_loss.requires_grad: mse_loss.backward(retain_graph=False)\n",
    "        return mse_loss\n",
    "    \n",
    "    print(\"Pretraining\")\n",
    "    pretraining_optimizer = LBFGSNew(semisup_model.network.parameters(),\n",
    "                                     lr=1e-1, max_iter=300,\n",
    "                                     max_eval=int(300*1.25), history_size=150,\n",
    "                                     line_search_fn=True, batch_mode=False)\n",
    "\n",
    "    semisup_model.network.train()    \n",
    "    for i in range(120):\n",
    "        pretraining_optimizer.step(pretraining_closure)\n",
    "            \n",
    "        if (i%10)==0:\n",
    "            l = pretraining_closure()\n",
    "            curr_loss = l.item()\n",
    "            print(\"Epoch {}: \".format(i), curr_loss)\n",
    "\n",
    "            # See how well the model perform on the test set\n",
    "            semisup_model.network.eval()\n",
    "            test_performance = complex_mse(semisup_model.network(*dimension_slicing(X_star)).detach(), h_star).item()\n",
    "            string_test_performance = scientific2string(test_performance)\n",
    "            print('Test MSE:', string_test_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 25000\n",
    "test_idx = np.random.choice(X_star.shape[0], n_test, replace=False)\n",
    "referenced_derivatives, h_t = semisup_model.network.get_selector_data(*dimension_slicing(X_star[test_idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing h_x\n",
      "Computing h_xx\n",
      "Computing h_xxx\n",
      "Computing V\n",
      "Computing hf^2\n",
      "Computing hf h_x\n",
      "Computing hf h_xx\n",
      "Computing hf h_xxx\n",
      "Computing hf V\n",
      "Computing h_x^2\n",
      "Computing h_x h_xx\n",
      "Computing h_x h_xxx\n",
      "Computing h_x V\n",
      "Computing h_xx^2\n",
      "Computing h_xx h_xxx\n",
      "Computing h_xx V\n",
      "Computing h_xxx^2\n",
      "Computing h_xxx V\n",
      "Computing V^2\n",
      "PDE derived using STRidge\n",
      "u_t = (-0.000084 +0.494702i)h_xx\n",
      "    + (0.001434 -0.994890i)hf V\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "derivatives = referenced_derivatives.detach().numpy()\n",
    "\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "\n",
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, d_tol=1000, maxit=1000, l0_penalty=5, normalize=1)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure(return_list=False):\n",
    "    global N, X_train, h_train\n",
    "    fd_guidance, unsup_loss = semisup_model(X_train, h_train, include_unsup=True)\n",
    "    losses = [fd_guidance, unsup_loss]\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in semisup_model.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(semisup_model.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return sum(losses)\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-61ef6e2e66cc>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0003, grad_fn=<AddBackward0>), tensor(1.4120, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0016, grad_fn=<AddBackward0>), tensor(0.7315, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0032, grad_fn=<AddBackward0>), tensor(0.4353, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0025, grad_fn=<AddBackward0>), tensor(0.4947, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0017, grad_fn=<AddBackward0>), tensor(0.5749, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0012, grad_fn=<AddBackward0>), tensor(0.5057, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0012, grad_fn=<AddBackward0>), tensor(0.5784, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0011, grad_fn=<AddBackward0>), tensor(0.3636, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0009, grad_fn=<AddBackward0>), tensor(0.4600, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0009, grad_fn=<AddBackward0>), tensor(0.3899, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0010, grad_fn=<AddBackward0>), tensor(0.4627, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0009, grad_fn=<AddBackward0>), tensor(0.5591, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0008, grad_fn=<AddBackward0>), tensor(0.5558, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0007, grad_fn=<AddBackward0>), tensor(0.3543, grad_fn=<AddBackward0>)]\n",
      "[tensor(0.0007, grad_fn=<AddBackward0>), tensor(0.3789, grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# Joint training\n",
    "optimizer = MADGRAD([{'params':semisup_model.network.parameters()}, {'params':semisup_model.selector.parameters()}], lr=1e-6)\n",
    "optimizer.param_groups[0]['lr'] = 1e-11\n",
    "optimizer.param_groups[1]['lr'] = 1e-1\n",
    "\n",
    "# TODO: also need the adversarial examples as well (Use ~idx to sample)\n",
    "for i in range(150):\n",
    "    semisup_model.train()\n",
    "    optimizer.step(pcgrad_closure)\n",
    "    loss = pcgrad_closure(return_list=True)\n",
    "    if i%10==0: print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Joint training\n",
    "# optimizer = MADGRAD([{'params':semisup_model.network.parameters()}, {'params':semisup_model.selector.parameters()}], lr=1e-6)\n",
    "# optimizer.param_groups[0]['lr'] = 1e-11\n",
    "# optimizer.param_groups[1]['lr'] = 1e-1\n",
    "\n",
    "# # TODO: also need the adversarial examples as well (Use ~idx to sample)\n",
    "# for i in range(50):\n",
    "#     semisup_model.train()\n",
    "#     optimizer.step(pcgrad_closure)\n",
    "#     loss = pcgrad_closure(return_list=True)\n",
    "#     if i%10==0: print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning both the solver and selector network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A cell for saving and loading\n",
    "# torch.save(semisup_model.state_dict(), \"saved_path_inverse_qho/qho_complex_model_2000labeledsamples_jointtrainwith4000unlabeledsamples.pth\")\n",
    "semisup_model.load_state_dict(torch.load(\"saved_path_inverse_qho/qho_complex_model_2000labeledsamples_jointtrainwith4000unlabeledsamples.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5619996702298522e-05\n",
      "6.379249498422723e-06\n",
      "6.33568970442866e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n",
      "6.3344527916342486e-06\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning the solver network\n",
    "f_opt = torch.optim.LBFGS(semisup_model.network.parameters(), lr=1e-1, max_iter=300, history_size=300)\n",
    "# f_opt = LBFGSNew(semisup_model.network.parameters(),\n",
    "#         lr=1e-1, max_iter=300,\n",
    "#         max_eval=int(300*1.25), history_size=150,\n",
    "#         line_search_fn=True, batch_mode=False)\n",
    "\n",
    "def finetuning_closure():\n",
    "    global N, X_train, h_train\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # the solver network only consider the first N samples.\n",
    "    loss = complex_mse(semisup_model.network(*dimension_slicing(X_train[:N, :])), h_train)\n",
    "    if loss.requires_grad: loss.backward(retain_graph=True)\n",
    "    return loss\n",
    "\n",
    "semisup_model.network.train()\n",
    "semisup_model.selector.eval()\n",
    "\n",
    "for i in range(200):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    if i%10==0:\n",
    "        loss = finetuning_closure()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selector, y_selector = semisup_model.network.get_selector_data(*dimension_slicing(X_train))\n",
    "# X_selector = (X_selector - semisup_model.mini)/(semisup_model.maxi-semisup_model.mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-dedd9bdd523e>:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.latest_weighted_features = self.prob_activation(cplx2tensor(self.linear1(inn)).abs())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008191938977688551\n",
      "[3 1 2 4 0]\n",
      "0.0002734411973506212\n",
      "[3 1 2 4 0]\n",
      "0.00021122515317983925\n",
      "[3 1 2 4 0]\n"
     ]
    }
   ],
   "source": [
    "f_opt = torch.optim.LBFGS(semisup_model.selector.parameters(), lr=1e-1, max_iter=200, history_size=300)\n",
    "\n",
    "def finetuning_closure():\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # Am I forget to normalize the derivative features?, NVM\n",
    "    loss = complex_mse(semisup_model.selector(X_selector), y_selector)\n",
    "    if loss.requires_grad: loss.backward(retain_graph=True)\n",
    "    return loss\n",
    "\n",
    "semisup_model.network.eval()\n",
    "semisup_model.selector.train()\n",
    "\n",
    "max_it = 10\n",
    "for i in range(max_it):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    \n",
    "    if i%5==0 or i==max_it-1:\n",
    "        loss = finetuning_closure()\n",
    "        print(loss.item())\n",
    "        print(np.argsort(semisup_model.selector.latest_weighted_features.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature importance ranking ---\n",
      "hf 0.56193215\n",
      "V 0.21649641\n",
      "h_xx 0.102043524\n",
      "h_x 0.10136571\n",
      "h_xxx 0.01816225\n"
     ]
    }
   ],
   "source": [
    "feature_importance = semisup_model.selector.latest_weighted_features.detach().numpy()\n",
    "print(\"--- Feature importance ranking ---\")\n",
    "for idx in np.argsort(feature_importance)[::-1]:\n",
    "    print(feature_names[idx], feature_importance[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_feature_importance_neural_net(feature_importances, feature_names, threshold=0.2, save_path=None):\n",
    "    # split it up\n",
    "    above_threshold = np.maximum(feature_importance - threshold, 0)\n",
    "    below_threshold = np.minimum(feature_importance, threshold)\n",
    "\n",
    "    # and plot it\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(feature_names, below_threshold, 0.35, color=\"g\")\n",
    "    ax.bar(feature_names, above_threshold, 0.35, color=\"r\",\n",
    "            bottom=below_threshold)\n",
    "    # horizontal line indicating the threshold\n",
    "    ax.plot([0., 4.5], [threshold, threshold], \"k--\")\n",
    "    plt.xlabel(\"Partial derivative features (possible candidates)\")\n",
    "    plt.ylabel(\"Softmax layer's outputs as feature importances\")\n",
    "    \n",
    "    if save_path is not None: fig.savefig(save_path, dpi=200)\n",
    "\n",
    "plot_feature_importance_neural_net(feature_importance, feature_names,threshold=0.1, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(semisup_model.state_dict(), \"saved_path_inverse_qho/qho_complex_model_2000labeledsamples_jointtrainwith4000unlabeledsamplesV3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./tmp_files/X_train_2000labeledsamplesV3\", X_train.detach().numpy())\n",
    "np.save(\"./tmp_files/h_train_2000labeledsamplesV3\", h_train.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SHAP to compute neural network's feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Using 4000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e7d12001d64286b845db1ab8844129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fn(inp):\n",
    "    global semisup_model\n",
    "    out = semisup_model.selector(torch.tensor(inp, dtype=torch.cfloat))\n",
    "    return torch.hstack([out.real, out.imag]).detach().numpy()\n",
    "    \n",
    "explainer = shap.KernelExplainer(model=fn, data=X_selector.detach().numpy(), link=\"identity\")\n",
    "shap_values = explainer.shap_values(X=X_selector.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, feature_names=feature_names, class_names=['Real', 'Imaginary'], show=False)\n",
    "plt.savefig(\"../visualization/qho_shap_feature_importances_selector_with_softmax.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
