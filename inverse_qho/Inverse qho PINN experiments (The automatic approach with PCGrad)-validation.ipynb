{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from complexPyTorch.complexLayers import ComplexLinear\n",
    "\n",
    "import cplxmodule\n",
    "from cplxmodule import cplx\n",
    "from cplxmodule.nn import RealToCplx, CplxToReal, CplxSequential, CplxToCplx\n",
    "from cplxmodule.nn import CplxLinear, CplxModReLU, CplxAdaptiveModReLU, CplxModulus, CplxAngle\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from lightning_utils import *\n",
    "from utils import *\n",
    "from models import (TorchComplexMLP, ImaginaryDimensionAdder, cplx2tensor, \n",
    "                    ComplexTorchMLP, ComplexSymPyModule, complex_mse)\n",
    "from models import UncertaintyWeightedLoss\n",
    "from preprocess import *\n",
    "\n",
    "# Model selection\n",
    "from sparsereg.model import STRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pde_diff import TrainSTRidge, FiniteDiff, print_pde\n",
    "from robust_pde_diff import Robust_LRSTR, RobustPCA\n",
    "from RegscorePy.bic import bic\n",
    "\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../utils.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(arr).float().requires_grad_(g)\n"
     ]
    }
   ],
   "source": [
    "# torch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You're running on\", device)\n",
    "\n",
    "DATA_PATH = '../PDE_FIND_experimental_datasets/harmonic_osc.mat'\n",
    "data = io.loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "\n",
    "spatial_dim = x.shape[0]\n",
    "time_dim = t.shape[0]\n",
    "\n",
    "potential = np.vstack([0.5*np.power(x,2).reshape((1, spatial_dim)) for _ in range(time_dim)])\n",
    "Exact = data['usol']\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# Adjust the diemnsion of Exact and potential (0.5*x**2)\n",
    "if Exact.T.shape == X.shape: Exact = Exact.T\n",
    "if potential.T.shape == X.shape: potential = potential.T\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "# Converting in a feature vector for each feature\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "h_star = to_column_vector(Exact)\n",
    "u_star = to_column_vector(Exact_u)\n",
    "v_star = to_column_vector(Exact_v)\n",
    "potential = to_column_vector(potential)\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "# Converting the grounds to be tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "h_star = to_complex_tensor(h_star, False)\n",
    "\n",
    "N = 2000; include_N_res = 2\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "# idx = np.arange(N) # Just have an easy dataset for experimenting\n",
    "\n",
    "lb = to_tensor(lb, False).to(device)\n",
    "ub = to_tensor(ub, False).to(device)\n",
    "\n",
    "X_train = to_tensor(X_star[idx, :], True).to(device)\n",
    "u_train = to_tensor(u_star[idx, :], False).to(device)\n",
    "v_train = to_tensor(v_star[idx, :], False).to(device)\n",
    "h_train = torch.complex(u_train, v_train).to(device)\n",
    "potential = to_tensor(potential[idx, :], False).to(device)\n",
    "\n",
    "# X_train = to_tensor(np.load(\"./tmp_files/X_train_2000labeledsamplesV3.npy\")[:N, :], True).to(device)\n",
    "# h_train = to_complex_tensor(np.load(\"./tmp_files/h_train_2000labeledsamplesV3.npy\"), False).to(device)\n",
    "\n",
    "# Unsup data -> We do not need this here.\n",
    "# Potential is calculated from x\n",
    "# Hence, Quadratic features of x are required.\n",
    "feature_names = ['hf', 'h_xx', 'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial coeffs\n",
    "# u_t = (-0.000084 +0.494702i)h_xx\n",
    "#     + (0.001434 -0.994890i)hf V\n",
    "\n",
    "cn1 = (-0.000084-0.994890*1j)\n",
    "cn2 = (0.001434+0.494702*1j)\n",
    "cns = [cn1, cn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0*X2 {X2, X0}\n",
      "X1 {X1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ComplexSymPyModule(\n",
       "  (sympymodule): SymPyModule(expressions=(X0*X2, X1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type the equation got from the symbolic regression step\n",
    "# No need to save the eq save a pickle file before\n",
    "program1 = \"X0*X2\"\n",
    "pde_expr1, variables1,  = build_exp(program1); print(pde_expr1, variables1)\n",
    "\n",
    "program2 = \"X1\"\n",
    "pde_expr2, variables2,  = build_exp(program2); print(pde_expr2, variables2)\n",
    "\n",
    "mod = ComplexSymPyModule(expressions=[pde_expr1, pde_expr2], complex_coeffs=cns, learnable_parts=[True, True]); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, uncert=False):\n",
    "        super(ComplexPINN, self).__init__()\n",
    "        self.model = model\n",
    "        self.callable_loss_fn = loss_fn\n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        if self.scale and (self.lb is None or self.ub is None): \n",
    "            print(\"Please provide thw lower and upper bounds of your PDE.\")\n",
    "            print(\"Otherwise, there will be error(s)\")\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        self.uncert = None\n",
    "        if uncert: self.uncert = UncertaintyWeightedLoss(2)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        H = torch.cat([x, t], dim=1)\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, x, t, potential, y_input, update_network_params=True, update_pde_params=True):\n",
    "        total_loss = []\n",
    "        grads_dict, u_t = self.grads_dict(x, t, potential)\n",
    "        # MSE Loss\n",
    "        if update_network_params:\n",
    "            total_loss.append(complex_mse(grads_dict['X0'], y_input))\n",
    "        # PDE Loss\n",
    "        if update_pde_params:\n",
    "            total_loss.append(complex_mse(self.callable_loss_fn(grads_dict), u_t))\n",
    "            \n",
    "        if self.uncert is not None: return self.uncert(*total_loss)\n",
    "        else: return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t, potential):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = complex_diff(uf, t)\n",
    "        \n",
    "        ### PDE Loss calculation ###\n",
    "        derivatives = {}\n",
    "        derivatives['X0'] = cplx2tensor(uf)\n",
    "        derivatives['X1'] = complex_diff(complex_diff(uf, x), x)\n",
    "        derivatives['X2'] = potential\n",
    "        \n",
    "        return derivatives, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "    \n",
    "    # Must ensure that the implementation of neural_net_scale is consistent\n",
    "    # and hopefully correct\n",
    "    # also, you might not need this function in some datasets\n",
    "    def neural_net_scale(self, inp): \n",
    "        return 2*(inp-self.lb)/(self.ub-self.lb)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:587: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "inp_dimension = 2\n",
    "act = CplxToCplx[torch.tanh]\n",
    "complex_model = CplxSequential(\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 100, bias=True),\n",
    "                            act(),\n",
    "                            CplxLinear(100, 1, bias=True),\n",
    "                            )\n",
    "\n",
    "complex_model = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(inp_dimension, 200),\n",
    "                                    RealToCplx(),\n",
    "                                    complex_model\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model's weights properly\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "semisup_model_state_dict = cpu_load(\"./saved_path_inverse_qho/qho_complex_model_2000labeledsamples_jointtrainwith4000unlabeledsamplesV3.pth\")\n",
    "parameters = OrderedDict()\n",
    "\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "complex_model.load_state_dict(parameters)\n",
    "\n",
    "pinn = ComplexPINN(model=complex_model, loss_fn=mod, index2features=feature_names, scale=True, lb=lb, ub=ub, uncert=False)\n",
    "pinn = load_weights(pinn, \"tmp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global X_train, h_train, potential\n",
    "    if torch.is_grad_enabled(): optimizer2.zero_grad(set_to_none=True)\n",
    "    losses = pinn.loss(X_train[:, 0:1], X_train[:, 1:2], potential, h_train, update_network_params=True, update_pde_params=True)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad: l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def mtl_closure():\n",
    "    global X_train, h_train, potential\n",
    "    n_obj = 2 # There are two tasks\n",
    "    losses = pinn.loss(X_train[:, 0:1], X_train[:, 1:2], potential, h_train, update_network_params=True, update_pde_params=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(n_obj):\n",
    "        optimizer1.zero_grad(set_to_none=True)\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(pinn.parameters()): \n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0083-0.9968j],\n",
       "        [ 0.0088+0.4921j]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1, p2 = see_params(pinn.callable_loss_fn)\n",
    "torch.complex(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6599999999999995, 0.3400000000000014)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = abs(np.array([100j*(1-0.9968), 100j*(0.5-0.4950)/0.5]))\n",
    "np.mean(errs), np.std(errs) # 2.05 +- 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = X_star.shape[0]\n",
    "n_test = spatial_dim*np.ceil(n_test/spatial_dim)\n",
    "test_idx = np.arange(n_test)\n",
    "# test_idx = np.random.choice(X_star.shape[0], n_test, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, tt = dimension_slicing(X_star[test_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd, h_t = pinn.grads_dict(xx, tt, 0.5*(xx**2)[test_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_derivatives = cat(*list(gd.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing h_xx\n",
      "Computing V\n",
      "Computing hf^2\n",
      "Computing hf h_xx\n",
      "Computing hf V\n",
      "Computing h_xx^2\n",
      "Computing h_xx V\n",
      "Computing V^2\n"
     ]
    }
   ],
   "source": [
    "derivatives = referenced_derivatives.detach().numpy()\n",
    "\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ensure that the shape of U is correct.\n",
      "iteration:1, err:25034.412222887466, nc_norm:894.0360098638092 eta1:0.007047486302441743\n",
      "iteration:50, err:101.77410269173963, nc_norm:1292.7806066028145 eta1:0.7521003888196454\n",
      "iteration:100, err:0.8916539777836258, nc_norm:689.4859967031524 eta1:88.28970609468897\n",
      "iteration:150, err:0.003867425433608397, nc_norm:684.3352549807297 eta1:10364.403898953218\n",
      "iteration:200, err:2.0426641840410834e-05, nc_norm:684.2898544829554 eta1:1216686.213287763\n",
      "iteration:207, err:9.907857375522878e-06, nc_norm:684.289663161962 eta1:2370977.2291681124\n"
     ]
    }
   ],
   "source": [
    "pred_Exact = referenced_derivatives[:, 0:1].reshape((int(spatial_dim), int(n_test//spatial_dim))).detach()\n",
    "Z, E1 = RobustPCA(pred_Exact, lam_2=0.001)\n",
    "complex_poly_features[:, 0:1] = to_column_vector(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1, err:5435.652231767041, nc_norm:2583.8183532097005 eta2:0.004379923816486254\n",
      "u_t = \n",
      "u_t = (0.002150 +0.496235i)h_xx\n",
      "    + (0.000024 -0.998133i)hf V\n",
      "   \n",
      "u_t = (0.002135 +0.497022i)h_xx\n",
      "    + (-0.000010 -0.999669i)hf V\n",
      "   \n",
      "u_t = (0.002126 +0.496620i)h_xx\n",
      "    + (-0.000023 -0.998932i)hf V\n",
      "   \n",
      "u_t = (0.002124 +0.496557i)h_xx\n",
      "    + (-0.000028 -0.998915i)hf V\n",
      "   \n",
      "u_t = (0.002124 +0.496505i)h_xx\n",
      "    + (-0.000030 -0.998911i)hf V\n",
      "   \n",
      "u_t = (0.002125 +0.496469i)h_xx\n",
      "    + (-0.000031 -0.998911i)hf V\n",
      "   \n",
      "u_t = (0.002125 +0.496446i)h_xx\n",
      "    + (-0.000031 -0.998912i)hf V\n",
      "   \n",
      "u_t = (0.002126 +0.496433i)h_xx\n",
      "    + (-0.000032 -0.998913i)hf V\n",
      "   \n",
      "u_t = (0.002126 +0.496425i)h_xx\n",
      "    + (-0.000033 -0.998914i)hf V\n",
      "   \n",
      "u_t = (0.002126 +0.496420i)h_xx\n",
      "    + (-0.000033 -0.998915i)hf V\n",
      "   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8de9fb951556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mUt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspatial_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobust_LRSTR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_poly_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoly_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../robust_pde_diff.py\u001b[0m in \u001b[0;36mRobust_LRSTR\u001b[0;34m(R, Ut, rhs_des, lam_1, lam_3, lam_4, d_tol)\u001b[0m\n\u001b[1;32m    699\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcasvd_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlam_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m            \u001b[0mvectorX\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m            \u001b[0mx\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mTrainSTRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_tol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m            \u001b[0mRxmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m            \u001b[0mprint_pde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_des\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../robust_pde_diff.py\u001b[0m in \u001b[0;36mTrainSTRidge\u001b[0;34m(R, Ut, lam, d_tol, maxit, STR_iters, l0_penalty, normalize, split, print_best_tol)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m     \u001b[0mTrainR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0mTestR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Multi-task-Physics-informed-neural-networks/inverse_qho/../robust_pde_diff.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m     \u001b[0mTrainR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0mTestR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ut1 = np.reshape(to_numpy(h_t), (int(spatial_dim), int(n_test//spatial_dim)))\n",
    "w, X, E2 = Robust_LRSTR(complex_poly_features, Ut1, c_poly.poly_feature_names, lam_1=1e-5, lam_3=0.3, lam_4=1e-4, d_tol=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hf\n",
      "Computing h_xx\n",
      "Computing V\n",
      "Computing hf^2\n",
      "Computing hf h_xx\n",
      "Computing hf V\n",
      "Computing h_xx^2\n",
      "Computing h_xx V\n",
      "Computing V^2\n",
      "PDE derived using STRidge\n",
      "u_t = (0.002135 +0.496425i)h_xx\n",
      "    + (0.000018 -0.998858i)hf V\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "derivatives = referenced_derivatives.detach().numpy()\n",
    "\n",
    "dictionary = {}\n",
    "for i in range(len(feature_names)): dictionary[feature_names[i]] = get_feature(derivatives, i)\n",
    "\n",
    "c_poly = ComplexPolynomialFeatures(feature_names, dictionary)\n",
    "complex_poly_features = c_poly.fit()\n",
    "\n",
    "w = TrainSTRidge(complex_poly_features, to_numpy(h_t), 1e-10, d_tol=1000, maxit=1000, l0_penalty=5, normalize=1)\n",
    "print(\"PDE derived using STRidge\")\n",
    "print_pde(w, c_poly.poly_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_t = (0.002135 +0.497022i)h_xx\n",
    "#     + (-0.000010 -0.999669i)hf V\n",
    "\n",
    "# u_t = (0.002135 +0.497022i)h_xx\n",
    "#     + (-0.000010 -0.999669i)hf V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9868, 0.4911\n",
    "# 1.0230, 0.4948\n",
    "# 0.9968, 0.4950\n",
    "# 0.9989, 0.4970\n",
    "# 0.9997, 0.4971 # use this..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
