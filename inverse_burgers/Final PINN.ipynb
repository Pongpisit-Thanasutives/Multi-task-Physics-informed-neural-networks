{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python 3.9.7\n",
      "You can use npar for np.array\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# always import gbm_algos first !\n",
    "import xgboost, lightgbm, catboost\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "# To access the contents of the parent dir\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "from preprocess import *\n",
    "from models import RobustPCANN\n",
    "\n",
    "# Let's do facy optimizers\n",
    "from optimizers import Lookahead, AdamGC, SGDGC\n",
    "from madgrad import MADGRAD\n",
    "from lbfgsnew import LBFGSNew\n",
    "\n",
    "from pytorch_robust_pca import *\n",
    "\n",
    "# Modify at /usr/local/lib/python3.9/site-packages/torch_lr_finder/lr_finder.py\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "# Tracking\n",
    "from tqdm import trange\n",
    "\n",
    "# Symbolics\n",
    "import sympy\n",
    "import sympytorch\n",
    "\n",
    "# BayesianOptimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import Optimizer\n",
    "\n",
    "# hyperopt\n",
    "from hyperopt import hp, fmin, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Exact\n",
      "Clean (x, t)\n",
      "Training with 1000 samples\n",
      "โหลดทับ\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../experimental_data/burgers_shock.mat\"\n",
    "data = loadmat(DATA_PATH)\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "# Adding noise\n",
    "noise_intensity = 0.0\n",
    "noisy_xt = False\n",
    "sub = True\n",
    "\n",
    "if noise_intensity>0.0:\n",
    "    Exact = perturb(Exact, intensity=noise_intensity, noise_type=\"normal\")\n",
    "    print(\"Perturbed Exact with intensity =\", float(noise_intensity))\n",
    "else: print(\"Clean Exact\")\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]\n",
    "\n",
    "if noisy_xt and noise_intensity>0.0:\n",
    "    print(\"Noisy (x, t)\")\n",
    "    X_star = perturb(X_star, intensity=noise_intensity, noise_type=\"normal\")\n",
    "else: print(\"Clean (x, t)\")\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "N = 1000\n",
    "print(f\"Training with {N} samples\")\n",
    "idx = np.random.choice(X_star.shape[0], N, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "if sub:\n",
    "    print(\"โหลดทับ\")\n",
    "    X_u_train = np.load(\"./data_files/X_u_train_1000labeledsamples.npy\")[:N, :]\n",
    "    u_train = np.load(\"./data_files/u_train_1000labeledsamples.npy\")\n",
    "\n",
    "# Convert to torch.tensor\n",
    "X_u_train = to_tensor(X_u_train, True)\n",
    "u_train = to_tensor(u_train, False)\n",
    "\n",
    "scaling_factor = 1.0\n",
    "lb = scaling_factor*to_tensor(lb, False)\n",
    "ub = scaling_factor*to_tensor(ub, False)\n",
    "\n",
    "# Feature names, base on the symbolic regression results\n",
    "feature_names = ('uf', 'u_x', 'u_xx'); feature2index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.860374*u_x*uf + 0.002631*u_xx {uf, u_xx, u_x}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymPyModule(expressions=(-0.860374*u_x*uf + 0.002631*u_xx,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if u_train.shape[0] == 2000:\n",
    "    ### Noiseless 2000 labeled samples program ###\n",
    "    program = '''\n",
    "    -0.970158*uf*u_x+0.003090*u_xx\n",
    "    '''\n",
    "elif u_train.shape[0] == 1000:\n",
    "    ### Noiseless 1000 labeled samples program ###\n",
    "    program = '''\n",
    "    -0.860374*uf*u_x+0.002631*u_xx\n",
    "    '''\n",
    "else: program = None\n",
    "\n",
    "pde_expr, variables = build_exp(program); print(pde_expr, variables)\n",
    "mod = sympytorch.SymPyModule(expressions=[pde_expr]); mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor(0.0026, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor(-0.8604, requires_grad=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mod.parameters())[0], list(mod.parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustPINN(nn.Module):\n",
    "    def __init__(self, model, loss_fn, index2features, scale=False, lb=None, ub=None, pretrained=False, noiseless_mode=True, init_cs=(0.5, 0.5), init_betas=(0.0, 0.0)):\n",
    "        super(RobustPINN, self).__init__()\n",
    "        self.model = model\n",
    "        if not pretrained: self.model.apply(self.xavier_init)\n",
    "        \n",
    "        self.noiseless_mode = noiseless_mode\n",
    "        self.in_fft_nn = None; self.out_fft_nn = None\n",
    "        self.inp_rpca = None; self.out_rpca = None\n",
    "        if not self.noiseless_mode:\n",
    "            # FFTNN\n",
    "            self.in_fft_nn = FFTTh(c=init_cs[0])\n",
    "            self.out_fft_nn = FFTTh(c=init_cs[1])\n",
    "\n",
    "            # Robust Beta-PCA\n",
    "            self.inp_rpca = RobustPCANN(beta=0.0, is_beta_trainable=True, inp_dims=2, hidden_dims=32)\n",
    "            self.out_rpca = RobustPCANN(beta=0.0, is_beta_trainable=True, inp_dims=1, hidden_dims=32)\n",
    "        \n",
    "        self.p0 = torch.log(list(loss_fn.parameters())[0])\n",
    "        self.p1 = list(loss_fn.parameters())[1]\n",
    "        \n",
    "        self.index2features = index2features; self.feature2index = {}\n",
    "        for idx, fn in enumerate(self.index2features): self.feature2index[fn] = str(idx)\n",
    "        self.scale = scale; self.lb, self.ub = lb, ub\n",
    "        self.diff_flag = diff_flag(self.index2features)\n",
    "        \n",
    "    def xavier_init(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        H = torch.cat([x, t], dim=1)\n",
    "        if self.scale: H = self.neural_net_scale(H)\n",
    "        return self.model(H)\n",
    "    \n",
    "    def loss(self, X_input, X_input_noise, y_input, y_input_noise, exp_p0=True, update_network_params=True, update_pde_params=True):\n",
    "        # Denoising process\n",
    "        if not self.noiseless_mode:\n",
    "            # (1) Denoising FFT on (x, t)\n",
    "            # This line returns the approx. recon.\n",
    "            X_input_noise = cat(torch.fft.ifft(self.in_fft_nn(X_input_noise[1])*X_input_noise[0]).real.reshape(-1, 1), \n",
    "                                torch.fft.ifft(self.in_fft_nn(X_input_noise[3])*X_input_noise[2]).real.reshape(-1, 1))\n",
    "            X_input_noise = X_input-X_input_noise\n",
    "            X_input = self.inp_rpca(X_input, X_input_noise, normalize=True)\n",
    "            \n",
    "            # (2)D enoising FFT on y_input\n",
    "            y_input_noise = y_input-torch.fft.ifft(self.out_fft_nn(y_input_noise[1])*y_input_noise[0]).real.reshape(-1, 1)\n",
    "            y_input = self.out_rpca(y_input, y_input_noise, normalize=True)\n",
    "        \n",
    "        grads_dict, u_t = self.grads_dict(X_input[:, 0:1], X_input[:, 1:2])\n",
    "        \n",
    "        total_loss = []\n",
    "        # MSE Loss\n",
    "        if update_network_params:\n",
    "            mse_loss = F.mse_loss(grads_dict[\"uf\"], y_input)\n",
    "            total_loss.append(mse_loss)\n",
    "            \n",
    "        # PDE Loss\n",
    "        if update_pde_params:\n",
    "            if exp_p0: p0_coeff = torch.exp(self.p0)\n",
    "            else: p0_coeff = self.p0\n",
    "            l_eq = F.mse_loss(p0_coeff*grads_dict[\"u_xx\"]+self.p1*grads_dict[\"uf\"]*grads_dict[\"u_x\"], u_t)\n",
    "            total_loss.append(l_eq)\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "    def grads_dict(self, x, t):\n",
    "        uf = self.forward(x, t)\n",
    "        u_t = self.gradients(uf, t)[0]\n",
    "        u_x = self.gradients(uf, x)[0]\n",
    "        u_xx = self.gradients(u_x, x)[0]\n",
    "        \n",
    "        return {\"uf\":uf, \"u_x\":u_x, \"u_xx\":u_xx}, u_t\n",
    "    \n",
    "    def gradients(self, func, x):\n",
    "        return grad(func, x, create_graph=True, retain_graph=True, grad_outputs=torch.ones(func.shape))\n",
    "    \n",
    "    def neural_net_scale(self, inp): \n",
    "        return -1.0+2.0*(inp-self.lb)/(self.ub-self.lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using old implementation of TorchMLP. See models.py for more new model-related source code.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TorchMLP(dimensions=[2, 50, 50, 50 ,50, 50, 1], \n",
    "         activation_function=nn.Tanh, bn=None, # nn.LayerNorm\n",
    "         dropout=None)\n",
    "\n",
    "### TODO: How to load weights without using bn ###\n",
    "\n",
    "# Pretrained model\n",
    "semisup_model_state_dict = torch.load(\"./weights_nobn/semisup_model_nobn_2000_2000_finetuned.pth\")\n",
    "parameters = OrderedDict()\n",
    "# Filter only the parts that I care about renaming (to be similar to what defined in TorchMLP).\n",
    "inner_part = \"network.model.\"\n",
    "for p in semisup_model_state_dict:\n",
    "    if inner_part in p:\n",
    "        parameters[p.replace(inner_part, \"\")] = semisup_model_state_dict[p]\n",
    "\n",
    "model.load_state_dict(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1039e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(model(X_u_train), u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISELESS_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_fft, x_PSD = fft1d_denoise(X_u_train[:, 0:1], c=-5, return_real=True)\n",
    "_, t_fft, t_PSD = fft1d_denoise(X_u_train[:, 1:2], c=-5, return_real=True)\n",
    "_, u_train_fft, u_train_PSD = fft1d_denoise(u_train, c=-5, return_real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global NOISELESS_MODE\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad()\n",
    "    losses = pinn.loss(X_u_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD), exp_p0=True, update_network_params=True, update_pde_params=True)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad:\n",
    "        l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def mtl_closure():\n",
    "    global NOISELESS_MODE\n",
    "    losses = pinn.loss(X_u_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD), exp_p0=True, update_network_params=True, update_pde_params=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(len(losses)):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(pinn.parameters()): \n",
    "        param.grad = updated_grads[0][idx]+updated_grads[1][idx]\n",
    "        \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in noisy mode.\n",
      "100%|██████████| 200/200 [00:02<00:00, 73.35trial/s, best loss: 0.33631765842437744]\n",
      "{'c1': 4.769812029937644, 'c2': 0.5112086380989461}\n"
     ]
    }
   ],
   "source": [
    "if not NOISELESS_MODE:\n",
    "    print(\"You are in noisy mode.\")\n",
    "    pinn = RobustPINN(model=model, loss_fn=mod, index2features=feature_names, \n",
    "                      scale=False, lb=None, ub=None, pretrained=True, noiseless_mode=NOISELESS_MODE)\n",
    "\n",
    "    def inference(args):\n",
    "        global pinn\n",
    "        c1, c2 = args\n",
    "        \n",
    "        pinn.in_fft_nn.c = nn.Parameter(data=torch.FloatTensor([float(c1)]), requires_grad=False)\n",
    "        pinn.out_fft_nn.c = nn.Parameter(data=torch.FloatTensor([float(c2)]), requires_grad=False)\n",
    "        \n",
    "        losses = pinn.loss(X_u_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD), update_network_params=True, update_pde_params=True)\n",
    "        return sum(losses).item()\n",
    "\n",
    "    pinn.eval()\n",
    "    space = [hp.uniform('c1', 0, 5), hp.uniform('c2', 0, 5)]\n",
    "    res = fmin(fn=inference, space=space, algo=tpe.suggest, max_evals=200)\n",
    "\n",
    "    print(res)\n",
    "    if 'pinn' in globals(): del pinn\n",
    "\n",
    "    pinn = RobustPINN(model=model, loss_fn=mod, index2features=feature_names, \n",
    "                      scale=False, lb=None, ub=None, pretrained=True, noiseless_mode=NOISELESS_MODE,\n",
    "                      init_cs=(res['c1'], res['c2']))\n",
    "    \n",
    "else: \n",
    "    pinn = RobustPINN(model=model, loss_fn=mod, index2features=feature_names, \n",
    "                      scale=False, lb=None, ub=None, pretrained=True, noiseless_mode=NOISELESS_MODE)\n",
    "    print(\"You are in noiseless mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs1, epochs2 = 10000, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Phase optimization using Adam with PCGrad gradient modification\n",
      "Epoch 0:  1.2613317966461182\n",
      "Epoch 1000:  0.003170547541230917\n",
      "Epoch 2000:  0.004777888301759958\n",
      "Epoch 3000:  0.006724500562995672\n",
      "Epoch 4000:  0.0002450841711834073\n",
      "Epoch 5000:  0.0016158738872036338\n",
      "Epoch 6000:  0.00021704065147787333\n",
      "Epoch 7000:  0.00028554489836096764\n",
      "Epoch 8000:  0.0005420554080046713\n",
      "Epoch 9000:  0.00028504140209406614\n",
      "Epoch 9999:  0.0006107053486630321\n"
     ]
    }
   ],
   "source": [
    "# optimizer1 = MADGRAD(pinn.parameters(), lr=1e-7, momentum=0.95)\n",
    "optimizer1 = AdamGC(pinn.parameters(), lr=6e-4, use_gc=True, gc_conv_only=False, gc_loc=False)\n",
    "pinn.train(); best_train_loss = 1e6\n",
    "\n",
    "print('1st Phase optimization using Adam with PCGrad gradient modification')\n",
    "for i in range(epochs1):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    if (i % 1000) == 0 or i == epochs1-1:\n",
    "        l = mtl_closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Phase optimization using LBFGS\n",
      "Epoch 0:  3.698242289829068e-05\n",
      "Epoch 10:  2.5909303076332435e-05\n",
      "Epoch 20:  2.5909303076332435e-05\n",
      "Epoch 30:  2.5909303076332435e-05\n",
      "Epoch 40:  2.5909303076332435e-05\n",
      "Epoch 49:  2.5909303076332435e-05\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=500, max_eval=int(500*1.25), history_size=500, line_search_fn='strong_wolfe')\n",
    "print('2nd Phase optimization using LBFGS')\n",
    "for i in range(epochs2):\n",
    "    optimizer2.step(closure)\n",
    "    if (i % 10) == 0 or i == epochs2-1:\n",
    "        l = closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0026310004759579897, -0.9879413843154907)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(np.exp(pinn.p0.detach().numpy())), float(pinn.p1.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pinn, \"tmp.pth\")\n",
    "# pinn = load_weights(pinn, \"tmp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global NOISELESS_MODE\n",
    "    if torch.is_grad_enabled():\n",
    "        optimizer2.zero_grad()\n",
    "    losses = pinn.loss(X_u_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD), exp_p0=False, update_network_params=True, update_pde_params=True)\n",
    "    l = sum(losses)\n",
    "    if l.requires_grad:\n",
    "        l.backward(retain_graph=True)\n",
    "    return l\n",
    "\n",
    "def mtl_closure():\n",
    "    global NOISELESS_MODE\n",
    "    losses = pinn.loss(X_u_train, (x_fft, x_PSD, t_fft, t_PSD), u_train, (u_train_fft, u_train_PSD), exp_p0=False, update_network_params=True, update_pde_params=True)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(len(losses)):\n",
    "        optimizer1.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(pinn.parameters()): \n",
    "        param.grad = updated_grads[0][idx]+updated_grads[1][idx]\n",
    "        \n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor(0.0026, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor(-0.9879, requires_grad=True))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn.p0 = nn.Parameter(data=torch.tensor(round(float(np.exp(pinn.p0.detach().numpy())), 4)))\n",
    "pinn.p1 = nn.Parameter(data=torch.tensor(round(float(pinn.p1.detach().numpy()), 4)))\n",
    "pinn.p0, pinn.p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del optimizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = AdamGC(pinn.parameters(), lr=1e-6, use_gc=True, gc_conv_only=False, gc_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  0.0007452174904756248\n",
      "-0.9878990054130554 0.002601000014692545\n",
      "Epoch 100:  3.253961767768487e-05\n",
      "-0.9878814816474915 0.0026205615140497684\n",
      "Epoch 200:  3.240258592995815e-05\n",
      "-0.987881064414978 0.002624478889629245\n",
      "Epoch 300:  3.529949754010886e-05\n",
      "-0.987881064414978 0.0026273303665220737\n",
      "Epoch 400:  3.931709943572059e-05\n",
      "-0.987881064414978 0.00263031292706728\n",
      "Epoch 500:  4.403798811836168e-05\n",
      "-0.987881064414978 0.00263412157073617\n",
      "Epoch 600:  4.9221591325476766e-05\n",
      "-0.987881064414978 0.0026389809790998697\n",
      "Epoch 700:  5.464071000460535e-05\n",
      "-0.987881064414978 0.0026449195574969053\n",
      "Epoch 800:  6.011920777382329e-05\n",
      "-0.987881064414978 0.0026518679223954678\n",
      "Epoch 900:  6.551588012371212e-05\n",
      "-0.987881064414978 0.002659706398844719\n",
      "Epoch 1000:  7.077569171087816e-05\n",
      "-0.987881064414978 0.0026683027390390635\n",
      "Epoch 1100:  7.589880260638893e-05\n",
      "-0.987881064414978 0.002677512587979436\n",
      "Epoch 1200:  8.083410648396239e-05\n",
      "-0.987881064414978 0.0026872006710618734\n",
      "Epoch 1300:  8.553006773581728e-05\n",
      "-0.9878751635551453 0.0026972407940775156\n",
      "Epoch 1400:  8.995616371976212e-05\n",
      "-0.9878692030906677 0.002707521431148052\n",
      "Epoch 1500:  9.397616668138653e-05\n",
      "-0.9878632426261902 0.0027179387398064137\n",
      "Epoch 1600:  9.757937368704006e-05\n",
      "-0.9878572821617126 0.002728401217609644\n",
      "Epoch 1700:  0.00010069346899399534\n",
      "-0.9878513216972351 0.002738826908171177\n",
      "Epoch 1800:  0.00010320868750568479\n",
      "-0.9878453612327576 0.0027491513174027205\n",
      "Epoch 1900:  0.0001049320781021379\n",
      "-0.98783940076828 0.0027592885307967663\n",
      "Epoch 2000:  0.00010592780017759651\n",
      "-0.9878334403038025 0.0027691770810633898\n",
      "Epoch 2100:  0.00010612981714075431\n",
      "-0.987827479839325 0.0027787727303802967\n",
      "Epoch 2200:  0.00010554034815868363\n",
      "-0.9878215193748474 0.002788024488836527\n",
      "Epoch 2300:  0.00010412866686237976\n",
      "-0.9878155589103699 0.0027969107031822205\n",
      "Epoch 2400:  0.00010196231596637517\n",
      "-0.9878095984458923 0.0028053889982402325\n",
      "Epoch 2500:  9.923223115038127e-05\n",
      "-0.9878036379814148 0.0028134509921073914\n",
      "Epoch 2600:  9.601325291441754e-05\n",
      "-0.9877976775169373 0.0028211139142513275\n",
      "Epoch 2700:  9.257283090846613e-05\n",
      "-0.9877917170524597 0.0028284003492444754\n",
      "Epoch 2800:  8.8949927885551e-05\n",
      "-0.9877857565879822 0.0028353347443044186\n",
      "Epoch 2900:  8.526962483301759e-05\n",
      "-0.9877797961235046 0.002841936657205224\n",
      "Epoch 3000:  8.171025547198951e-05\n",
      "-0.9877756237983704 0.002848259173333645\n",
      "Epoch 3100:  7.839650061214343e-05\n",
      "-0.9877756237983704 0.0028543679509311914\n",
      "Epoch 3200:  7.531642768299207e-05\n",
      "-0.9877756237983704 0.002860291628167033\n",
      "Epoch 3300:  7.252679642988369e-05\n",
      "-0.9877756237983704 0.0028660602401942015\n",
      "Epoch 3400:  6.994193972786888e-05\n",
      "-0.9877756237983704 0.0028716998640447855\n",
      "Epoch 3500:  6.75112969474867e-05\n",
      "-0.9877756237983704 0.0028772077057510614\n",
      "Epoch 3600:  6.528219091705978e-05\n",
      "-0.9877756237983704 0.0028825937770307064\n",
      "Epoch 3700:  6.316701183095574e-05\n",
      "-0.9877756237983704 0.0028878767043352127\n",
      "Epoch 3800:  6.119168392615393e-05\n",
      "-0.9877756834030151 0.002893031807616353\n",
      "Epoch 3900:  5.8321471442468464e-05\n",
      "-0.9877814054489136 0.002897952450439334\n",
      "Epoch 4000:  5.615430563921109e-05\n",
      "-0.9877873659133911 0.0029023790266364813\n",
      "Epoch 4100:  5.351221261662431e-05\n",
      "-0.9877933263778687 0.0029067585710436106\n",
      "Epoch 4200:  5.129155397298746e-05\n",
      "-0.9878018498420715 0.0029107441660016775\n",
      "Epoch 4300:  4.879122207057662e-05\n",
      "-0.9878137707710266 0.0029143672436475754\n",
      "Epoch 4400:  4.703641388914548e-05\n",
      "-0.9878256916999817 0.0029177172109484673\n",
      "Epoch 4500:  4.483855445869267e-05\n",
      "-0.9878392815589905 0.0029209915082901716\n",
      "Epoch 4600:  4.345208071754314e-05\n",
      "-0.9878568649291992 0.002924241591244936\n",
      "Epoch 4700:  4.238351175445132e-05\n",
      "-0.9878737330436707 0.002927563851699233\n",
      "Epoch 4800:  4.152531619183719e-05\n",
      "-0.98788982629776 0.0029309154488146305\n",
      "Epoch 4900:  4.081700535607524e-05\n",
      "-0.9879035353660583 0.0029345897492021322\n",
      "Epoch 5000:  3.9981136069400236e-05\n",
      "-0.9879163503646851 0.002938235877081752\n",
      "Epoch 5100:  3.977572123403661e-05\n",
      "-0.9879291653633118 0.0029419809579849243\n",
      "Epoch 5200:  3.8266178307821974e-05\n",
      "-0.9879413843154907 0.0029457875061780214\n",
      "Epoch 5300:  3.795680095208809e-05\n",
      "-0.9879539608955383 0.002949612680822611\n",
      "Epoch 5400:  3.736377402674407e-05\n",
      "-0.9879664182662964 0.0029530737083405256\n",
      "Epoch 5500:  3.613489025156014e-05\n",
      "-0.9879778623580933 0.002957138465717435\n",
      "Epoch 5600:  3.632732114056125e-05\n",
      "-0.987991452217102 0.0029604220762848854\n",
      "Epoch 5700:  3.521334656397812e-05\n",
      "-0.9880031943321228 0.002964196028187871\n",
      "Epoch 5800:  3.47787317878101e-05\n",
      "-0.988014817237854 0.0029679243452847004\n",
      "Epoch 5900:  3.458459104876965e-05\n",
      "-0.9880257248878479 0.002971656620502472\n",
      "Epoch 6000:  3.3788379369070753e-05\n",
      "-0.988034725189209 0.0029754345305263996\n",
      "Epoch 6100:  3.350499173393473e-05\n",
      "-0.9880452752113342 0.002978926757350564\n",
      "Epoch 6200:  3.279143857071176e-05\n",
      "-0.9880547523498535 0.0029821693897247314\n",
      "Epoch 6300:  3.219764766981825e-05\n",
      "-0.988066554069519 0.0029854695312678814\n",
      "Epoch 6400:  3.153942452627234e-05\n",
      "-0.9880776405334473 0.002988493535667658\n",
      "Epoch 6500:  3.141041088383645e-05\n",
      "-0.9880868792533875 0.002991965040564537\n",
      "Epoch 6600:  3.088896846747957e-05\n",
      "-0.9880959987640381 0.0029948847368359566\n",
      "Epoch 6700:  3.0425138902501203e-05\n",
      "-0.9881041049957275 0.002998398384079337\n",
      "Epoch 6800:  3.050204395549372e-05\n",
      "-0.9881098866462708 0.0030018589459359646\n",
      "Epoch 6900:  3.0179369787219912e-05\n",
      "-0.9881125688552856 0.003004765138030052\n",
      "Epoch 7000:  2.8857401048298925e-05\n",
      "-0.9881181120872498 0.0030081034637987614\n",
      "Epoch 7100:  2.857772051356733e-05\n",
      "-0.9881253838539124 0.0030108303762972355\n",
      "Epoch 7200:  2.8624057449633256e-05\n",
      "-0.9881328344345093 0.0030129794031381607\n",
      "Epoch 7300:  2.918521386163775e-05\n",
      "-0.9881337881088257 0.0030168683733791113\n",
      "Epoch 7400:  2.906847294070758e-05\n",
      "-0.9881284832954407 0.003021426033228636\n",
      "Epoch 7500:  2.908012356783729e-05\n",
      "-0.9881240725517273 0.0030245028901845217\n",
      "Epoch 7600:  2.8773993108188733e-05\n",
      "-0.9881192445755005 0.0030283965170383453\n",
      "Epoch 7700:  2.868034425773658e-05\n",
      "-0.9881148934364319 0.0030321090016514063\n",
      "Epoch 7800:  2.839287117240019e-05\n",
      "-0.9881131649017334 0.0030349143780767918\n",
      "Epoch 7900:  2.764374039543327e-05\n",
      "-0.9881157279014587 0.003037508809939027\n",
      "Epoch 8000:  2.7013395083486103e-05\n",
      "-0.9881179332733154 0.003040720708668232\n",
      "Epoch 8100:  2.720304109971039e-05\n",
      "-0.9881215691566467 0.0030430504120886326\n",
      "Epoch 8200:  2.6792768039740622e-05\n",
      "-0.9881244897842407 0.0030457114335149527\n",
      "Epoch 8300:  2.629768096085172e-05\n",
      "-0.9881269335746765 0.003047887235879898\n",
      "Epoch 8400:  2.626162131491583e-05\n",
      "-0.9881299734115601 0.003050697036087513\n",
      "Epoch 8500:  2.607721216918435e-05\n",
      "-0.9881313443183899 0.0030534148681908846\n",
      "Epoch 8600:  2.590712028904818e-05\n",
      "-0.988132119178772 0.003055854234844446\n",
      "Epoch 8700:  2.5518005713820457e-05\n",
      "-0.9881346821784973 0.0030583750922232866\n",
      "Epoch 8800:  2.5406643544556573e-05\n",
      "-0.9881384968757629 0.0030606910586357117\n",
      "Epoch 8900:  2.5090166673180647e-05\n",
      "-0.9881417155265808 0.003062622621655464\n",
      "Epoch 9000:  2.4226445020758547e-05\n",
      "-0.9881488680839539 0.003064463846385479\n",
      "Epoch 9100:  2.4318647774634883e-05\n",
      "-0.9881526231765747 0.00306652020663023\n",
      "Epoch 9200:  2.3539370886282995e-05\n",
      "-0.9881582856178284 0.0030681081116199493\n",
      "Epoch 9300:  2.3728573069092818e-05\n",
      "-0.9881632924079895 0.003069899044930935\n",
      "Epoch 9400:  2.3380584025289863e-05\n",
      "-0.9881678819656372 0.003071861108765006\n",
      "Epoch 9500:  2.3166838218457997e-05\n",
      "-0.9881724715232849 0.0030735787004232407\n",
      "Epoch 9600:  2.2915533918421715e-05\n",
      "-0.9881786108016968 0.003075274406000972\n",
      "Epoch 9700:  2.253614911751356e-05\n",
      "-0.9881849884986877 0.0030768774449825287\n",
      "Epoch 9800:  2.224326271971222e-05\n",
      "-0.9881885051727295 0.003078638343140483\n",
      "Epoch 9900:  2.2037136659491807e-05\n",
      "-0.9881936311721802 0.00308025861158967\n",
      "Epoch 10000:  2.2006473955116235e-05\n",
      "-0.9881961941719055 0.003081715200096369\n",
      "Epoch 10100:  2.1582978661172092e-05\n",
      "-0.9882026314735413 0.0030835047364234924\n",
      "Epoch 10200:  2.119577220582869e-05\n",
      "-0.9882071018218994 0.003085056785494089\n",
      "Epoch 10300:  2.1018327970523387e-05\n",
      "-0.988211989402771 0.003086224664002657\n",
      "Epoch 10400:  2.0859191863564774e-05\n",
      "-0.9882179498672485 0.0030876637902110815\n",
      "Epoch 10500:  2.0611418221960776e-05\n",
      "-0.9882235527038574 0.003089056583121419\n",
      "Epoch 10600:  2.0413797756191343e-05\n",
      "-0.9882307052612305 0.0030904121231287718\n",
      "Epoch 10700:  2.0297027731430717e-05\n",
      "-0.9882346391677856 0.003092039842158556\n",
      "Epoch 10800:  2.016998769249767e-05\n",
      "-0.9882382750511169 0.0030934824608266354\n",
      "Epoch 10900:  1.9866860384354368e-05\n",
      "-0.9882409572601318 0.003095047315582633\n",
      "Epoch 11000:  1.934842293849215e-05\n",
      "-0.988246738910675 0.0030958226416260004\n",
      "Epoch 11100:  1.9328126654727384e-05\n",
      "-0.9882542490959167 0.003097159555181861\n",
      "Epoch 11200:  1.9280490960227326e-05\n",
      "-0.9882605075836182 0.0030982126481831074\n",
      "Epoch 11300:  1.8791730326483957e-05\n",
      "-0.9882664084434509 0.003099028253927827\n",
      "Epoch 11400:  1.8748005459201522e-05\n",
      "-0.9882720708847046 0.003100093686953187\n",
      "Epoch 11500:  1.859596886788495e-05\n",
      "-0.9882773756980896 0.003101054113358259\n",
      "Epoch 11600:  1.8467129848431796e-05\n",
      "-0.9882820248603821 0.0031020103488117456\n",
      "Epoch 11700:  1.8097111023962498e-05\n",
      "-0.9882873892784119 0.0031032266560941935\n",
      "Epoch 11800:  1.7985537851927802e-05\n",
      "-0.9882925152778625 0.0031040830072015524\n",
      "Epoch 11900:  1.7960819604923017e-05\n",
      "-0.9882985949516296 0.0031050771940499544\n",
      "Epoch 12000:  1.7654276234679855e-05\n",
      "-0.9883034825325012 0.0031060492619872093\n",
      "Epoch 12100:  1.7425909391022287e-05\n",
      "-0.988308310508728 0.003106858814135194\n",
      "Epoch 12200:  1.7300522813457064e-05\n",
      "-0.9883146286010742 0.0031079077161848545\n",
      "Epoch 12300:  1.702478766674176e-05\n",
      "-0.9883190989494324 0.0031086511444300413\n",
      "Epoch 12400:  1.702127519820351e-05\n",
      "-0.9883258938789368 0.0031094099394977093\n",
      "Epoch 12500:  1.6755035176174715e-05\n",
      "-0.9883299469947815 0.0031099370680749416\n",
      "Epoch 12600:  1.6718975530238822e-05\n",
      "-0.9883362054824829 0.003110807156190276\n",
      "Epoch 12700:  1.6486952517880127e-05\n",
      "-0.9883403182029724 0.003111650701612234\n",
      "Epoch 12800:  1.616195004316978e-05\n",
      "-0.9883431196212769 0.003111785277724266\n",
      "Epoch 12900:  1.6012101696105674e-05\n",
      "-0.9883502125740051 0.0031123990193009377\n",
      "Epoch 13000:  1.5997620721464045e-05\n",
      "-0.9883553385734558 0.0031132667791098356\n",
      "Epoch 13100:  1.60509989655111e-05\n",
      "-0.9883593320846558 0.0031140653882175684\n",
      "Epoch 13200:  1.5710444131400436e-05\n",
      "-0.9883628487586975 0.003114747814834118\n",
      "Epoch 13300:  1.5724626791779883e-05\n",
      "-0.988366961479187 0.003115488216280937\n",
      "Epoch 13400:  1.5502693713642657e-05\n",
      "-0.9883701205253601 0.003116181120276451\n",
      "Epoch 13500:  1.5512261597905308e-05\n",
      "-0.9883756637573242 0.003116738284006715\n",
      "Epoch 13600:  1.540655648568645e-05\n",
      "-0.9883801937103271 0.003117504296824336\n",
      "Epoch 13700:  1.5137988157221116e-05\n",
      "-0.9883830547332764 0.0031182344537228346\n",
      "Epoch 13800:  1.4992749129305594e-05\n",
      "-0.9883882999420166 0.003118582535535097\n",
      "Epoch 13900:  1.4893407751515042e-05\n",
      "-0.988392174243927 0.003119091270491481\n",
      "Epoch 14000:  1.48498847920564e-05\n",
      "-0.9883966445922852 0.003119442379102111\n",
      "Epoch 14100:  1.4666899915027898e-05\n",
      "-0.9884002804756165 0.003120127832517028\n",
      "Epoch 14200:  1.4379338608705439e-05\n",
      "-0.9884011745452881 0.003120355075225234\n",
      "Epoch 14300:  1.4381043001776561e-05\n",
      "-0.9884044528007507 0.0031209855806082487\n",
      "Epoch 14400:  1.4377053958014585e-05\n",
      "-0.9884090423583984 0.00312136416323483\n",
      "Epoch 14500:  1.4255982023314573e-05\n",
      "-0.9884141087532043 0.003122141817584634\n",
      "Epoch 14600:  1.420262924511917e-05\n",
      "-0.9884176850318909 0.0031228181906044483\n",
      "Epoch 14700:  1.4010760423843749e-05\n",
      "-0.9884214401245117 0.003123400267213583\n",
      "Epoch 14800:  1.385044652124634e-05\n",
      "-0.9884245991706848 0.0031236789654940367\n",
      "Epoch 14900:  1.3943530575488694e-05\n",
      "-0.988429844379425 0.0031239278614521027\n",
      "Epoch 15000:  1.3737876543018501e-05\n",
      "-0.9884326457977295 0.0031241814140230417\n",
      "Epoch 15100:  1.3727521945838816e-05\n",
      "-0.9884381294250488 0.0031247965525835752\n",
      "Epoch 15200:  1.3558964383264538e-05\n",
      "-0.9884378910064697 0.003124962328001857\n",
      "Epoch 15300:  1.3513209523807745e-05\n",
      "-0.9884434342384338 0.003125492949038744\n",
      "Epoch 15400:  1.3504855814971961e-05\n",
      "-0.988446831703186 0.0031262317206710577\n",
      "Epoch 15500:  1.3351858797250316e-05\n",
      "-0.9884509444236755 0.0031266657169908285\n",
      "Epoch 15600:  1.3245298760011792e-05\n",
      "-0.9884540438652039 0.0031269153114408255\n",
      "Epoch 15700:  1.3128876162227243e-05\n",
      "-0.988458514213562 0.003127097152173519\n",
      "Epoch 15800:  1.310908828600077e-05\n",
      "-0.988462507724762 0.003127520205453038\n",
      "Epoch 15900:  1.2981678082724102e-05\n",
      "-0.9884667992591858 0.0031280526891350746\n",
      "Epoch 16000:  1.297308972425526e-05\n",
      "-0.9884703159332275 0.003128330921754241\n",
      "Epoch 16100:  1.2750326277455315e-05\n",
      "-0.9884735941886902 0.003128441283479333\n",
      "Epoch 16200:  1.2769213753927033e-05\n",
      "-0.9884774684906006 0.0031288028694689274\n",
      "Epoch 16300:  1.2616072126547806e-05\n",
      "-0.9884798526763916 0.00312894769012928\n",
      "Epoch 16400:  1.2633443475351669e-05\n",
      "-0.9884840846061707 0.0031292035710066557\n",
      "Epoch 16500:  1.2606058589881286e-05\n",
      "-0.9884860515594482 0.0031294410582631826\n",
      "Epoch 16600:  1.2441984836186748e-05\n",
      "-0.9884892702102661 0.003129791235551238\n",
      "Epoch 16700:  1.2346225048531778e-05\n",
      "-0.9884930849075317 0.0031302724964916706\n",
      "Epoch 16800:  1.222903301822953e-05\n",
      "-0.9884939193725586 0.0031304217409342527\n",
      "Epoch 16900:  1.2162766324763652e-05\n",
      "-0.9884968400001526 0.003130368422716856\n",
      "Epoch 17000:  1.2086144124623388e-05\n",
      "-0.9884998798370361 0.0031307428143918514\n",
      "Epoch 17100:  1.2000644346699119e-05\n",
      "-0.9885027408599854 0.0031308531761169434\n",
      "Epoch 17200:  1.1967595128226094e-05\n",
      "-0.9885056018829346 0.003130977740511298\n",
      "Epoch 17300:  1.1873268704221118e-05\n",
      "-0.9885078072547913 0.0031313332729041576\n",
      "Epoch 17400:  1.1833488315460272e-05\n",
      "-0.9885105490684509 0.00313143921084702\n",
      "Epoch 17500:  1.173950749944197e-05\n",
      "-0.9885145425796509 0.0031317865941673517\n",
      "Epoch 17600:  1.165279172710143e-05\n",
      "-0.988518238067627 0.003132166340947151\n",
      "Epoch 17700:  1.1666743375826627e-05\n",
      "-0.9885202646255493 0.0031322843860834837\n",
      "Epoch 17800:  1.1630575500021223e-05\n",
      "-0.9885239601135254 0.0031326361931860447\n",
      "Epoch 17900:  1.154151868831832e-05\n",
      "-0.9885264039039612 0.003132849931716919\n",
      "Epoch 18000:  1.1411996638344135e-05\n",
      "-0.9885275959968567 0.0031329141929745674\n",
      "Epoch 18100:  1.1313214599795174e-05\n",
      "-0.9885275363922119 0.0031329295597970486\n",
      "Epoch 18200:  1.1284075299045071e-05\n",
      "-0.9885318279266357 0.0031332792714238167\n",
      "Epoch 18300:  1.1220886335649993e-05\n",
      "-0.9885340929031372 0.003133390098810196\n",
      "Epoch 18400:  1.1118212569272146e-05\n",
      "-0.9885359406471252 0.003133596619591117\n",
      "Epoch 18500:  1.1116387213405687e-05\n",
      "-0.9885375499725342 0.003133740508928895\n",
      "Epoch 18600:  1.110342054744251e-05\n",
      "-0.988541841506958 0.0031340369023382664\n",
      "Epoch 18700:  1.0987447240040638e-05\n",
      "-0.9885432720184326 0.0031340892892330885\n",
      "Epoch 18800:  1.100561348721385e-05\n",
      "-0.9885470271110535 0.003134296275675297\n",
      "Epoch 18900:  1.0899933840846643e-05\n",
      "-0.9885491132736206 0.0031345579773187637\n",
      "Epoch 19000:  1.0880958143388852e-05\n",
      "-0.988552451133728 0.0031347188632935286\n",
      "Epoch 19100:  1.079666708392324e-05\n",
      "-0.9885544180870056 0.0031348001211881638\n",
      "Epoch 19200:  1.0755190487543587e-05\n",
      "-0.9885575771331787 0.0031350620556622744\n",
      "Epoch 19300:  1.0744286555564031e-05\n",
      "-0.988560140132904 0.003135123522952199\n",
      "Epoch 19400:  1.0644901522027794e-05\n",
      "-0.9885614514350891 0.003135221777483821\n",
      "Epoch 19500:  1.0616206964186858e-05\n",
      "-0.9885650873184204 0.0031355409882962704\n",
      "Epoch 19600:  1.0611999641696457e-05\n",
      "-0.9885676503181458 0.003135738195851445\n",
      "Epoch 19700:  1.0547449164732825e-05\n",
      "-0.988571286201477 0.003135936101898551\n",
      "Epoch 19800:  1.0482750440132804e-05\n",
      "-0.9885739684104919 0.003136138431727886\n",
      "Epoch 19900:  1.0424442734802142e-05\n",
      "-0.9885751008987427 0.0031361014116555452\n",
      "Epoch 20000:  1.039610924635781e-05\n",
      "-0.9885775446891785 0.0031362874433398247\n",
      "Epoch 20100:  1.0333922546124086e-05\n",
      "-0.9885810017585754 0.0031365312170237303\n",
      "Epoch 20200:  1.0282732546329498e-05\n",
      "-0.9885837435722351 0.003136750776320696\n",
      "Epoch 20300:  1.0206840670434758e-05\n",
      "-0.9885831475257874 0.003136636223644018\n",
      "Epoch 20400:  1.018965122057125e-05\n",
      "-0.9885867238044739 0.0031367146875709295\n",
      "Epoch 20500:  1.0116266821569297e-05\n",
      "-0.9885885715484619 0.00313677079975605\n",
      "Epoch 20600:  1.0164103514398448e-05\n",
      "-0.9885926842689514 0.003137021092697978\n",
      "Epoch 20700:  1.0023592039942741e-05\n",
      "-0.9885917901992798 0.0031369654461741447\n",
      "Epoch 20800:  1.000292286335025e-05\n",
      "-0.9885916709899902 0.003136853687465191\n",
      "Epoch 20900:  9.922026947606355e-06\n",
      "-0.988595724105835 0.003137074178084731\n",
      "Epoch 21000:  9.886584848572966e-06\n",
      "-0.988598108291626 0.0031371263321489096\n",
      "Epoch 21100:  9.854348718363326e-06\n",
      "-0.9885988831520081 0.003137126797810197\n",
      "Epoch 21200:  9.915882401401177e-06\n",
      "-0.9886024594306946 0.0031372965313494205\n",
      "Epoch 21300:  9.790065632842015e-06\n",
      "-0.9886043071746826 0.003137372899800539\n",
      "Epoch 21400:  9.73954865912674e-06\n",
      "-0.9886057376861572 0.0031374883837997913\n",
      "Epoch 21500:  9.727531505632214e-06\n",
      "-0.9886078834533691 0.0031375237740576267\n",
      "Epoch 21600:  9.633437912270892e-06\n",
      "-0.9886111617088318 0.0031376515980809927\n",
      "Epoch 21700:  9.637495168135501e-06\n",
      "-0.9886138439178467 0.0031378688290715218\n",
      "Epoch 21800:  9.580629011907149e-06\n",
      "-0.9886155128479004 0.0031379112042486668\n",
      "Epoch 21900:  9.561044862493873e-06\n",
      "-0.9886173009872437 0.003137909108772874\n",
      "Epoch 22000:  9.49127661442617e-06\n",
      "-0.9886196255683899 0.0031380988657474518\n",
      "Epoch 22100:  9.442445843887981e-06\n",
      "-0.9886186122894287 0.003137875348329544\n",
      "Epoch 22200:  9.467225936532486e-06\n",
      "-0.9886207580566406 0.003137923777103424\n",
      "Epoch 22300:  9.390265404363163e-06\n",
      "-0.9886235594749451 0.0031381575390696526\n",
      "Epoch 22400:  9.350331310997717e-06\n",
      "-0.9886246919631958 0.003138110274448991\n",
      "Epoch 22500:  9.270520422433037e-06\n",
      "-0.9886260032653809 0.0031380902510136366\n",
      "Epoch 22600:  9.235496690962464e-06\n",
      "-0.9886269569396973 0.0031379503197968006\n",
      "Epoch 22700:  9.288184628530871e-06\n",
      "-0.9886309504508972 0.0031382415909320116\n",
      "Epoch 22800:  9.209644304064568e-06\n",
      "-0.9886310696601868 0.0031383000314235687\n",
      "Epoch 22900:  9.206163667840883e-06\n",
      "-0.9886348247528076 0.00313843647018075\n",
      "Epoch 23000:  9.151458471023943e-06\n",
      "-0.9886355996131897 0.0031385149341076612\n",
      "Epoch 23100:  9.117658919421956e-06\n",
      "-0.988638162612915 0.003138620173558593\n",
      "Epoch 23200:  9.081895768758841e-06\n",
      "-0.9886408448219299 0.003138803644105792\n",
      "Epoch 23300:  8.99994483916089e-06\n",
      "-0.9886419177055359 0.0031387510243803263\n",
      "Epoch 23400:  8.985295607999433e-06\n",
      "-0.9886434078216553 0.003138757310807705\n",
      "Epoch 23500:  8.963757863966748e-06\n",
      "-0.9886455535888672 0.003138807136565447\n",
      "Epoch 23600:  8.91781019163318e-06\n",
      "-0.9886467456817627 0.0031388236675411463\n",
      "Epoch 23700:  8.885070201358758e-06\n",
      "-0.9886487126350403 0.0031388828065246344\n",
      "Epoch 23800:  8.831059858493973e-06\n",
      "-0.988650381565094 0.003138885134831071\n",
      "Epoch 23900:  8.849393452692311e-06\n",
      "-0.9886525273323059 0.0031390092335641384\n",
      "Epoch 24000:  8.799002898740582e-06\n",
      "-0.9886550307273865 0.00313915079459548\n",
      "Epoch 24100:  8.787279512034729e-06\n",
      "-0.9886560440063477 0.003139059292152524\n",
      "Epoch 24200:  8.737801181268878e-06\n",
      "-0.9886587858200073 0.0031392232049256563\n",
      "Epoch 24300:  8.669913768244442e-06\n",
      "-0.9886592626571655 0.0031391424126923084\n",
      "Epoch 24400:  8.675533536006697e-06\n",
      "-0.9886603355407715 0.003139152890071273\n",
      "Epoch 24500:  8.627761417301372e-06\n",
      "-0.9886630177497864 0.0031392101664096117\n",
      "Epoch 24600:  8.585660907556303e-06\n",
      "-0.9886626601219177 0.0031392083037644625\n",
      "Epoch 24700:  8.561123649997171e-06\n",
      "-0.9886630773544312 0.0031391663942486048\n",
      "Epoch 24800:  8.515419722243678e-06\n",
      "-0.9886646270751953 0.0031390381045639515\n",
      "Epoch 24900:  8.512752174283378e-06\n",
      "-0.9886672496795654 0.003139177104458213\n",
      "Epoch 25000:  8.455761417280883e-06\n",
      "-0.9886685609817505 0.00313921389169991\n",
      "Epoch 25100:  8.413468094659038e-06\n",
      "-0.9886695146560669 0.003139109117910266\n",
      "Epoch 25200:  8.400699698540848e-06\n",
      "-0.9886701703071594 0.0031391538213938475\n",
      "Epoch 25300:  8.385719411307946e-06\n",
      "-0.9886727333068848 0.0031392278615385294\n",
      "Epoch 25400:  8.334994163305964e-06\n",
      "-0.98867267370224 0.003139105159789324\n",
      "Epoch 25500:  8.329515367222484e-06\n",
      "-0.9886749386787415 0.0031392292585223913\n",
      "Epoch 25600:  8.280959264084231e-06\n",
      "-0.988674521446228 0.0031391114462167025\n",
      "Epoch 25700:  8.251748113252688e-06\n",
      "-0.9886765480041504 0.0031391780357807875\n",
      "Epoch 25800:  8.244222954090219e-06\n",
      "-0.9886780381202698 0.0031390744261443615\n",
      "Epoch 25900:  8.180907570931595e-06\n",
      "-0.9886791706085205 0.003139015519991517\n",
      "Epoch 26000:  8.16979900264414e-06\n",
      "-0.988681435585022 0.0031391324009746313\n",
      "Epoch 26100:  8.146163054334465e-06\n",
      "-0.9886820912361145 0.003139140084385872\n",
      "Epoch 26200:  8.116733624774497e-06\n",
      "-0.988685667514801 0.003139314940199256\n",
      "Epoch 26300:  8.140411409840453e-06\n",
      "-0.9886896014213562 0.0031395028345286846\n",
      "Epoch 26400:  8.070570402196608e-06\n",
      "-0.9886907339096069 0.0031394250690937042\n",
      "Epoch 26500:  8.047908522712532e-06\n",
      "-0.9886904358863831 0.0031393610406666994\n",
      "Epoch 26600:  8.022880138014443e-06\n",
      "-0.9886918663978577 0.0031393931712955236\n",
      "Epoch 26700:  8.005918061826378e-06\n",
      "-0.9886923432350159 0.003139427164569497\n",
      "Epoch 26800:  7.970995284267701e-06\n",
      "-0.9886971712112427 0.003139502601698041\n",
      "Epoch 26900:  7.939986971905455e-06\n",
      "-0.9886961579322815 0.003139473730698228\n",
      "Epoch 27000:  7.944326171127614e-06\n",
      "-0.9886971116065979 0.0031395291443914175\n",
      "Epoch 27100:  7.887947504059412e-06\n",
      "-0.9886986017227173 0.0031394183170050383\n",
      "Epoch 27200:  7.8569573815912e-06\n",
      "-0.9886985421180725 0.003139429958537221\n",
      "Epoch 27300:  7.856887350499164e-06\n",
      "-0.9887015223503113 0.003139516804367304\n",
      "Epoch 27400:  7.841934348107316e-06\n",
      "-0.988704264163971 0.0031396218109875917\n",
      "Epoch 27500:  7.789742994646076e-06\n",
      "-0.9887072443962097 0.003139705862849951\n",
      "Epoch 27600:  7.766647286189254e-06\n",
      "-0.9887065291404724 0.0031396783888339996\n",
      "Epoch 27700:  7.755033948342316e-06\n",
      "-0.9887098670005798 0.0031398124992847443\n",
      "Epoch 27800:  7.717332664469723e-06\n",
      "-0.988711416721344 0.003139766398817301\n",
      "Epoch 27900:  7.720725079707336e-06\n",
      "-0.9887109398841858 0.0031396104022860527\n",
      "Epoch 28000:  7.675820597796701e-06\n",
      "-0.988713800907135 0.0031397077254951\n",
      "Epoch 28100:  7.665044904570095e-06\n",
      "-0.9887159466743469 0.003139832289889455\n",
      "Epoch 28200:  7.651667147001717e-06\n",
      "-0.988717794418335 0.00313993776217103\n",
      "Epoch 28300:  7.61121918912977e-06\n",
      "-0.988720715045929 0.003139887936413288\n",
      "Epoch 28400:  7.608394753333414e-06\n",
      "-0.9887215495109558 0.0031401037704199553\n",
      "Epoch 28500:  7.561829079349991e-06\n",
      "-0.9887234568595886 0.0031399547588080168\n",
      "Epoch 28600:  7.547484528913628e-06\n",
      "-0.9887241721153259 0.003139931010082364\n",
      "Epoch 28700:  7.541238574049203e-06\n",
      "-0.9887286424636841 0.0031401056330651045\n",
      "Epoch 28800:  7.511889634770341e-06\n",
      "-0.9887295365333557 0.003140105167403817\n",
      "Epoch 28900:  7.488793471566169e-06\n",
      "-0.9887295365333557 0.003140172455459833\n",
      "Epoch 29000:  7.486079539376078e-06\n",
      "-0.9887335896492004 0.003140290267765522\n",
      "Epoch 29100:  7.4415870585653465e-06\n",
      "-0.988735020160675 0.0031402918975800276\n",
      "Epoch 29200:  7.451798410329502e-06\n",
      "-0.988737165927887 0.0031403566244989634\n",
      "Epoch 29300:  7.419645044137724e-06\n",
      "-0.9887409806251526 0.003140508895739913\n",
      "Epoch 29400:  7.381242085102713e-06\n",
      "-0.9887396097183228 0.003140394575893879\n",
      "Epoch 29500:  7.35213870939333e-06\n",
      "-0.9887388348579407 0.003140234388411045\n",
      "Epoch 29600:  7.366470526903868e-06\n",
      "-0.9887394309043884 0.0031402609311044216\n",
      "Epoch 29700:  7.309326065296773e-06\n",
      "-0.9887417554855347 0.0031402769964188337\n",
      "Epoch 29800:  7.31745558368857e-06\n",
      "-0.9887440204620361 0.003140412038192153\n",
      "Epoch 29900:  7.285802439582767e-06\n",
      "-0.9887463450431824 0.003140405984595418\n",
      "Epoch 30000:  7.2696911956882104e-06\n",
      "-0.988747775554657 0.0031404378823935986\n",
      "Epoch 30100:  7.285029823833611e-06\n",
      "-0.9887534379959106 0.003140712156891823\n",
      "Epoch 30200:  7.22980075806845e-06\n",
      "-0.9887551665306091 0.0031406728085130453\n",
      "Epoch 30300:  7.238843863888178e-06\n",
      "-0.9887568950653076 0.0031407454516738653\n",
      "Epoch 30400:  7.213814569695387e-06\n",
      "-0.9887589812278748 0.003140756394714117\n",
      "Epoch 30500:  7.214382094389293e-06\n",
      "-0.9887611865997314 0.0031408527866005898\n",
      "Epoch 30600:  7.192527846200392e-06\n",
      "-0.9887626767158508 0.0031409654766321182\n",
      "Epoch 30700:  7.168725915107643e-06\n",
      "-0.9887678623199463 0.003140984335914254\n",
      "Epoch 30800:  7.139572517189663e-06\n",
      "-0.9887679815292358 0.003141060471534729\n",
      "Epoch 30900:  7.110475962690543e-06\n",
      "-0.9887648224830627 0.0031408648937940598\n",
      "Epoch 31000:  7.15027726982953e-06\n",
      "-0.9887678027153015 0.003140890272334218\n",
      "Epoch 31100:  7.0877813413972035e-06\n",
      "-0.988773763179779 0.0031411361414939165\n",
      "Epoch 31200:  7.105906661308836e-06\n",
      "-0.9887780547142029 0.003141445806249976\n",
      "Epoch 31300:  7.060359166644048e-06\n",
      "-0.9887803792953491 0.003141542663797736\n",
      "Epoch 31400:  7.037818249955308e-06\n",
      "-0.9887821078300476 0.003141489578410983\n",
      "Epoch 31500:  7.016929885139689e-06\n",
      "-0.9887823462486267 0.0031414430122822523\n",
      "Epoch 31600:  7.0379110184148885e-06\n",
      "-0.9887837767601013 0.003141540801152587\n",
      "Epoch 31700:  6.996986485319212e-06\n",
      "-0.988787829875946 0.003141625551506877\n",
      "Epoch 31800:  6.97870245858212e-06\n",
      "-0.988787055015564 0.0031415438279509544\n",
      "Epoch 31900:  6.951961950107943e-06\n",
      "-0.9887894988059998 0.00314154545776546\n",
      "Epoch 32000:  6.921665772097185e-06\n",
      "-0.9887909293174744 0.0031416353303939104\n",
      "Epoch 32100:  6.90454453433631e-06\n",
      "-0.9887899160385132 0.0031414933037012815\n",
      "Epoch 32200:  6.914133336977102e-06\n",
      "-0.9887921810150146 0.0031416304409503937\n",
      "Epoch 32300:  6.865877821837785e-06\n",
      "-0.9887914061546326 0.0031415217090398073\n",
      "Epoch 32400:  6.8428203121584374e-06\n",
      "-0.988791286945343 0.0031413850374519825\n",
      "Epoch 32500:  6.855315859866096e-06\n",
      "-0.9887969493865967 0.0031416993588209152\n",
      "Epoch 32600:  6.85002396494383e-06\n",
      "-0.9888017177581787 0.003141869558021426\n",
      "Epoch 32700:  6.8491926867864095e-06\n",
      "-0.9888057708740234 0.0031420979648828506\n",
      "Epoch 32800:  6.803970791224856e-06\n",
      "-0.9888054728507996 0.003141836728900671\n",
      "Epoch 32900:  6.803981250413926e-06\n",
      "-0.9888042211532593 0.0031419270671904087\n",
      "Epoch 33000:  6.8111498876533005e-06\n",
      "-0.9888096451759338 0.0031421722378581762\n",
      "Epoch 33100:  6.779230716347229e-06\n",
      "-0.9888140559196472 0.0031422872561961412\n",
      "Epoch 33200:  6.762162684026407e-06\n",
      "-0.98881596326828 0.0031424195040017366\n",
      "Epoch 33300:  6.719968041579705e-06\n",
      "-0.9888134598731995 0.0031420430168509483\n",
      "Epoch 33400:  6.724942522851052e-06\n",
      "-0.9888142347335815 0.0031422621104866266\n",
      "Epoch 33500:  6.722050784446765e-06\n",
      "-0.9888197779655457 0.003142370842397213\n",
      "Epoch 33600:  6.70003100822214e-06\n",
      "-0.988823413848877 0.0031425331253558397\n",
      "Epoch 33700:  6.671373284916626e-06\n",
      "-0.9888237714767456 0.0031424842309206724\n",
      "Epoch 33800:  6.679154012090294e-06\n",
      "-0.9888296127319336 0.0031426711939275265\n",
      "Epoch 33900:  6.642712833127007e-06\n",
      "-0.9888278245925903 0.0031426565255969763\n",
      "Epoch 34000:  6.655872311966959e-06\n",
      "-0.9888331294059753 0.003142839064821601\n",
      "Epoch 34100:  6.657850008195965e-06\n",
      "-0.9888365268707275 0.0031430141534656286\n",
      "Epoch 34200:  6.589679287571926e-06\n",
      "-0.9888328909873962 0.0031425897032022476\n",
      "Epoch 34300:  6.619582563871518e-06\n",
      "-0.9888389110565186 0.003142885398119688\n",
      "Epoch 34400:  6.589849817828508e-06\n",
      "-0.988838791847229 0.0031429000664502382\n",
      "Epoch 34500:  6.578130069101462e-06\n",
      "-0.9888426065444946 0.0031430013477802277\n",
      "Epoch 34600:  6.563851002283627e-06\n",
      "-0.9888423085212708 0.003143010661005974\n",
      "Epoch 34700:  6.522068360936828e-06\n",
      "-0.9888448119163513 0.0031429617665708065\n",
      "Epoch 34800:  6.514525011880323e-06\n",
      "-0.9888446927070618 0.003142970846965909\n",
      "Epoch 34900:  6.497393769677728e-06\n",
      "-0.988847553730011 0.0031429603695869446\n",
      "Epoch 35000:  6.48333343633567e-06\n",
      "-0.9888499975204468 0.0031430816743522882\n",
      "Epoch 35100:  6.473369921877747e-06\n",
      "-0.9888480305671692 0.003142962232232094\n",
      "Epoch 35200:  6.487367500085384e-06\n",
      "-0.9888541102409363 0.003143199486657977\n",
      "Epoch 35300:  6.467555976996664e-06\n",
      "-0.9888573288917542 0.0031433608382940292\n",
      "Epoch 35400:  6.4673572524043266e-06\n",
      "-0.9888570308685303 0.0031432686373591423\n",
      "Epoch 35500:  6.43418388790451e-06\n",
      "-0.9888622760772705 0.0031434481497853994\n",
      "Epoch 35600:  6.456521987274755e-06\n",
      "-0.9888675808906555 0.003143728245049715\n",
      "Epoch 35700:  6.480020147137111e-06\n",
      "-0.9888728857040405 0.003144098911434412\n",
      "Epoch 35800:  6.415555162675446e-06\n",
      "-0.9888733625411987 0.003143968526273966\n",
      "Epoch 35900:  6.406673492165282e-06\n",
      "-0.9888773560523987 0.0031441282480955124\n",
      "Epoch 36000:  6.403154202416772e-06\n",
      "-0.9888827204704285 0.0031443610787391663\n",
      "Epoch 36100:  6.372701136569958e-06\n",
      "-0.9888852834701538 0.003144399030134082\n",
      "Epoch 36200:  6.358583505061688e-06\n",
      "-0.9888851642608643 0.0031442695762962103\n",
      "Epoch 36300:  6.348367151076673e-06\n",
      "-0.9888860583305359 0.003144312184303999\n",
      "Epoch 36400:  6.337298600556096e-06\n",
      "-0.9888856410980225 0.003144293325021863\n",
      "Epoch 36500:  6.335613761621062e-06\n",
      "-0.9888864755630493 0.0031443063635379076\n",
      "Epoch 36600:  6.322258741420228e-06\n",
      "-0.988892138004303 0.0031444893684238195\n",
      "Epoch 36700:  6.335614216368413e-06\n",
      "-0.9888955354690552 0.0031446004286408424\n",
      "Epoch 36800:  6.299691449385136e-06\n",
      "-0.9888962507247925 0.003144543617963791\n",
      "Epoch 36900:  6.308039246505359e-06\n",
      "-0.9889001250267029 0.0031447140499949455\n",
      "Epoch 37000:  6.2812823671265505e-06\n",
      "-0.9889022707939148 0.003144780872389674\n",
      "Epoch 37100:  6.27429517408018e-06\n",
      "-0.9889046549797058 0.0031447799410670996\n",
      "Epoch 37200:  6.261110684135929e-06\n",
      "-0.988909900188446 0.00314496923238039\n",
      "Epoch 37300:  6.239620233827736e-06\n",
      "-0.9889132976531982 0.0031451466493308544\n",
      "Epoch 37400:  6.2248636822914705e-06\n",
      "-0.9889141321182251 0.003145120106637478\n",
      "Epoch 37500:  6.1895689213997684e-06\n",
      "-0.988912045955658 0.003144835354760289\n",
      "Epoch 37600:  6.185892743815202e-06\n",
      "-0.988914966583252 0.0031450071837753057\n",
      "Epoch 37700:  6.2092840380501e-06\n",
      "-0.988915205001831 0.003145098453387618\n",
      "Epoch 37800:  6.166425009723753e-06\n",
      "-0.9889180660247803 0.003145200666040182\n",
      "Epoch 37900:  6.1859441302658524e-06\n",
      "-0.9889230132102966 0.0031452681869268417\n",
      "Epoch 38000:  6.1389291658997536e-06\n",
      "-0.9889232516288757 0.003145256545394659\n",
      "Epoch 38100:  6.13470547250472e-06\n",
      "-0.9889245629310608 0.0031453229021281004\n",
      "Epoch 38200:  6.127449069026625e-06\n",
      "-0.988929033279419 0.0031455059070140123\n",
      "Epoch 38300:  6.124425453890581e-06\n",
      "-0.988929033279419 0.003145503578707576\n",
      "Epoch 38400:  6.102683073549997e-06\n",
      "-0.9889327883720398 0.0031455380376428366\n",
      "Epoch 38500:  6.096273864386603e-06\n",
      "-0.9889329075813293 0.0031454290729016066\n",
      "Epoch 38600:  6.07595256951754e-06\n",
      "-0.9889341592788696 0.0031453934498131275\n",
      "Epoch 38700:  6.11616587775643e-06\n",
      "-0.988941490650177 0.003145732684060931\n",
      "Epoch 38800:  6.056082838767907e-06\n",
      "-0.9889439940452576 0.003145851893350482\n",
      "Epoch 38900:  6.045852387615014e-06\n",
      "-0.9889446496963501 0.003145756432786584\n",
      "Epoch 39000:  6.0434704209910706e-06\n",
      "-0.9889460802078247 0.0031458456069231033\n",
      "Epoch 39100:  6.038183983037015e-06\n",
      "-0.9889463782310486 0.0031458225566893816\n",
      "Epoch 39200:  6.023264631949132e-06\n",
      "-0.9889503717422485 0.0031459671445190907\n",
      "Epoch 39300:  6.016075076331617e-06\n",
      "-0.988955557346344 0.003146118950098753\n",
      "Epoch 39400:  5.982768925605342e-06\n",
      "-0.9889528751373291 0.0031459801830351353\n",
      "Epoch 39500:  5.96665995544754e-06\n",
      "-0.9889541864395142 0.0031459673773497343\n",
      "Epoch 39600:  5.968173809378641e-06\n",
      "-0.9889563918113708 0.003146034199744463\n",
      "Epoch 39700:  5.952562332822708e-06\n",
      "-0.9889569282531738 0.0031460451427847147\n",
      "Epoch 39800:  5.962364411971066e-06\n",
      "-0.9889606237411499 0.0031461401376873255\n",
      "Epoch 39900:  5.940729352005292e-06\n",
      "-0.988963782787323 0.003146198345348239\n",
      "Epoch 40000:  5.9057515500171576e-06\n",
      "-0.9889602661132812 0.0031460211612284184\n",
      "Epoch 40100:  5.928799964749487e-06\n",
      "-0.9889658093452454 0.0031462484039366245\n",
      "Epoch 40200:  5.900759333599126e-06\n",
      "-0.9889659881591797 0.0031460796017199755\n",
      "Epoch 40300:  5.898622930544661e-06\n",
      "-0.9889679551124573 0.003146116156131029\n",
      "Epoch 40400:  5.863540536665823e-06\n",
      "-0.9889668822288513 0.0031460903119295835\n",
      "Epoch 40500:  5.874687303730752e-06\n",
      "-0.9889687299728394 0.0031461543403565884\n",
      "Epoch 40600:  5.848545242770342e-06\n",
      "-0.9889699220657349 0.003146095434203744\n",
      "Epoch 40700:  5.848356977367075e-06\n",
      "-0.9889698028564453 0.0031460539903491735\n",
      "Epoch 40800:  5.839278401253978e-06\n",
      "-0.9889729619026184 0.0031461163889616728\n",
      "Epoch 40900:  5.834505827806424e-06\n",
      "-0.9889751672744751 0.003146156668663025\n",
      "Epoch 41000:  5.816095836053137e-06\n",
      "-0.9889788627624512 0.0031462328042834997\n",
      "Epoch 41100:  5.784049335488817e-06\n",
      "-0.9889777898788452 0.003146074479445815\n",
      "Epoch 41200:  5.813744792249054e-06\n",
      "-0.9889819622039795 0.003146213013678789\n",
      "Epoch 41300:  5.776100806542672e-06\n",
      "-0.9889823794364929 0.003146201139315963\n",
      "Epoch 41400:  5.776569651061436e-06\n",
      "-0.988987147808075 0.003146370407193899\n",
      "Epoch 41500:  5.7965949054050725e-06\n",
      "-0.9889885187149048 0.0031465066131204367\n",
      "Epoch 41600:  5.765368769061752e-06\n",
      "-0.98899245262146 0.003146479604765773\n",
      "Epoch 41700:  5.746579518017825e-06\n",
      "-0.9889925718307495 0.003146503586322069\n",
      "Epoch 41800:  5.7277393352705985e-06\n",
      "-0.9889922738075256 0.003146424423903227\n",
      "Epoch 41900:  5.714791313948808e-06\n",
      "-0.9889956712722778 0.0031464649364352226\n",
      "Epoch 42000:  5.6931016843009274e-06\n",
      "-0.9889927506446838 0.003146267728880048\n",
      "Epoch 42100:  5.724168659071438e-06\n",
      "-0.9889974594116211 0.0031465620268136263\n",
      "Epoch 42200:  5.705723197024781e-06\n",
      "-0.9890006184577942 0.003146539907902479\n",
      "Epoch 42300:  5.662850526277907e-06\n",
      "-0.9889990091323853 0.0031463513150811195\n",
      "Epoch 42400:  5.675007741956506e-06\n",
      "-0.9890008568763733 0.0031463722698390484\n",
      "Epoch 42500:  5.67006964047323e-06\n",
      "-0.9890023469924927 0.003146519185975194\n",
      "Epoch 42600:  5.652894287777599e-06\n",
      "-0.9890037775039673 0.0031465019565075636\n",
      "Epoch 42700:  5.6784019761835225e-06\n",
      "-0.9890087842941284 0.0031466269865632057\n",
      "Epoch 42800:  5.634935405396391e-06\n",
      "-0.989012598991394 0.0031467133667320013\n",
      "Epoch 42900:  5.650002549373312e-06\n",
      "-0.9890161156654358 0.003146839328110218\n",
      "Epoch 43000:  5.635476099996595e-06\n",
      "-0.9890185594558716 0.003146841423586011\n",
      "Epoch 43100:  5.629411589325173e-06\n",
      "-0.9890207648277283 0.0031468651723116636\n",
      "Epoch 43200:  5.600980784947751e-06\n",
      "-0.9890180826187134 0.0031467098742723465\n",
      "Epoch 43300:  5.58492865820881e-06\n",
      "-0.9890199303627014 0.003146858187392354\n",
      "Epoch 43400:  5.572087047767127e-06\n",
      "-0.9890213012695312 0.003146848874166608\n",
      "Epoch 43500:  5.583850906987209e-06\n",
      "-0.9890222549438477 0.003146874951198697\n",
      "Epoch 43600:  5.54774214833742e-06\n",
      "-0.9890233874320984 0.0031468113884329796\n",
      "Epoch 43700:  5.54229927729466e-06\n",
      "-0.989022433757782 0.0031467010267078876\n",
      "Epoch 43800:  5.563694685406517e-06\n",
      "-0.9890268445014954 0.003147000912576914\n",
      "Epoch 43900:  5.544002760871081e-06\n",
      "-0.9890304803848267 0.0031469406094402075\n",
      "Epoch 44000:  5.520601462194463e-06\n",
      "-0.9890339374542236 0.0031470321118831635\n",
      "Epoch 44100:  5.502041858562734e-06\n",
      "-0.989033579826355 0.003147011622786522\n",
      "Epoch 44200:  5.516004421224352e-06\n",
      "-0.9890367388725281 0.003147041890770197\n",
      "Epoch 44300:  5.477246304508299e-06\n",
      "-0.9890359044075012 0.003147000912576914\n",
      "Epoch 44400:  5.494118795468239e-06\n",
      "-0.98903489112854 0.00314702489413321\n",
      "Epoch 44500:  5.471546501212288e-06\n",
      "-0.9890356659889221 0.0031470113899558783\n",
      "Epoch 44600:  5.484648227138678e-06\n",
      "-0.9890387058258057 0.0031471115071326494\n",
      "Epoch 44700:  5.462056378746638e-06\n",
      "-0.9890415072441101 0.0031471294350922108\n",
      "Epoch 44800:  5.448890533443773e-06\n",
      "-0.9890435934066772 0.0031471189577132463\n",
      "Epoch 44900:  5.43766964256065e-06\n",
      "-0.9890444278717041 0.003147078910842538\n",
      "Epoch 45000:  5.419219178293133e-06\n",
      "-0.9890455007553101 0.00314699811860919\n",
      "Epoch 45100:  5.4018069022276904e-06\n",
      "-0.9890435338020325 0.003146946895867586\n",
      "Epoch 45200:  5.399007932282984e-06\n",
      "-0.989046037197113 0.00314702233299613\n",
      "Epoch 45300:  5.385217264120001e-06\n",
      "-0.9890452027320862 0.00314693502150476\n",
      "Epoch 45400:  5.396621418185532e-06\n",
      "-0.9890488386154175 0.003147101728245616\n",
      "Epoch 45500:  5.380448783398606e-06\n",
      "-0.9890518188476562 0.0031470172107219696\n",
      "Epoch 45600:  5.380719812819734e-06\n",
      "-0.9890564680099487 0.0031473019625991583\n",
      "Epoch 45700:  5.376650278776651e-06\n",
      "-0.9890598058700562 0.0031474195420742035\n",
      "Epoch 45800:  5.35503204446286e-06\n",
      "-0.9890596270561218 0.003147259820252657\n",
      "Epoch 45900:  5.340910774975782e-06\n",
      "-0.9890594482421875 0.003147131996229291\n",
      "Epoch 46000:  5.35386243427638e-06\n",
      "-0.9890620112419128 0.0031471969559788704\n",
      "Epoch 46100:  5.33388174517313e-06\n",
      "-0.9890627264976501 0.003147256327793002\n",
      "Epoch 46200:  5.327964117896045e-06\n",
      "-0.9890674352645874 0.0031474081333726645\n",
      "Epoch 46300:  5.34249465999892e-06\n",
      "-0.9890682697296143 0.003147413954138756\n",
      "Epoch 46400:  5.3046296670800075e-06\n",
      "-0.9890704154968262 0.0031474512070417404\n",
      "Epoch 46500:  5.3132089306018315e-06\n",
      "-0.9890725016593933 0.0031475394498556852\n",
      "Epoch 46600:  5.297810730553465e-06\n",
      "-0.9890749454498291 0.0031475990545004606\n",
      "Epoch 46700:  5.303729267325252e-06\n",
      "-0.989078938961029 0.0031477119773626328\n",
      "Epoch 46800:  5.283192422211869e-06\n",
      "-0.9890823364257812 0.003147783922031522\n",
      "Epoch 46900:  5.2884279284626245e-06\n",
      "-0.9890846610069275 0.0031478749588131905\n",
      "Epoch 47000:  5.2739210332219955e-06\n",
      "-0.9890870451927185 0.0031478856690227985\n",
      "Epoch 47100:  5.29362750967266e-06\n",
      "-0.9890894889831543 0.003148040035739541\n",
      "Epoch 47200:  5.272581802273635e-06\n",
      "-0.9890927076339722 0.003148092655465007\n",
      "Epoch 47300:  5.2488476285361685e-06\n",
      "-0.9890962243080139 0.0031481939367949963\n",
      "Epoch 47400:  5.266677362669725e-06\n",
      "-0.9890978336334229 0.003148200921714306\n",
      "Epoch 47500:  5.263621915219119e-06\n",
      "-0.9891030788421631 0.0031483699567615986\n",
      "Epoch 47600:  5.23391008755425e-06\n",
      "-0.9891035556793213 0.0031483126804232597\n",
      "Epoch 47700:  5.2137170314381365e-06\n",
      "-0.9891039729118347 0.0031482994090765715\n",
      "Epoch 47800:  5.218878868618049e-06\n",
      "-0.9891056418418884 0.003148382995277643\n",
      "Epoch 47900:  5.210361905483296e-06\n",
      "-0.9891080260276794 0.00314835412427783\n",
      "Epoch 48000:  5.1970064305351116e-06\n",
      "-0.9891088008880615 0.003148480085656047\n",
      "Epoch 48100:  5.181885171623435e-06\n",
      "-0.9891096949577332 0.003148463321849704\n",
      "Epoch 48200:  5.160378805157961e-06\n",
      "-0.989107072353363 0.0031482845079153776\n",
      "Epoch 48300:  5.170873464521719e-06\n",
      "-0.9891088008880615 0.0031484540086239576\n",
      "Epoch 48400:  5.173302724870155e-06\n",
      "-0.9891114234924316 0.003148348070681095\n",
      "Epoch 48500:  5.1376437113503926e-06\n",
      "-0.9891088008880615 0.0031483015045523643\n",
      "Epoch 48600:  5.138274445926072e-06\n",
      "-0.9891120791435242 0.0031483506318181753\n",
      "Epoch 48700:  5.125881216372363e-06\n",
      "-0.9891135692596436 0.0031483692582696676\n",
      "Epoch 48800:  5.125288225826807e-06\n",
      "-0.9891149997711182 0.003148433519527316\n",
      "Epoch 48900:  5.124365088704508e-06\n",
      "-0.989117443561554 0.0031484824139624834\n",
      "Epoch 49000:  5.113092811370734e-06\n",
      "-0.9891191720962524 0.0031484358478337526\n",
      "Epoch 49100:  5.104201591166202e-06\n",
      "-0.9891190528869629 0.0031483869533985853\n",
      "Epoch 49200:  5.085018983663758e-06\n",
      "-0.989120364189148 0.0031483923085033894\n",
      "Epoch 49300:  5.102031536807772e-06\n",
      "-0.9891226291656494 0.0031485441140830517\n",
      "Epoch 49400:  5.108634468342643e-06\n",
      "-0.9891265034675598 0.0031485974323004484\n",
      "Epoch 49500:  5.073265583632747e-06\n",
      "-0.9891299605369568 0.0031486302614212036\n",
      "Epoch 49600:  5.077585683466168e-06\n",
      "-0.9891322255134583 0.0031486095394939184\n",
      "Epoch 49700:  5.049381798016839e-06\n",
      "-0.9891322255134583 0.0031486384104937315\n",
      "Epoch 49800:  5.036223683418939e-06\n",
      "-0.9891300797462463 0.003148528514429927\n",
      "Epoch 49900:  5.0598087000253145e-06\n",
      "-0.9891317486763 0.0031485131476074457\n",
      "Epoch 49999:  5.03948194818804e-06\n",
      "-0.9891335368156433 0.0031485233921557665\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "pinn.train()\n",
    "for i in range(epochs):\n",
    "    optimizer1.step(mtl_closure)\n",
    "    if (i % 100) == 0 or i == epochs-1:\n",
    "        l = mtl_closure()\n",
    "        print(\"Epoch {}: \".format(i), l.item())\n",
    "        print(float(pinn.p1.detach().numpy()), float((pinn.p0.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pinn, \"pinn_ffth_cleanob_cleanlabel_1000labeledsamples.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinn no ffth clean all\n",
    "# (-1.00022292137146, 0.0031830661464482546)\n",
    "# (0.011659960711956706, 0.01063217643403939)\n",
    "\n",
    "# pinn no ffth clean ob noisy label\n",
    "# (-1.0002213716506958, 0.003198811085894704)\n",
    "# (0.2578756208767374, 0.2357384558071573)\n",
    "\n",
    "# pinn no ffth noisy ob noisy label\n",
    "# (-1.009460687637329 0.0032692295499145985)\n",
    "# (1.8259720664182926, 0.8799033026853824)\n",
    "\n",
    "### ----- ###\n",
    "# pinn ffth clean all\n",
    "# (-0.9994307160377502, 0.0031862353649783444)\n",
    "# 0.07773227423228249\n",
    "\n",
    "# pinn ffth clean ob noisy label\n",
    "# (-1.0016363859176636 0.003176966216415167)\n",
    "# (0.17815066491893816, 0.014512073152580726)\n",
    "\n",
    "# pinn ffth noisy ob noisy label\n",
    "# (-1.0197374820709229 0.0031673626508563757)\n",
    "# (1.2340579276207333, 0.7396902794715519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = torch.load(\"...\")\n",
    "# est1 = abs(float(sd[\"p1\"].detach().numpy()))\n",
    "# est2 = float(sd[\"p0\"].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "est1 = abs(float((pinn.p1.detach().numpy())))\n",
    "est2 = (float((pinn.p0.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9891335368156433, 0.0031485233921557665)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est1, est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0864333669569826, 0.0002129514786863851)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = 0.01/np.pi\n",
    "errs = 100*npar([np.abs(est1-1), np.abs(est2-const)/const])\n",
    "errs.mean(), errs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
