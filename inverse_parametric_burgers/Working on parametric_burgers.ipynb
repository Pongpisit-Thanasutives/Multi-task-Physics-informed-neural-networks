{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys; sys.path.insert(0, \"../\"); from utils import *\n",
    "from parametric_discovery_pinn import ParametricPINN\n",
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ../parametric_pde_data/parametric_burgers.pkl\n"
     ]
    }
   ],
   "source": [
    "data = pickle_load(\"../parametric_pde_data/parametric_burgers.pkl\")\n",
    "\n",
    "x = data['x']; spatial_dims = x.shape[0]\n",
    "t = data['t']; time_dims = t.shape[0]\n",
    "\n",
    "Exact = data['u']\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((to_column_vector(X), to_column_vector(T)))\n",
    "u_star = to_column_vector(Exact.T)\n",
    "\n",
    "# domain bounds\n",
    "lb = X_star.min(axis=0)\n",
    "ub = X_star.max(axis=0)\n",
    "\n",
    "# Sampling training data points\n",
    "N = 20000\n",
    "training_idxs = sampling_from_rows(X_star, N, True)\n",
    "X_train = X_star[training_idxs, :]\n",
    "u_train = u_star[training_idxs, :]\n",
    "\n",
    "# to_tensor\n",
    "X_star = to_tensor(X_star, True)\n",
    "u_star = to_tensor(u_star, False)\n",
    "X_train = to_tensor(X_train, True)\n",
    "u_train = to_tensor(u_train, False)\n",
    "lb = to_tensor(lb, False)\n",
    "ub = to_tensor(ub, False)\n",
    "\n",
    "u_xx_true = 0.1*np.ones(u_star.shape)\n",
    "uu_x_true = -1*(1+0.25*np.sin(X_star[:, 1:2].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn = ParametricPINN(scale=True, lb=lb, ub=ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcgrad_closure(return_list=False):\n",
    "    global N, X_train, u_train\n",
    "    losses = pinn.loss(*dimension_slicing(X_train), u_train)\n",
    "    updated_grads = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        losses[i].backward(retain_graph=True)\n",
    "\n",
    "        g_task = []\n",
    "        for param in pinn.parameters():\n",
    "            if param.grad is not None:\n",
    "                g_task.append(Variable(param.grad.clone(), requires_grad=False))\n",
    "            else:\n",
    "                g_task.append(Variable(torch.zeros(param.shape), requires_grad=False))\n",
    "        # appending the gradients from each task\n",
    "        updated_grads.append(g_task)\n",
    "\n",
    "    updated_grads = list(pcgrad.pc_grad_update(updated_grads))[0]\n",
    "    for idx, param in enumerate(pinn.parameters()):\n",
    "        param.grad = (updated_grads[0][idx]+updated_grads[1][idx])\n",
    "        \n",
    "    if not return_list: return sum(losses)\n",
    "    else: return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_closure():\n",
    "    global N, X_train, u_train\n",
    "    if torch.is_grad_enabled(): f_opt.zero_grad()\n",
    "    # the solver network only consider the first N samples.\n",
    "    loss = sum(pinn.loss(*dimension_slicing(X_train), u_train))\n",
    "    if loss.requires_grad: loss.backward(retain_graph=False)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004037567996419966\n",
      "1.7877066511573503e-06\n",
      "1.78347431756265e-06\n",
      "1.7828524505603127e-06\n",
      "1.7828524505603127e-06\n"
     ]
    }
   ],
   "source": [
    "# ‡πÉ‡∏™‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ\n",
    "# optimizer = MADGRAD(pinn.parameters(), lr=1e-3, momentum=0.9)\n",
    "# for i in range(150):\n",
    "#     pinn.train()\n",
    "#     optimizer.step(pcgrad_closure)\n",
    "#     if i%10==0:\n",
    "#         loss = pcgrad_closure(return_list=True)\n",
    "#         print(loss)\n",
    "        \n",
    "f_opt = torch.optim.LBFGS(pinn.parameters(), lr=1e-1, max_iter=300, history_size=300)\n",
    "for i in range(50):\n",
    "    f_opt.step(finetuning_closure)\n",
    "    if i%10==0:\n",
    "        loss = finetuning_closure()\n",
    "        print(loss.item())\n",
    "        \n",
    "# ‚àí0.56759363sin(ùë•0)‚àí0.8300467 will be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7851e-06, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pinn.loss(*dimension_slicing(X_star), u_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_preds, learned_func = pinn(*dimension_slicing(X_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011552452\n",
      "1.3926681303858421e-05\n"
     ]
    }
   ],
   "source": [
    "print(np.mean((learned_func[:, 0:1].detach().numpy()-uu_x_true)**2))\n",
    "print(np.mean((learned_func[:, 1:2].detach().numpy()-u_xx_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = X_star[:, 1:2].detach().numpy()\n",
    "plt.scatter(time, uu_x_true)\n",
    "plt.scatter(time, learned_func[:, 0:1].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr import pysr, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on julia -O3 /var/folders/z3/_stfms3523dd5mnfr3ch5n100000gp/T/tmpo0i11pro/runfile.jl\n",
      "Activating environment on workers.\n",
      "      From worker 4:\t  Activating environment at `/usr/local/lib/python3.9/site-packages/Project.toml`\n",
      "      From worker 3:\t  Activating environment at `/usr/local/lib/python3.9/site-packages/Project.toml`\n",
      "      From worker 5:\t  Activating environment at `/usr/local/lib/python3.9/site-packages/Project.toml`\n",
      "      From worker 2:\t  Activating environment at `/usr/local/lib/python3.9/site-packages/Project.toml`\n",
      "Importing installed module on workers...Finished!\n",
      "Testing module on workers...Finished!\n",
      "Testing entire pipeline on workers...Finished!\n",
      "Started!\n",
      "\n",
      "Cycles per second: 1.100e+03\n",
      "Head worker occupation: 4.3%\n",
      "Progress: 1 / 250 total iterations (0.400%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 3.550e+03\n",
      "Head worker occupation: 3.5%\n",
      "Progress: 2 / 250 total iterations (0.800%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 3.690e+03\n",
      "Head worker occupation: 2.9%\n",
      "Progress: 3 / 250 total iterations (1.200%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 4.270e+03\n",
      "Head worker occupation: 2.6%\n",
      "Progress: 4 / 250 total iterations (1.600%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 4.000e+03\n",
      "Head worker occupation: 2.2%\n",
      "Progress: 5 / 250 total iterations (2.000%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 6.340e+03\n",
      "Head worker occupation: 2.2%\n",
      "Progress: 8 / 250 total iterations (3.200%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 5.760e+03\n",
      "Head worker occupation: 1.9%\n",
      "Progress: 9 / 250 total iterations (3.600%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 7.290e+03\n",
      "Head worker occupation: 1.9%\n",
      "Progress: 12 / 250 total iterations (4.800%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 6.640e+03\n",
      "Head worker occupation: 1.5%\n",
      "Progress: 13 / 250 total iterations (5.200%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 7.180e+03\n",
      "Head worker occupation: 1.5%\n",
      "Progress: 15 / 250 total iterations (6.000%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 7.270e+03\n",
      "Head worker occupation: 1.3%\n",
      "Progress: 16 / 250 total iterations (6.400%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 7.870e+03\n",
      "Head worker occupation: 1.3%\n",
      "Progress: 18 / 250 total iterations (7.200%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 8.670e+03\n",
      "Head worker occupation: 1.3%\n",
      "Progress: 20 / 250 total iterations (8.000%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 8.300e+03\n",
      "Head worker occupation: 1.2%\n",
      "Progress: 21 / 250 total iterations (8.400%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 1.040e+04\n",
      "Head worker occupation: 1.2%\n",
      "Progress: 25 / 250 total iterations (10.000%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "\n",
      "Cycles per second: 1.010e+04\n",
      "Head worker occupation: 5.2%\n",
      "Progress: 30 / 250 total iterations (12.000%)\n",
      "==============================\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.002e-02  -0.000e+00  -1.0908816\n",
      "5           4.127e-04  9.705e-01  (-0.8492799 + (-0.48320252 * x0))\n",
      "6           1.083e-04  1.338e+00  (-0.8300467 + (-0.56759363 * sin(x0)))\n",
      "8           7.216e-05  2.029e-01  (sin(-7.2256327 + x0) + (-1.3620443 * x0))\n",
      "10          9.226e-06  1.028e+00  ((-0.81369656 + (0.47702125 * x0)) + (-1.1221873 * sin(x0)))\n",
      "\n",
      "==============================\n",
      "Killing process... will return when done.\n"
     ]
    }
   ],
   "source": [
    "xx = (to_tensor(t, False)/10.0).reshape(-1, 1)\n",
    "yy = pinn.parametric_func_net(xx)[:, 0:1].detach().numpy()\n",
    "\n",
    "equations = pysr(\n",
    "    xx.detach().numpy(),\n",
    "    yy,\n",
    "    populations=50,\n",
    "    niterations=5,\n",
    "    binary_operators=[\"+\", \"*\"],\n",
    "    unary_operators=[\n",
    "        \"sin\",\n",
    "        \"cos\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 0.56759363 \\sin{\\left(x_{0} \\right)} - 0.8300467$"
      ],
      "text/plain": [
       "-0.56759363*sin(x0) - 0.8300467"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
